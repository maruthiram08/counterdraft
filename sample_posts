
## **Introduction: What Are AI Agents? **

An **AI Agent** is an autonomous software program that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to understand context, reason about problems, and generate intelligent responses.

### **Key Characteristics of AI Agents:**

- 

**Autonomy**: They can operate independently without constant human intervention
- 

**Perception**: They can read and understand various data formats (text, files, APIs)
- 

**Reasoning**: They use LLMs to analyze information and make decisions
- 

**Action**: They can execute tasks, generate reports, and provide recommendations
- 

**Goal-Oriented**: They work towards specific objectives defined by their role

### **Real-World Analogy**

Think of an AI agent like a **smart assistant**:
- 

A traditional program is like a calculator: you input numbers, it gives you a result
- 

An AI agent is like a financial advisor: you show them your bank statement, they understand the context, analyze patterns, and provide personalized advice

## **Why Multi-Agent Systems?**

Instead of one ‚Äújack-of-all-trades‚Äù agent, we use **multiple specialized agents** that collaborate. Each agent has a specific role and expertise, making the system more effective and reliable.

Full github code

### **Our Finance Agent System Uses Two Agents:**

#### **1. Spending Analyst Agent**

- 

**Role**: Financial data analyst
- 

**Expertise**: Pattern recognition, categorization, data analysis
- 

**Responsibilities**:
- 

Categorizes transactions (groceries, dining, bills, etc.)
- 

Identifies spending patterns and trends
- 

Calculates totals, averages, and percentages
- 

Finds the largest transactions

#### **2. Financial Advisor Agent**

- 

**Role**: Personal financial advisor
- 

**Expertise**: Budgeting, financial planning, recommendations
- 

**Responsibilities**:
- 

Creates personalized recommendations
- 

Suggests realistic budgets
- 

Identifies savings opportunities
- 

Develops 30-day action plans

### **Why This Approach Works Better:**

- 

**Specialization**: Each agent focuses on what they do best
- 

**Quality**: Specialized agents produce better results than generalists
- 

**Modularity**: Easy to improve or replace individual agents
- 

**Collaboration**: Agents can build on each other‚Äôs work
- 

**Scalability**: Easy to add more agents for new features

## **Technology Stack & Frameworks :**

Full github code

## **Core Frameworks**

#### **1. CrewAI üöÄ**

- 

**What it is**: A framework for orchestrating multi-agent AI systems
- 

**Why do we use it**:
- 

Simplifies agent coordination and task management
- 

Handles agent communication and workflow
- 

Built specifically for multi-agent scenarios
- 

Provides clean abstractions for agents, tasks, and crews

**Key Features:**
- 

Agent definition and management
- 

Task orchestration
- 

Sequential and hierarchical process flows
- 

Built-in memory and caching

#### **2. LangChain üîó**

- 

**What it is**: A framework for building LLM-powered applications
- 

**Why do we use it**:
- 

Provides standardized interfaces to LLMs
- 

Handles API communication with OpenAI
- 

Manages prompts and responses
- 

Enables tool integration

**Key Features:**
- 

LLM abstraction layer
- 

Prompt management
- 

Chain composition
- 

Tool integration

#### **3. Streamlit üìä**

- 

**What it is**: A Python framework for building web applications
- 

**Why we use it**:
- 

Rapid UI development (no HTML/CSS/JS needed)
- 

Built-in components for data visualization
- 

Easy file upload handling
- 

Perfect for AI/ML demos and dashboards

**Key Features:**
- 

Simple Python-based UI
- 

Interactive widgets
- 

File upload support
- 

Real-time updates

### **Supporting Libraries**

#### **pandas & numpy**

- 

Data manipulation and analysis
- 

Used for processing CSV/Excel files
- 

Statistical calculations

#### **pdfplumber & openpyxl**

- 

PDF text extraction
- 

Excel file reading
- 

File format handling

#### **python-dotenv**

- 

Environment variable management
- 

Secure API key storage

#### **plotly**

- 

Interactive data visualization
- 

Charts and graphs for spending analysis

## **Project Architecture Overview {#architecture}**

### **System Flow**

```
User Uploads Bank Statement
         ‚Üì
Streamlit UI (streamlit_app.py)
         ‚Üì
Smart Processor (smart_processor.py)
    - Extracts transactions
    - Normalizes data format
    - Returns JSON
         ‚Üì
CrewAI Orchestrator (crew.py)
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
Spending Analyst   Financial Advisor
    Agent              Agent
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Results Displayed

```

### **Component Responsibilities**

- 

**User Interface Layer** ( `streamlit_app.py`)
- 

Handles file uploads
- 

Displays results
- 

User interaction

- 

**Data Processing Layer** ( `smart_processor.py`)
- 

Reads various file formats
- 

Extracts transaction data
- 

Normalizes to standard format
- 

Handles currency detection

- 

**Orchestration Layer** ( `crew.py`)
- 

Coordinates agent execution
- 

Manages task flow
- 

Handles agent communication

- 

**Agent Layer** ( `agents.py`)
- 

Defines agent personalities
- 

Sets roles and goals
- 

Configures LLM connections

- 

**Task Layer** ( `tasks.py`)
- 

Defines what each agent should do
- 

Provides instructions and context
- 

Sets expected outputs

## **Understanding the Code Structure **

Full github code

### **File-by-File Overview**

#### `streamlit_app.py`** - The User Interface**

**Purpose**: Creates the web interface that users interact with

**Key Components**:
- 

File upload widget for bank statements
- 

Progress indicators during analysis
- 

Results display sections
- 

Styling and layout

**What it does**:
- 

Accepts file uploads (CSV, Excel, PDF)
- 

Calls the processor to extract data
- 

Triggers the CrewAI analysis
- 

Displays formatted results

**Key Functions**:
- 

File upload handling
- 

Progress tracking
- 

Error management
- 

Results rendering

#### `smart_processor.py`** - The Data Extractor**

**Purpose**: Converts various bank statement formats into standardized transaction data

**Key Components**:
- 

File type detection (CSV, Excel, PDF)
- 

Data extraction methods
- 

Currency detection
- 

Amount normalization

**What it does**:
- 

Detects file format
- 

Reads file content
- 

Extracts transaction data (Date, Description, Amount)
- 

Normalizes amounts and dates
- 

Returns a JSON array of transactions

**Key Classes**:
- 

`SmartBankStatementProcessor`: Main processor class
- 

Handles multiple file formats intelligently
- 

Uses AI for PDF extraction when needed

**Key Methods**:
- 

`process_file()`: Main entry point
- 

`_extract_from_dataframe()`: Processes tabular data
- 

`_ai_extract_transactions()`: Uses LLM for PDF extraction
- 

`_parse_amount()`: Normalizes currency amounts

#### `agents.py`** - Agent Definitions**

**Purpose**: Defines the personality, role, and capabilities of each AI agent

**Key Components**:
- 

LLM configuration
- 

Agent role definitions
- 

Backstories (personality)
- 

Goals and behaviors

**What it defines**:

**Spending Analyst Agent**:
- 

**Role**: Spending Behavior Analyst
- 

**Goal**: Identify patterns and categorize expenses
- 

**Backstory**: Expert financial data analyst
- 

**Capabilities**: Pattern recognition, categorization

**Financial Advisor Agent**:
- 

**Role**: Personal Financial Advisor
- 

**Goal**: Provide personalized recommendations
- 

**Backstory**: Certified financial advisor
- 

**Capabilities**: Budgeting, planning, recommendations

**Key Concepts**:
- 

**Role**: What the agent is (job title)
- 

**Goal**: What the agent should achieve
- 

**Backstory**: Personality and expertise (helps LLM understand context)
- 

**LLM**: The language model powering the agent (GPT-4)

#### `tasks.py`** - Task Definitions**

**Purpose**: Defines specific tasks for each agent with detailed instructions

**Key Components**:
- 

Task descriptions
- 

Input data context
- 

Output format specifications
- 

Instructions for agents

**What it defines**:

**Analysis Task** (for Spending Analyst):
- 

Receives transaction JSON
- 

Instructions to categorize and analyze
- 

Format for output (categories, totals, insights)
- 

Emphasis on using real numbers

**Recommendation Task** (for Financial Advisor):
- 

Receives analysis results
- 

Instructions to create recommendations
- 

Format for budgets and action plans
- 

Emphasis on personalization

**Key Concepts**:
- 

**Description**: What the agent should do (detailed instructions)
- 

**Agent**: Which agent performs this task
- 

**Expected Output**: What format should the result be in
- 

**Context**: Data passed to the agent

#### `crew.py`** - Orchestration**

**Purpose**: Coordinates the multi-agent workflow

**Key Components**:
- 

Crew creation
- 

Task sequencing
- 

Agent coordination
- 

Result aggregation

**What it does**:
- 

Creates the first crew with Spending Analyst
- 

Executes analysis task
- 

Creates a second crew with a Financial Advisor
- 

Passes analysis results to advisor
- 

Executes the recommendation task
- 

Returns combined results

**Key Functions**:
- 

`analyze_finances()`: Main orchestration function
- 

Creates sequential crews
- 

Manages data flow between agents
- 

Combines results

**Key Concepts**:
- 

**Crew**: A group of agents working together
- 

**Process**: How agents execute (sequential, hierarchical)
- 

**Kickoff**: Starting the crew execution
- 

**Sequential**: Tasks run one after another

## **Setting Up Your Environment **

### **Prerequisites**

- 

**Python 3.8+**: Modern Python with latest features
- 

**OpenAI API Key**: Access to GPT-4 (we‚Äôll cover this next)
- 

**Git**: For cloning the repository
- 

**Terminal/Command Line**: For running commands

### **Step-by-Step Setup**

#### **1. Clone the Repository**

```
git clone <repository-url>
cd ‚Äúpersonal Finacne agent‚Äù
```

#### **2. Create Virtual Environment**

**Why?** Isolates project dependencies from the system Python

```
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**What this does**: Creates a clean Python environment just for this project

#### **3. Install Dependencies**

```
pip install -r requirements.txt
```

**What gets installed**:
- 

CrewAI framework
- 

LangChain and OpenAI integration
- 

Streamlit for UI
- 

Data processing libraries (pandas, pdfplumber, etc.)

#### **4. Configure Environment Variables**

```
# Create .env file
touch .env
```

Add your API key (see next section):

```
OPENAI_API_KEY=sk-your-key-here

```

#### **5. Run the Application**

```
streamlit run streamlit_app.py
```

The app will open at 

http://localhost:8501

## **Getting API Keys **

### **OpenAI API Key Setup**

#### **Step 1: Create an OpenAI Account**

- 

Go to platform.openai.com
- 

Sign up or log in
- 

Verify your email if required

#### **Step 2: Add Payment Method**

- 

Navigate to **Settings** ‚Üí **Billing**
- 

Add a payment method (credit card)
- 

Set up usage limits (recommended: $10-20/month for testing)

**Why payment is needed**: GPT-4 is a paid service (pay-per-use)

#### **Step 3: Generate API Key**

- 

Go to the **API Keys** section
- 

Click **‚ÄúCreate new secret key.‚Äù**
- 

Name it (e.g., ‚ÄúFinance Agent‚Äù)
- 

**Copy the key immediately** (you won‚Äôt see it again!)

#### **Step 4: Add to Project**

- 

Create `.env` file in project root
- 

Add: `OPENAI_API_KEY=sk-your-actual-key-here`
- 

**Never commit this file to Git!**

### **API Key Security Best Practices**

‚úÖ **DO**:
- 

Store in `.env` file
- 

Add `.env` to `.gitignore`
- 

Use environment variables in production
- 

Rotate keys periodically

‚ùå **DON‚ÄôT**:
- 

Commit keys to Git
- 

Share keys publicly
- 

Hardcode in source files
- 

Use same key for multiple projects

### **Understanding API Costs**

**GPT-4 Pricing** (as of 2024):
- 

Input: ~$0.03 per 1K tokens
- 

Output: ~$0.06 per 1K tokens
- 

Typical analysis: ~$0.10-0.50 per bank statement

**Cost Optimization Tips**:
- 

Use GPT-3.5-turbo for simpler tasks (10x cheaper)
- 

Cache results when possible
- 

Set monthly spending limits
- 

Monitor usage in the OpenAI dashboard

## **Next Steps & Extensions {#next-steps}**

### **Immediate Improvements**

- 

**Add More Agents**
- 

Budget Tracker Agent: Monitors spending against budgets
- 

Trend Analyst Agent: Identifies long-term patterns
- 

Alert Agent: Flags unusual spending

- 

**Enhanced Features**
- 

Multi-month analysis
- 

Recurring transaction detection
- 

Savings goal tracking
- 

Export reports as PDF

- 

**Better UI**
- 

Interactive charts (Plotly)
- 

Category breakdowns
- 

Spending trends over time
- 

Comparison views

### **Advanced Extensions**

- 

**Database Integration**
- 

Store transaction history
- 

Track spending over time
- 

Generate monthly reports

- 

**Real-time Monitoring**
- 

Connect to bank APIs
- 

Automatic transaction import
- 

Daily spending alerts

- 

**Multi-Account Support**
- 

Multiple bank accounts
- 

Credit card integration
- 

Investment account tracking

- 

**AI Enhancements**
- 

Custom categorization rules
- 

Predictive spending forecasts
- 

Personalized savings strategies

### **Learning Resources**

**CrewAI Documentation**:
- 

Official Docs
- 

GitHub Examples

**LangChain Resources**:
- 

LangChain Docs
- 

Tutorials

**Streamlit Guides**:
- 

Streamlit Docs
- 

Gallery

## **Conclusion**

You‚Äôve now built a sophisticated multi-agent AI system that can analyze personal finances! This project demonstrates:

‚úÖ **Multi-agent orchestration** with CrewAI ‚úÖ **Intelligent data processing** with AI ‚úÖ **User-friendly interface** with Streamlit ‚úÖ **Real-world application** solving actual problems

### **Key Takeaways**

- 

**AI Agents** are autonomous programs that can reason and act
- 

**Multi-agent systems** are more powerful than single agents
- 

**CrewAI** simplifies agent coordination
- 

**Proper prompts** are crucial for good results
- 

**Real-world apps** need robust error handling

### **What You‚Äôve Learned**

- 

How to structure a multi-agent system
- 

How to process various file formats
- 

How to create effective agent prompts
- 

How to build a production-ready UI
- 

How to integrate multiple frameworks and tools

**Keep experimenting, keep building, and keep learning!** üöÄ

## **Appendix: Quick Reference**

### **Project Structure**

```
personal Finacne agent/
‚îú‚îÄ‚îÄ streamlit_app.py      # UI layer
‚îú‚îÄ‚îÄ smart_processor.py     # Data extraction
‚îú‚îÄ‚îÄ agents.py              # Agent definitions
‚îú‚îÄ‚îÄ tasks.py               # Task definitions
‚îú‚îÄ‚îÄ crew.py                # Orchestration
‚îú‚îÄ‚îÄ requirements.txt       # Dependencies
‚îî‚îÄ‚îÄ .env                   # API keys (not in Git)

```

### **Key Commands**

```
# Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run
streamlit run streamlit_app.py

# Check logs
# View terminal output for agent execution details
```

### **Important Files**

- 

`.env`: Contains your API key (never commit!)
- 

`requirements.txt`: All Python dependencies
- 

`agents.py`: Define your AI agents
- 

`tasks.py`: Define what agents should do

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

## Frequently Asked Questions (FAQ)

### What is an AI agent in simple terms?

An **AI agent** is an intelligent software system that can understand information, make decisions, and take actions on its own to achieve a goal. Unlike traditional programs that follow fixed rules, AI agents use large language models (LLMs) to reason, adapt, and respond intelligently to different situations.

### How is an AI agent different from a chatbot?

A chatbot mainly **responds to questions**, while an AI agent can **analyze data, make decisions, and perform tasks**. In this project, AI agents don‚Äôt just answer queries‚Äîthey analyze bank statements, detect spending patterns, and generate personalized financial advice.

### What is a multi-agent system?

A **multi-agent system** is a setup where multiple AI agents, each with a specific role, work together to solve a problem. Instead of one general-purpose agent, tasks are divided among specialized agents, resulting in better accuracy, scalability, and maintainability.

### Why use multiple AI agents instead of a single agent?

Using multiple AI agents improves results because of:
- 

**Specialization**: Each agent focuses on what it does best
- 

**Higher quality outputs**: Specialists outperform generalists
- 

**Scalability**: New agents can be added easily
- 

**Modularity**: Individual agents can be upgraded or replaced

This finance system uses one agent for **spending analysis** and another for **financial recommendations**, making insights more reliable.

### What does the Spending Analyst Agent do?

The **Spending Analyst Agent** processes transaction data and:
- 

Categorizes expenses (groceries, rent, dining, etc.)
- 

Identifies spending trends and patterns
- 

Calculates totals, averages, and percentages
- 

Detects large or unusual transactions

It focuses purely on **data analysis**, not advice.

### What does the Financial Advisor Agent do?

The **Financial Advisor Agent** takes the analyzed data and:
- 

Creates personalized budgeting suggestions
- 

Identifies saving opportunities
- 

Recommends spending improvements
- 

Generates a practical 30-day financial action plan

This agent focuses on **decision-making and guidance**, not raw analysis.

### What frameworks are used to build this AI finance agent?

This project uses:
- 

**CrewAI** for orchestrating multiple AI agents
- 

**LangChain** for interacting with large language models and tools
- 

**Streamlit** for building the web-based user interface

Together, these frameworks make it easy to build, manage, and scale multi-agent AI applications.

### Can this AI agent read PDF and Excel bank statements?

Yes. The system supports **CSV, Excel, and PDF** bank statements. It automatically detects the file type, extracts transactions, normalizes the data, and converts everything into a structured JSON format for analysis.

### Is my financial data stored or saved anywhere?

No. By default, the application processes data **in-memory only**. Your bank statement is analyzed during the session and not stored in any database unless you explicitly add storage features.

### Do I need coding experience to use this app?

To **use** the app, no coding experience is required. To **build or extend** the system, basic Python knowledge is helpful, especially for working with frameworks like Streamlit, LangChain, and CrewAI.

### Is an OpenAI API key required?

Yes. The system uses OpenAI models to power reasoning and PDF extraction. You‚Äôll need:
- 

An OpenAI account
- 

A valid API key
- 

A small budget (typically under $1 per analysis for testing)

### How much does it cost to run this AI finance agent?

Costs depend on usage, but typically:
- 

One bank statement analysis costs around **$0.10‚Äì$0.50**
- 

Costs can be reduced by caching results or using cheaper models for simpler tasks

You can set monthly spending limits in your OpenAI dashboard.

### Can this project be used in production?

Yes, with some enhancements. For production use, consider adding:
- 

Secure authentication
- 

Database storage
- 

Rate limiting
- 

Error monitoring
- 

API-based bank integrations

The current version is ideal for **learning, demos, and prototypes**.

### Can I add more AI agents to this system?

Absolutely. The architecture is designed for extension. You can easily add agents such as:
- 

Budget Tracking Agent
- 

Fraud or Anomaly Detection Agent
- 

Savings Goal Agent
- 

Long-term Trend Analysis Agent

This is one of the biggest advantages of a multi-agent design.

### What skills will I learn from this project?

By building this system, you learn:
- 

How AI agents work
- 

Multi-agent orchestration patterns
- 

Real-world LLM application design
- 

File processing and data normalization
- 

Prompt design and task decomposition
- 

Building AI-powered web apps

### Who is this project best suited for?

This project is ideal for:
- 

AI/ML engineers
- 

Product managers exploring AI agents
- 

Developers learning multi-agent systems
- 

Anyone building real-world LLM applications
- 

Learners transitioning from chatbots to agentic AI

If you‚Äôre interested in building **practical, real-world AI agents**, this finance agent is a great place to start üöÄ]]><![CDATA[Day 10 of building AI agents: Multi-Agent Competitor Analysis Agent using Crew AI]]>https://srilaxmi.substack.com/p/day-10-of-building-ai-agents-multihttps://srilaxmi.substack.com/p/day-10-of-building-ai-agents-multiFri, 09 Jan 2026 05:45:44 GMTIntroduction: What Are AI Agents?

### Understanding AI Agents

An **AI Agent** is an autonomous software entity that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to reason, plan, and execute tasks dynamically.

Think of an AI agent as a digital employee:
- 

**Traditional Program**: ‚ÄúIf X, do Y‚Äù (rigid, predefined)
- 

**AI Agent**: ‚ÄúAnalyze the situation, understand the goal, and figure out the best approach‚Äù (flexible, intelligent)

### Why Multi-Agent Systems?

A **multi-agent system** utilizes multiple specialized agents that work together, each with distinct roles and expertise. This approach offers several advantages:
- 

Specialization
- 

Parallel processing
- 

Modularity
- 

Scalability

### Real-World Analogy

Imagine a business consulting firm:
- 

**Research Agent** = Market researcher gathering data
- 

**Analysis Agent** = Strategic analyst interpreting findings
- 

**Report Agent** = Senior consultant synthesizing insights

Each has unique skills, but together they deliver comprehensive results.

## System Overview

Full GitHub code

### What We‚Äôre Building

A **Competitor Analysis System** that automatically:
- 

Discovers competitors in any industry
- 

Gathers data (pricing, features, reviews)
- 

Performs SWOT and competitive comparisons
- 

Generates executive-ready reports

### Key Features

- 

Automated research
- 

AI-powered SWOT analysis
- 

PDF export
- 

Streamlit web interface
- 

Configurable competitor depth

### **Agent Workflow**

- 

**Research Agent**:
- 

Searches for competitors using SerpAPI
- 

Gathers company information, pricing, and reviews
- 

Collects market positioning data
- 

Output: Structured competitor dataset

- 

**Analysis Agent**:
- 

Receives competitor data from Research Agent
- 

Performs SWOT analysis for each competitor
- 

Creates competitive comparison matrices
- 

Identifies market trends and gaps
- 

Output: Comprehensive competitive analysis

- 

**Report Agent**:
- 

Synthesizes research and analysis
- 

Generates an executive summary
- 

Creates strategic recommendations
- 

Identifies opportunities and threats
- 

Output: Final professional report

## Frameworks and Technologies

Full GitHub code

### CrewAI ‚Äî The Orchestration Layer

**What it is** CrewAI is a framework for orchestrating role-playing, autonomous AI agents in a collaborative environment.

**Why do we use it**
- 

Agent coordination
- 

Task sequencing
- 

Memory
- 

Tool integration
- 

Workflow control

**Core Concepts**
- 

Agents
- 

Tasks
- 

Crew
- 

Tools

### Streamlit ‚Äî The Interface

Streamlit enables rapid UI development using Python with built-in state management, widgets, and deployment support.

### OpenAI ‚Äî The Reasoning Engine

We use OpenAI GPT models for reasoning, analysis, and report synthesis.

**Model choice**
- 

`gpt-4-turbo-preview` ‚Üí complex reasoning
- 

`gpt-3.5-turbo` ‚Üí lighter tasks, lower cost

### SerpAPI ‚Äî Research Without Scraping

Provides structured Google search data safely and reliably.

### ReportLab ‚Äî PDF Generation

A pure-Python solution for generating professionally formatted PDF reports.

## Architecture Deep Dive

### System Architecture

```
Streamlit UI
     ‚Üì
CrewAI Orchestrator
     ‚Üì
Research Agent ‚Üí Analysis Agent ‚Üí Report Agent
     ‚Üì
PDF / UI Output

```

### The Three-Agent System

#### Research Agent üîé

Focuses on competitor discovery, pricing, reviews, and positioning.

#### Analysis Agent üìä

Performs SWOT, comparison matrices, and trend analysis.

#### Report Agent üìù

Synthesizes findings into executive-ready insights.

## Setting Up API Keys

### OpenAI API Key

- 

Create a key from the OpenAI dashboard
- 

Store in `.env`
- 

Never commit secrets

```
OPENAI_API_KEY=sk-xxxx

```

### SerpAPI Key

Free tier includes 100 searches/month.

```
SERPAPI_API_KEY=xxxx

```

## Code Structure Overview

```
Competitor analysis agent/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ agents.py
‚îú‚îÄ‚îÄ tasks.py
‚îú‚îÄ‚îÄ tools.py
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md

```

Each file has a **single responsibility**, making the system easy to extend and debug.

## How It Works: The Multi-Agent Workflow

### Phase-by-Phase Execution

- 

User inputs company and industry
- 

Agents are instantiated
- 

The research agent gathers data
- 

The analysis agent interprets findings
- 

The report agent generates insights
- 

UI renders results + export options

## Getting Started

### Prerequisites

- 

Python 3.9+
- 

OpenAI API key
- 

SerpAPI key

### Run Locally

```
pip install -r requirements.txt
streamlit run app.py

```

Open: 

http://localhost:8501

## Conclusion

### What We Built

A **production-ready multi-agent competitor analysis system** that automates research, analysis, and reporting with minimal human input.

### Key Takeaways

- 

Multi-agent systems scale better than monolithic prompts
- 

Clear agent roles reduce hallucination
- 

Tooling is as important as prompting
- 

UX matters even for internal AI tools

**Happy Building üöÄ**

_If this helped you understand multi-agent systems better, consider sharing it with others exploring agentic AI._

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

## Frequently Asked Questions (FAQ)

### What is a multi-agent system in AI?

A **multi-agent system** is an AI architecture in which multiple autonomous agents collaborate to achieve a shared goal. Each agent has a specific role (such as research, analysis, or reporting) and collaborates through an orchestration framework. Multi-agent systems are commonly used for complex workflows like competitor analysis, customer support, and research automation.

### How is an AI agent different from a chatbot?

A chatbot typically follows predefined conversation flows or single prompts, while an **AI agent** can reason, plan, use tools, and execute multi-step tasks autonomously. In this tutorial, each agent performs a specialized function‚Äîresearching competitors, analyzing data, or generating strategic reports‚Äîwithout manual intervention.

### Why use multiple AI agents instead of one large prompt?

Using multiple agents improves:
- 

**Accuracy** through specialization
- 

**Scalability** for complex workflows
- 

**Maintainability** by isolating responsibilities
- 

**Parallel processing** for faster execution

A single prompt struggles with long, multi-stage reasoning, while multi-agent systems handle complexity more reliably.

### What is CrewAI, and why is it used in this tutorial?

**CrewAI** is an AI agent orchestration framework that manages:
- 

Agent roles and goals
- 

Task sequencing and dependencies
- 

Memory and context sharing
- 

Tool usage

It simplifies building production-grade multi-agent systems without writing custom orchestration logic.

### Can this competitor analysis system be used for any industry?

Yes. The system is **industry-agnostic**. You can analyze competitors in:
- 

SaaS
- 

Fintech
- 

E-commerce
- 

Healthcare
- 

EdTech
- 

Consumer apps

The agents dynamically adapt their research and analysis based on the company and industry input.

### How accurate is AI-based competitor analysis?

Accuracy depends on:
- 

Quality of search data
- 

Prompt and agent design
- 

Tool reliability

This system reduces hallucinations by:
- 

Using real search APIs (SerpAPI)
- 

Separating research from analysis
- 

Structuring data before synthesis

It‚Äôs suitable for **strategic insights**, not legal or financial advice.

### What APIs are required to run this project?

You need:
- 

**OpenAI API** for reasoning and text generation
- 

**SerpAPI** for competitor research

Both offer free or low-cost tiers, making this system accessible for experimentation and small-scale use.

### How much does it cost to run this multi-agent system?

Typical costs depend on:
- 

Number of competitors analyzed
- 

Analysis depth
- 

LLM model used

Approximate range:
- 

Small analysis (2‚Äì3 competitors): a few cents to a few dollars
- 

Deep analysis (5 competitors): higher but still cost-effective compared to manual research

### Is this system production-ready?

Yes, the architecture is **production-oriented**:
- 

Modular agent design
- 

Clear task separation
- 

Error handling
- 

Exportable reports
- 

Configurable depth and limits

For large-scale use, you can add caching, databases, and job queues.

### Can I extend this system with more agents?

Absolutely. You can add:
- 

Pricing intelligence agents
- 

Sales positioning agents
- 

Product feature comparison agents
- 

Monitoring or alerting agents

The modular design makes extension straightforward.

### Do I need prior AI or ML experience to follow this tutorial?

Basic Python knowledge is helpful, but you **don‚Äôt need ML expertise**. The tutorial focuses on:
- 

System design
- 

Agent roles and workflows
- 

Practical implementation concepts

It‚Äôs suitable for product managers, founders, developers, and AI enthusiasts.

### How long does a full competitor analysis take?

Depending on depth:
- 

**Quick analysis**: 5‚Äì10 minutes
- 

**Standard analysis**: 10‚Äì20 minutes
- 

**Deep analysis**: 20‚Äì30 minutes

Most time is spent on research and synthesis, not UI rendering.

### Can this be used as an internal business intelligence tool?

Yes. Many teams use similar systems for:
- 

Strategy planning
- 

Market research
- 

Sales enablement
- 

Investor decks

You can run it internally or integrate it into existing dashboards.

### What are common challenges when building multi-agent systems?

Common challenges include:
- 

Hallucinations
- 

Task overlap between agents
- 

Poor tool integration
- 

Long execution times

This tutorial addresses them through clear agent boundaries, structured outputs, and tool-based grounding.

### Is this better than traditional market research tools?

It doesn‚Äôt replace professional research platforms, but it:
- 

Automates repetitive work
- 

Generates faster insights
- 

Adapts dynamically
- 

Costs significantly less

It‚Äôs ideal for **early-stage analysis, strategy exploration, and continuous monitoring**.

### 

]]><![CDATA[Day 9 of Building AI Agents: Building a Customer Support Agent with LangGraph]]>https://srilaxmi.substack.com/p/day-9-of-building-ai-agents-buildinghttps://srilaxmi.substack.com/p/day-9-of-building-ai-agents-buildingMon, 05 Jan 2026 05:43:59 GMT**Introduction**

In today‚Äôs fast-paced business environment, customer support has become a critical differentiator. Companies that respond quickly and accurately to customer inquiries gain a significant competitive advantage. However, scaling human support teams is expensive and challenging.

Enter AI agents‚Äîintelligent systems that can automate customer interactions while maintaining quality and consistency. In this comprehensive tutorial, we‚Äôll build a sophisticated customer support agent using LangGraph, a powerful framework for creating complex AI workflows.

Full Github code : fork the repo

## **Part 1: What is an AI Agent?**

### **Understanding AI Agents**

An **AI agent** is an autonomous software system that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike simple chatbots that follow rigid scripts, AI agents use large language models (LLMs) to understand context, reason about problems, and generate appropriate responses.

### **Key Characteristics of AI Agents**

- 

**Autonomy**: They can operate independently without constant human intervention
- 

**Reactivity**: They respond to changes in their environment (like new customer queries)
- 

**Proactivity**: They can take initiative when appropriate
- 

**Social Ability**: They interact with users in natural language
- 

**Goal-Oriented**: They work towards specific objectives (like resolving customer issues)

### **Types of AI Agents**

- 

**Simple Reflex Agents**: React to current situations based on predefined rules
- 

**Model-Based Agents**: Maintain internal models of the world
- 

**Goal-Based Agents**: Work towards achieving specific goals
- 

**Utility-Based Agents**: Optimize for the best outcome
- 

**Learning Agents**: Improve performance over time

Our customer support agent is a **goal-based agent** that uses a graph-based workflow to process customer queries intelligently.

## **Part 2: Why Build This Customer Support Agent?**

Full Github code : fork the repo

### **Current Implementation Scope**

**Important**: The current implementation is a foundational customer support agent that:
- 

Uses OpenAI‚Äôs LLM with general knowledge (no company-specific documentation)
- 

Does NOT include RAG (Retrieval-Augmented Generation) capabilities
- 

Provides a framework that can be extended with RAG and other features

This makes it perfect for learning LangGraph and as a starting point for building more sophisticated agents.

### **The Problem**

Traditional customer support faces several challenges:
- 

**High Volume**: Companies receive thousands of queries daily
- 

**24/7 Expectations**: Customers expect round-the-clock support
- 

**Consistency**: Ensuring all agents provide accurate, consistent information
- 

**Cost**: Scaling human support teams is expensive
- 

**Response Time**: Long wait times frustrate customers

### **The Solution**

Our AI agent addresses these challenges by:
- 

**Automating Routine Queries**: Handling common questions instantly
- 

**Categorizing Issues**: Automatically routing queries to appropriate handlers
- 

**Sentiment Analysis**: Identifying frustrated customers for priority escalation
- 

**Consistent Responses**: Providing accurate, uniform information every time
- 

**Scalability**: Handling unlimited queries without additional cost

### **Real-World Impact**

- 

**Reduced Response Time**: From hours to seconds
- 

**Cost Savings**: Automating 60-80% of routine queries
- 

**Improved Satisfaction**: Instant responses improve customer experience
- 

**Human Focus**: Agents can focus on complex issues requiring human judgment

## **Part 3: Understanding LangGraph**

### **What is LangGraph?**

**LangGraph** is a library for building stateful, multi-actor applications with LLMs. It extends LangChain by adding:
- 

**State Management**: Maintains context throughout the conversation
- 

**Graph-Based Workflows**: Visual representation of agent logic
- 

**Conditional Routing**: Dynamic decision-making based on state
- 

**Cycles and Loops**: Support for iterative processes

### **Why LangGraph for Customer Support?**

- 

**Complex Workflows**: Customer support requires multiple steps (categorize ‚Üí analyze ‚Üí respond)
- 

**State Management**: Need to track query, category, sentiment, and response
- 

**Conditional Logic**: Different paths based on query type and sentiment
- 

**Extensibility**: Easy to add new handlers or modify workflow

### **Our Workflow Architecture**

Full Github code : fork the repo

```
Customer Query
    ‚Üì
[Categorize] ‚Üí Technical, Billing, or General
    ‚Üì
[Analyze Sentiment] ‚Üí Positive, Neutral, or Negative
    ‚Üì
[Route Query] ‚Üí Decision point
    ‚îú‚îÄ Negative ‚Üí [Escalate to Human]
    ‚îú‚îÄ Technical ‚Üí [Handle Technical]
    ‚îú‚îÄ Billing ‚Üí [Handle Billing]
    ‚îî‚îÄ General ‚Üí [Handle General]
    ‚Üì
[Generate Response]

```

## **Part 4: Project Structure and Files**

Let‚Äôs explore the codebase at a high level to understand how everything fits together.

### **File Overview**

Our customer support agent consists of several key files, each serving a specific purpose:

#### **1. **`app.py`** - The Main Application**

**Purpose**: Contains the core agent logic and workflow definition.

**Key Components**:
- 

**State Definition**: `State` TypedDict that holds query information throughout the workflow
- 

**Node Functions**: Individual processing steps (categorize, analyze_sentiment, handle_technical, etc.)
- 

**Graph Construction**: Builds the LangGraph workflow with nodes and edges
- 

**Main Execution**: CLI interface for running queries

**What it does**:
- 

Defines the workflow structure
- 

Implements each processing step
- 

Compiles the graph into an executable application
- 

Provides command-line interface for testing

**Note**: This file does NOT include RAG functionality. It uses only the LLM‚Äôs general knowledge. See Part 6 for how to add RAG capabilities.

#### **2. **`config.py`** - Configuration Management**

**Purpose**: Handles environment variables and configuration settings.

**Key Components**:
- 

Loads environment variables from `.env` file
- 

Validates required configuration (like API keys)
- 

Provides configuration validation function

**What it does**:
- 

Centralizes configuration management
- 

Ensures required settings are present before execution
- 

Makes it easy to manage different environments

#### **3. **`requirements.txt`** - Dependencies**

**Purpose**: Lists all Python packages required for the project.

**Dependencies**:
- 

`langgraph`: Graph-based workflow orchestration
- 

`langchain-core`: Core LangChain functionality
- 

`langchain-openai`: OpenAI integration
- 

`python-dotenv`: Environment variable management

**What it does**:
- 

Ensures consistent environment across installations
- 

Makes dependency management simple with `pip install -r requirements.txt`

#### **4. **`.env.example`** - Environment Template**

**Purpose**: Template for environment variables.

**Contents**:
- 

`OPENAI_API_KEY`: Placeholder for OpenAI API key

**What it does**:
- 

Shows what environment variables are needed
- 

Provides a template for users to create their own `.env` file

#### **5. **`README.md`** - Documentation**

**Purpose**: Comprehensive project documentation.

**Contents**:
- 

Project overview and features
- 

Installation instructions
- 

Usage examples
- 

Architecture explanation
- 

Customization guide

**What it does**:
- 

Helps users understand and use the project
- 

Provides examples and troubleshooting tips

### **How Files Work Together**

```
User runs: python app.py "query"
    ‚Üì
app.py loads config.py ‚Üí Validates API key
    ‚Üì
app.py creates workflow ‚Üí Uses LangGraph
    ‚Üì
Workflow processes query ‚Üí Through nodes
    ‚Üì
Returns result ‚Üí Category, Sentiment, Response

```

## **Part 5: How the Agent Works**

### **Step-by-Step Process**

- 

**Input**: Customer query is received
- 

**Categorization**: Query is classified as Technical, Billing, or General
- 

**Sentiment Analysis**: Emotional tone is determined (Positive, Neutral, Negative)
- 

**Routing**: Based on sentiment and category, query is routed to appropriate handler
- 

**Response Generation**: Handler generates contextually appropriate response
- 

**Output**: Customer receives categorized, sentiment-analyzed response

### **Decision Logic**

The agent uses conditional routing:
- 

**If sentiment is Negative** ‚Üí Escalate to human agent
- 

**Else if category is Technical** ‚Üí Route to technical handler
- 

**Else if category is Billing** ‚Üí Route to billing handler
- 

**Else** ‚Üí Route to general handler

This ensures that frustrated customers get immediate human attention while routine queries are handled automatically.

Full Github code : fork the repo

## **Part 6: Adding Company Documentation (RAG Pipeline)**

### **Important Note**

‚ö†Ô∏è ** The current code implementation does NOT include RAG.** This section explains how you can add RAG functionality to enhance the agent with your company‚Äôs documentation. The existing code uses only the LLM‚Äôs general knowledge without any document retrieval capabilities.

### **Why Add Company Docs?**

Currently, the agent uses only the LLM‚Äôs general knowledge. To make it truly useful, we need to integrate your company‚Äôs specific documentation, policies, and knowledge base. This requires implementing a RAG (Retrieval-Augmented Generation) pipeline, which is not included in the current codebase.

### **What is RAG?**

**RAG (Retrieval-Augmented Generation)** is a technique that:
- 

**Retrieves** relevant information from your documents
- 

**Augments** the LLM prompt with this context
- 

**Generates** responses using both general knowledge and your specific information

### **How RAG Works**

```
Customer Query
    ‚Üì
[Embed Query] ‚Üí Convert to vector representation
    ‚Üì
[Search Vector DB] ‚Üí Find similar document chunks
    ‚Üì
[Retrieve Top-K Chunks] ‚Üí Get most relevant information
    ‚Üì
[Combine with Query] ‚Üí Create augmented prompt
    ‚Üì
[LLM Generation] ‚Üí Response using company docs

```

### **Implementation Steps**

**Note**: The following steps are NOT implemented in the current code. They represent what you would need to do to add RAG functionality.

To add RAG to this agent, you would need to:
- 

**Document Ingestion**:
- 

Load company documents (PDFs, text files, markdown)
- 

Split into chunks (typically 500-1000 characters)
- 

Generate embeddings for each chunk
- 

Store in vector database

- 

**Retrieval System**:
- 

Convert customer query to embedding
- 

Search vector database for similar chunks
- 

Retrieve top-K most relevant chunks

- 

**Integration**:
- 

Modify handler functions to include retrieved context
- 

Update prompts to use company-specific information
- 

Ensure responses reference your documentation

- 

**Vector Database Options**:
- 

**ChromaDB**: Simple, in-memory or persistent
- 

**FAISS**: Facebook‚Äôs vector similarity search
- 

**Qdrant**: Production-ready vector database
- 

**Pinecone**: Managed vector database service

### **Example Integration (Not in Current Code)**

**This is example code showing how you COULD modify the agent to include RAG. This is not part of the current implementation.**

Here‚Äôs how you would modify a handler function to use RAG:

```
def handle_technical(state: State) -> State:
    # Retrieve relevant documentation
    relevant_docs = vector_db.search(state[‚Äùquery‚Äù], top_k=3)
    
    # Create augmented prompt
    prompt = ChatPromptTemplate.from_template(
        ‚ÄúUsing the following company documentation:\n{context}\n\n‚Äù
        ‚ÄúProvide a technical support response to: {query}‚Äù
    )
    
    # Generate response with context
    chain = prompt | ChatOpenAI(temperature=0)
    response = chain.invoke({
        ‚Äúquery‚Äù: state[‚Äùquery‚Äù],
        ‚Äúcontext‚Äù: ‚Äú\n‚Äù.join(relevant_docs)
    }).content
    
    return {‚Äùresponse‚Äù: response}
```

### **Benefits of Adding RAG**

- 

**Accurate Information**: Responses based on your actual documentation
- 

**Consistency**: All responses align with company policies
- 

**Up-to-Date**: Easy to update by adding new documents
- 

**Brand Voice**: Maintains your company‚Äôs communication style

## **Part 7: Installation and Setup**

### **Prerequisites**

- 

Python 3.8 or higher
- 

OpenAI API key
- 

pip package manager

### **Step-by-Step Installation**

- 

**Navigate to the project directory**:

```
cd ‚Äúagents/customer support‚Äù
```

- 

**Install dependencies**:

```
pip install -r requirements.txt
```

- 

**Set up environment variables**:

```
cp .env.example .env
```

- 

Then edit `.env` and add your OpenAI API key:

```
OPENAI_API_KEY=your_actual_api_key_here

```

- 

**Verify installation**:

```
python app.py
```

### **Running the Agent**

**With example queries**:

```
python app.py
```

**With your own query**:

```
python app.py ‚ÄúYour customer question here‚Äù
```

## **Part 8: Usage Examples**

### **Example 1: Technical Query**

```
python app.py ‚ÄúHow do I reset my password?‚Äù
```

**Result**:
- 

Category: Technical
- 

Sentiment: Neutral
- 

Response: Step-by-step password reset instructions

### **Example 2: Billing Query**

```
python app.py ‚ÄúWhere can I find my receipt?‚Äù
```

**Result**:
- 

Category: Billing
- 

Sentiment: Neutral
- 

Response: Instructions on accessing receipts

### **Example 3: Escalation Case**

```
python app.py ‚ÄúThis is terrible! I want a refund now!‚Äù
```

**Result**:
- 

Category: Billing
- 

Sentiment: Negative
- 

Response: Escalated to human agent

## **Part 9: Customization and Extension**

### **Customizing Categories**

To add new categories (e.g., ‚ÄúShipping‚Äù):
- 

Update the `categorize()` function prompt
- 

Add a new handler function `handle_shipping()`
- 

Update `route_query()` to include the new category
- 

Add the new node to the graph

### **Modifying Sentiment Analysis**

To change sentiment thresholds or add more granular sentiment:
- 

Update the `analyze_sentiment()` function prompt
- 

Modify `route_query()` to handle new sentiment levels
- 

Add corresponding routing logic

### **Adding New Handlers**

To add a new handler for a specific query type:
- 

Create a new function following the pattern:

```
def handle_new_type(state: State) -> State:
    prompt = ChatPromptTemplate.from_template(
        ‚ÄúProvide response for: {query}‚Äù
    )
    chain = prompt | ChatOpenAI(temperature=0)
    response = chain.invoke({‚Äùquery‚Äù: state[‚Äùquery‚Äù]}).content
    return {‚Äùresponse‚Äù: response}
```

- 

Add node to graph: `workflow.add_node("handle_new_type", handle_new_type)`
- 

Update routing logic in `route_query()`

## **Part 10: Best Practices and Tips**

### **1. Prompt Engineering**

- 

**Be Specific**: Clear instructions produce better results
- 

**Use Examples**: Few-shot examples improve accuracy
- 

**Set Temperature**: Use `temperature=0` for consistent, factual responses

### **2. Error Handling**

- 

Always validate API keys before execution
- 

Handle API rate limits gracefully
- 

Provide helpful error messages to users

### **3. Monitoring**

- 

Log all queries and responses
- 

Track categorization accuracy
- 

Monitor sentiment distribution
- 

Measure response quality

### **4. Security**

- 

Never expose API keys in code
- 

Use environment variables
- 

Validate user inputs
- 

Sanitize outputs if displaying in web interfaces

### **5. Performance**

- 

Cache common responses
- 

Batch similar queries
- 

Use streaming for long responses
- 

Monitor API costs

## **Part 11: Future Enhancements**

### **Potential Improvements**

- 

**Multi-Language Support**: Add translation capabilities
- 

**Voice Integration**: Support voice queries and responses
- 

**Analytics Dashboard**: Visualize query patterns and trends
- 

**A/B Testing**: Compare different prompt strategies
- 

**Learning System**: Improve from feedback
- 

**Integration**: Connect to ticketing systems, CRM, etc.
- 

**Web Interface**: Build a user-friendly web UI
- 

**API Endpoint**: Expose as REST API for integration

### **Scaling Considerations**

- 

**Rate Limiting**: Implement to prevent abuse
- 

**Caching**: Cache frequent queries
- 

**Load Balancing**: Distribute load across instances
- 

**Database**: Store conversation history
- 

**Monitoring**: Track performance metrics

## **Part 12: Conclusion**

### **What We‚Äôve Built**

We‚Äôve created a foundational customer support agent that:
- 

Automatically categorizes customer queries
- 

Analyzes sentiment to prioritize urgent issues
- 

Routes queries to appropriate handlers
- 

Generates contextually appropriate responses using LLM general knowledge
- 

Escalates complex or negative cases to humans

**Note**: The current implementation does NOT include RAG. It uses OpenAI‚Äôs general knowledge. To add company-specific documentation, you would need to implement the RAG pipeline described in Part 6.

### **Key Takeaways**

- 

**AI Agents** can automate complex workflows using graph-based architectures
- 

**LangGraph** provides powerful tools for building stateful AI applications
- 

**RAG** enables agents to use company-specific knowledge
- 

**Modular Design** makes it easy to extend and customize

### **Next Steps**

- 

Test the agent with your own queries
- 

Customize categories and handlers for your use case
- 

Consider adding RAG for company-specific information
- 

Integrate with your existing support systems
- 

Monitor and iterate based on real-world usage

### **Resources**

- 

LangGraph Documentation
- 

LangChain Documentation
- 

OpenAI API Documentation

## **Appendix: Common Questions**

### **Q: Can I use a different LLM provider?**

A: Yes! LangChain supports multiple providers. Replace `ChatOpenAI` with `ChatAnthropic`, `ChatCohere`, or others.

### **Q: How do I handle multiple languages?**

A: Add a language detection step before categorization, then use language-specific prompts or translation.

### **Q: Can I deploy this to production?**

A: Yes, but consider adding error handling, logging, rate limiting, and monitoring first.

### **Q: How much does this cost?**

A: Costs depend on API usage. OpenAI charges per token. Monitor usage and set budgets.

### **Q: Is my data secure?**

A: Data is sent to OpenAI‚Äôs API. Review their privacy policy and consider on-premise solutions for sensitive data.

_Happy building! If you have questions or want to share your implementation, feel free to reach out._]]><![CDATA[Day 8 of Building AI Agents : Building a News TL;DR Agent with LangGraph ]]>https://srilaxmi.substack.com/p/day-8-of-building-ai-agents-buildinghttps://srilaxmi.substack.com/p/day-8-of-building-ai-agents-buildingFri, 02 Jan 2026 06:20:23 GMTWelcome to **Day 8** of the _30 Days of Building AI Agents_ series.

Today, we build something that looks **very close to how real AI agent systems work in production**.

Not a clever prompt. Not a linear script.

üëâ **A stateful, decision-making AI agent that can adapt while it runs.**

_**Github repo - Full Code **_

## **What Are AI Agents (Quick Recap)**

An **AI agent** is not just an LLM call.

An agent is a system that can:
- 

Understand intent
- 

Decide _what to do next_
- 

Use tools
- 

Evaluate intermediate results
- 

Change strategy if needed
- 

Stop when a goal is met

Traditional software executes instructions. Agents **reason through a workflow**.

## **Why News Is a Perfect Agent Problem**

News summarization sounds simple‚Äîuntil you break it down:
- 

Users ask vague questions
- 

News changes constantly
- 

Headlines are misleading
- 

Summaries without full text are low quality
- 

One search attempt is often not enough

This makes news summarization a **multi-step, decision-heavy task**‚Äîexactly where agents shine.

## **What We‚Äôre Building**

A **News TL;DR Agent** that can:
- 

Accept a natural language query
- 

Convert intent into structured search logic
- 

Query multiple news sources
- 

Scrape full article text
- 

Decide whether results are sufficient
- 

Retry intelligently if needed
- 

Select the most relevant articles
- 

Generate concise bullet-point summaries

All orchestrated using **LangGraph**.

## **High-Level Architecture**

The system has **three clearly separated layers**:

### 1Ô∏è‚É£ Intelligence Layer

Handled by **OpenAI** models:
- 

Understanding intent
- 

Generating search parameters
- 

Selecting relevant articles
- 

Summarizing content

### 2Ô∏è‚É£ Tooling Layer

Concrete execution:
- 

NewsAPI ‚Üí article discovery
- 

Web scraping ‚Üí full text
- 

Streamlit ‚Üí user interface

### 3Ô∏è‚É£ Orchestration Layer

Handled by LangGraph:
- 

State management
- 

Conditional routing
- 

Looping and termination

This separation is critical for scaling real agent systems.

## **LangGraph Explained **

Most explanations stop at:

‚ÄúLangGraph lets you build graphs with LLMs.‚Äù

That‚Äôs incomplete.

### **What LangGraph Actually Is**

LangGraph is a framework for building **state machines for LLM systems**.

It lets you combine:
- 

**Deterministic control flow**
- 

**Probabilistic LLM reasoning**

In simple terms:

**LangGraph = explicit state + explicit decisions + explicit flow**

## **Why LangGraph Exists**

LLMs are stateless. Every call forgets what happened before.

Real systems need:
- 

Memory
- 

Loops
- 

Retry logic
- 

Stop conditions
- 

Inspectability

LangGraph provides all of that.

## **The Three Core LangGraph Primitives**

Github repo - Codebase 

### **1Ô∏è‚É£ State (Shared Memory)**

State is the **single source of truth** for the entire agent run.

Conceptually:

```
GraphState = {
  "news_query": str,
  "search_attempts_left": int,
  "newsapi_params": dict,
  "articles_metadata": list,
  "scraped_articles": list,
  "selected_articles": list,
  "summaries": list,
  "final_output": str
}

```

Every node:
- 

Reads from state
- 

Updates state
- 

Passes it forward

Why this matters:
- 

Easy debugging
- 

Easy replay
- 

Easy evaluation
- 

Easy extension (memory, scoring, feedback)

### **2Ô∏è‚É£ Nodes (Pure Functions)**

A node is just:

```
(state) ‚Üí (updated state)

```

Examples:
- 

Generate search parameters
- 

Fetch article metadata
- 

Scrape article text
- 

Select best articles
- 

Summarize

Each node should:
- 

Do **one thing**
- 

Be replaceable
- 

Be easy to test

If a node needs a paragraph to explain, it‚Äôs too big.

### **3Ô∏è‚É£ Edges (Control Flow)**

Edges define **what runs next**.

There are:
- 

Normal edges (A ‚Üí B)
- 

Conditional edges (decision-based routing)

This is where _agent behavior_ emerges.

## **The Agent Workflow **

### **Step 1: Intent ‚Üí Search Parameters (LLM)**

The agent asks the LLM:

‚ÄúGiven this user query and previous attempts, what‚Äôs the best next NewsAPI search?‚Äù

This avoids:
- 

Hardcoded keywords
- 

Brittle heuristics

LLMs are excellent at translating vague intent into structured queries.

### **Step 2: Retrieve Article Metadata (NewsAPI)**

Using **NewsAPI**, we fetch:
- 

Titles
- 

Descriptions
- 

URLs
- 

Publish dates

At this stage:
- 

No summarization
- 

No relevance decisions

Cheap and fast.

### **Step 3: Scrape Full Article Text**

News APIs rarely return full content.

So the agent:
- 

Fetches each URL
- 

Parses HTML
- 

Extracts clean text

Failures are tolerated. The agent keeps going.

### **Step 4: Decision Point (Critical)**

The agent checks:
- 

Do I have enough usable articles?
- 

Do I still have search attempts left?

If not enough signal:
- 

It loops back
- 

Generates a _new_ search strategy

This is the moment the system becomes an **agent**, not a script.

### **Step 5: Select Best Articles (LLM)**

The LLM now sees:
- 

Full text
- 

Titles + descriptions
- 

Original user intent

It selects the most relevant articles semantically‚Äînot via keywords.

### **Step 6: Summarize (LLM, Parallel)**

Each selected article is summarized independently:
- 

Bullet points
- 

Signal over noise
- 

No filler

Parallelization keeps things fast.

### **Step 7: Format for Humans**

Final step:
- 

Clean formatting
- 

Headings
- 

Readable output

Agents shouldn‚Äôt just think well‚Äîthey should communicate well.

## **Project Structure **

Github repo - Codebase 

```
news-tldr-agent/
‚îú‚îÄ‚îÄ agents.py        # LangGraph nodes + graph
‚îú‚îÄ‚îÄ tools.py         # NewsAPI & scraping
‚îú‚îÄ‚îÄ config.py        # API keys & setup
‚îú‚îÄ‚îÄ utils.py         # Models & helpers
‚îú‚îÄ‚îÄ main.py          # CLI runner
‚îú‚îÄ‚îÄ streamlit_app.py # UI

```

Design rule:

**LLMs, tools, and orchestration must be separate.**

This enables:
- 

Testing
- 

Reuse
- 

Team development
- 

Scaling to larger systems

## **API Keys: Complete Setup **

### **You Need Two Keys**

- 

OpenAI (LLM)
- 

NewsAPI (news discovery)

### **OpenAI API Key**

- 

Go to 

https://platform.openai.com/
- 

Log in or sign up
- 

Click profile ‚Üí **API Keys**
- 

Create a new secret key
- 

Copy it immediately
- 

Add billing (required)

Key format:

```
sk-xxxxxxxxxxxxxxxx

```

### **NewsAPI Key**

- 

Go to 

https://newsapi.org/
- 

Click **Get API Key**
- 

Sign up
- 

Copy your key from the dashboard

Free tier:
- 

100 requests/day
- 

Articles from last 1‚Äì30 days

Perfect for this project.

### **Wiring Keys into the Project**

Create a `.env` file:

```
OPENAI_API_KEY=sk-your-key
NEWSAPI_KEY=your-newsapi-key

```

Load them in `config.py`:

```
from dotenv import load_dotenv
import os

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")

```

Add `.env` to `.gitignore`. Never commit keys.

## **Running the Agent**

### CLI

```
python main.py "AI news today"

```

### Streamlit UI

```
streamlit run streamlit_app.py

```

Watch how:
- 

Searches evolve
- 

Decisions are made
- 

Articles are filtered
- 

Summaries are produced

## **Why This Pattern Matters**

This architecture generalizes to:
- 

Research assistants
- 

Market intelligence agents
- 

Competitive analysis tools
- 

Strategy copilots
- 

Monitoring & alerting agents

Swap tools. Swap prompts.

The **orchestration stays the same**.

## **Key Takeaways**

- 

LangGraph gives explicit control over reasoning flows
- 

State makes agents debuggable and extensible
- 

LLMs should decide _what_, not _when_
- 

Conditional routing is what creates intelligence

## **Day 8 Complete ‚úÖ**

You now understand:
- 

How LangGraph actually works
- 

How real agents are structured
- 

How to manage state, decisions, and tools
- 

How to wire everything cleanly

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

]]><![CDATA[Day 7 of Building an AI Agents - AI Deep Research Agent]]>https://srilaxmi.substack.com/p/day-7-of-building-an-ai-agents-aihttps://srilaxmi.substack.com/p/day-7-of-building-an-ai-agents-aiWed, 31 Dec 2025 04:07:47 GMT**‚ö†Ô∏è Before You Start (Important)**

This project **requires basic Python understanding**.

You should be comfortable with:
- 

Python functions
- 

Variables, lists, dictionaries
- 

Reading `.py` files without panic
- 

Installing packages with `pip`
- 

Running a Python app from the terminal

üëâ You do **not** need to be an advanced Python engineer üëâ You **do** need to be comfortable _reading and tweaking code_

If Python is completely new, pause here and do a **1‚Äì2 hour Python crash course** first.

## **üßë‚Äçüíª Step 0: Use a Proper IDE (This Matters)**

You _can_ open this project anywhere. However, for the **best learning experience**, consider using an AI-native IDE.

### **‚úÖ Recommended: Cursor**

Cursor is one of the best IDEs today for AI-first development.

Why Cursor is perfect here:
- 

It understands your **entire repository**
- 

You can ask: _‚ÄúExplain this file.‚Äù_
- 

You can say: _‚ÄúRefactor this agent.‚Äù_
- 

You can debug multi-agent logic conversationally
- 

It‚Äôs built for reasoning across files, not just autocomplete

üëâ Download:

https://cursor.sh

## **üç¥ Step 1: Fork the Repository**

Do **not** clone directly.
- 

Open the GitHub repository **[Codebase]**
- 

Click **Fork**
- 

Fork into your own GitHub account
- 

Clone _your fork_ locally

This is how real developers work:
- 

safe experimentation
- 

clean version control
- 

freedom to extend

# **Understanding the Codebase**

Before running anything, **pause**.

Day 7 is not about ‚Äúgetting output fast.‚Äù It‚Äôs about understanding **how AI agents are designed**.

A typical structure of this repo looks like:

**[Codebase]**

## Introduction: What is an AI Agent? 

### What is an AI Agent?

An **AI Agent** is an autonomous software system that can:
- 

Understand a goal
- 

Decide what actions to take
- 

Use tools to gather information
- 

Execute tasks step by step
- 

Produce a final outcome without constant user input

Unlike a chatbot that only responds to messages, an AI agent **acts**.

Think of it as a digital worker that doesn‚Äôt just answer questions, but **completes jobs**.

### Key Characteristics of AI Agents

A true AI agent has the following properties:
- 

**Autonomy** Once started, it can continue working without repeated prompts.
- 

**Goal-Oriented** It works toward a defined outcome (for example: ‚Äúgenerate a research report‚Äù).
- 

**Reactive** It can respond to new information, errors, or partial results.
- 

**Proactive** It can decide what to do next instead of waiting for instructions.
- 

**Tool-Using** It can call APIs, search the web, read files, or write outputs.

### Real-World Analogy

Imagine hiring a human research analyst.

You don‚Äôt tell them:

‚ÄúSearch Google now.‚Äù

You tell them:

‚ÄúResearch this topic and give me a report.‚Äù

They:
- 

Decide what questions matter
- 

Search multiple sources
- 

Read and filter information
- 

Synthesize insights
- 

Present a structured report

That‚Äôs **exactly** what our AI Research Agent will do ‚Äî just automatically and much faster.

### Why Build an AI Agent?

Traditional chatbots:
- 

Answer one question at a time
- 

Forget context easily
- 

Don‚Äôt use tools unless explicitly told

AI agents:
- 

Break complex tasks into steps
- 

Use tools automatically
- 

Coordinate multiple actions
- 

Produce complete workflows end-to-end

This is why **real AI products today are agent-based**, not prompt-based.

## Understanding the Frameworks 

Before writing code, it‚Äôs important to understand **why each tool exists** in this project.

### 1. **Agno Framework** ‚Äì The Agent Orchestrator

**What is Agno?** Agno is a Python framework designed specifically to build **LLM-powered agents**.

Instead of writing messy glue code, Agno lets you define:
- 

What an agent‚Äôs role is
- 

What model does it use
- 

What instructions guide it
- 

How does it run safely

**Why Agno?**
- 

Simple and readable API
- 

Designed for agent workflows (not chat apps)
- 

Easy tool integration
- 

Built-in support for timeouts and failures
- 

Production-friendly patterns

**Key Agno Concepts**
- 

**Agent** ‚Üí a role-focused worker
- 

**Model** ‚Üí the LLM doing reasoning
- 

**Instructions** ‚Üí system-level behavior rules
- 

**Run** ‚Üí executing the agent with input

### 2. **OpenAI API** ‚Äì The Brain

The language model is the **reasoning engine** of the agent.

It is responsible for:
- 

Generating research questions
- 

Understanding search results
- 

Synthesizing insights
- 

Writing professional reports

Important idea:

The LLM **does not fetch data**. It **reasons over data** provided by tools.

### 3. **Streamlit** ‚Äì The User Interface

Streamlit allows us to build a working UI using only Python.

It:
- 

Collects user input (topic, domain, settings)
- 

Shows progress
- 

Displays results
- 

Allows downloads

Why Streamlit works well here:
- 

No frontend complexity
- 

Fast iteration
- 

Perfect for internal tools and prototypes

### 4. **SerpApi** ‚Äì The Search Engine

SerpApi gives programmatic access to **Google Search results**.

Why this matters:
- 

Scraping Google is unreliable and unsafe
- 

SerpApi provides clean JSON results
- 

Includes links, snippets, and metadata

This is how our agent accesses **real-world information**.

### 5. **Perplexity AI (Optional)** ‚Äì Enhanced Search

Perplexity provides AI-synthesized answers across multiple sources.

Used optionally to:
- 

Improve context
- 

Add alternative perspectives
- 

Enhance research depth

## Project Overview 

### What We‚Äôre Building

A **Market Research Agent** that:
- 

Accepts a research topic and domain
- 

Generates relevant research questions
- 

Searches multiple sources automatically
- 

Analyzes and synthesizes findings
- 

Compiles a structured research report
- 

Exports results in multiple formats

### Key Features

- 

Smart question generation
- 

Multi-source research
- 

Parallel execution for speed
- 

Professional report writing
- 

Export to PDF / Markdown / JSON
- 

Session-based research history

### Technology Stack Summary

```
Frontend: Streamlit
Backend: Python
Agent Framework: Agno
LLM: OpenAI GPT-4
Search: SerpApi, Perplexity (optional)
Exports: ReportLab

```

## Step-by-Step Build Process 

### Step 1: Environment Setup

#### 1.1 Create a Virtual Environment

```
mkdir market-research-agent
cd market-research-agent
python -m venv venv
source venv/bin/activate

```

**Why this matters:** Virtual environments prevent dependency conflicts and keep your project isolated.

#### 1.2 Install Dependencies

```
pip install agno>=2.2.10 streamlit openai requests reportlab python-dotenv

```

Each package has a clear purpose:
- 

`agno` ‚Üí agent orchestration
- 

`streamlit` ‚Üí UI
- 

`openai` ‚Üí LLM access
- 

`requests` ‚Üí API calls
- 

`reportlab` ‚Üí PDF exports
- 

`python-dotenv` ‚Üí API key management

### Step 2: Project Structure

```
market-research-agent/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ README.md

```

This minimal structure helps you **focus on logic, not boilerplate**.

### Step 3: Understanding Agent Architecture

We use **three agents**, each with a single responsibility.

#### 3.1 Question Generator Agent

**Purpose:** Convert a topic into structured research questions.

**Flow:**
- 

Receives topic + domain
- 

Uses LLM reasoning
- 

Outputs 3‚Äì10 research questions

This agent **defines the scope** of the entire system.

#### 3.2 Research Agent

**Purpose:** Answer _one_ question using real data.

**Flow:**
- 

Receives a question
- 

Searches Google via SerpApi
- 

Optionally queries Perplexity
- 

Synthesizes results using the LLM
- 

Returns an answer with citations

Each question runs **independently**.

#### 3.3 Report Compiler Agent

**Purpose:** Turn raw answers into a professional report.

**Flow:**
- 

Receives all Q&A pairs
- 

Structures the content
- 

Writes executive summary + analysis
- 

Formats output cleanly

This agent transforms **analysis into communication**.

### Step 4‚Äì8 (High-Level Logic)

- 

Agents are created with clear instructions
- 

Research runs in parallel using async
- 

Errors are handled gracefully
- 

Results are stored in the session state
- 

The final output is exported

## Key Concepts Explained 

### Agent Instructions

Instructions define **how an agent behaves**, not just what it does.

They specify:
- 

Role
- 

Tone
- 

Output format
- 

Constraints

Better instructions = better results.

### Agent Orchestration

Orchestration is the **sequence and coordination** of agents.

```
User Input
‚Üí Question Generator
‚Üí Parallel Research Agents
‚Üí Report Compiler
‚Üí Final Output

```

This pattern is reusable across domains.

### Tool Integration

Agents:
- 

Don‚Äôt ‚Äúknow‚Äù facts
- 

Call tools
- 

Reason over results

LLMs are thinkers, not databases.

### Asynchronous Processing

Parallel execution dramatically improves speed.

Instead of:
- 

Question 1 ‚Üí wait
- 

Question 2 ‚Üí wait

We run **all questions simultaneously**.

### State Management

State allows:
- 

Multi-step workflows
- 

Progress tracking
- 

Export functionality
- 

Research history

Without a state, agents cannot behave like systems.

## Architecture Deep Dive 

### Data Flow Summary

- 

User enters topic
- 

Questions are generated
- 

Research runs in parallel
- 

Answers are synthesized
- 

The report is compiled
- 

Results are displayed and exported

Each layer has a **single responsibility**.

## Deployment and Usage 

### Local Development

```
git clone https://github.com/SriLaxmi1993/Generative-AI-Projects.git
cd Generative-AI-Projects/agents/Market_Research_agent
pip install -r requirements.txt
streamlit run app.py

```

### Usage Flow

- 

Enter API keys
- 

Define topic and domain
- 

Generate questions
- 

Run research
- 

Compile report
- 

Export results

## Conclusion 

### What You Learned

By completing this tutorial, you learned:
- 

How real AI agents are structured
- 

How tools and LLMs work together
- 

How orchestration enables scale
- 

How async improves performance
- 

How AI products are actually built

### Final Takeaway

If you understand this project, you are no longer:
- 

‚ÄúUsing AI‚Äù
- 

‚ÄúPrompting models‚Äù

You are **building AI Agents**.

That‚Äôs the real skill.

Happy building üöÄ

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Day 6 of Building AI agents: A Multi-Agent AI Travel Planner (Hands-On Edition)  ]]>https://srilaxmi.substack.com/p/day-6-of-building-ai-agents-a-multihttps://srilaxmi.substack.com/p/day-6-of-building-ai-agents-a-multiTue, 30 Dec 2025 06:55:57 GMTWelcome to **Day 6** of building real AI projects.

Up to now, this series has been intentionally progressive:
- 

**Day 1‚Äì2** ‚Üí Automations with n8n & Zapier
- 

**Day 3** ‚Üí Custom GPTs and prompt-driven systems
- 

**Day 4-5** ‚Üí Building with AI agents

**Day 6 marks the point at which you cross the builder threshold.**

Today, you‚Äôre not just _understanding_ agents ‚Äî You‚Äôre **reading, running, and modifying a real agentic codebase**.

This is how AI products are actually built in startups and product teams.

## ‚ö†Ô∏è Before You Start (Important)

This project **requires basic Python understanding**.

You should be comfortable with:
- 

Python functions
- 

Variables, lists, dictionaries
- 

Reading `.py` files without panic
- 

Installing packages with `pip`
- 

Running a Python app from the terminal

üëâ You do **not** need to be an advanced Python engineer üëâ You **do** need to be comfortable _reading and tweaking code_

If Python is completely new, pause here and do a **1‚Äì2 hour Python crash course** first.

## üßë‚Äçüíª Step 0: Use a Proper IDE (This Matters)

You _can_ open this project anywhere. However, for the¬† **best learning experience**, consider using an AI-native IDE.

### ‚úÖ Recommended: Cursor

Cursor is one of the best IDEs today for AI-first development.

Why Cursor is perfect here:
- 

It understands your **entire repository**
- 

You can ask: _‚ÄúExplain this file.‚Äù_
- 

You can say: _‚ÄúRefactor this agent.‚Äù_
- 

You can debug multi-agent logic conversationally
- 

It‚Äôs built for reasoning across files, not just autocomplete

üëâ Download: 

https://cursor.sh

## üç¥ Step 1: Fork the Repository

Do **not** clone directly.
- 

Open the GitHub repository üëâ **[Codebase]**
- 

Click **Fork**
- 

Fork into your own GitHub account
- 

Clone _your fork_ locally

This is how real developers work:
- 

safe experimentation
- 

clean version control
- 

freedom to extend

# Understanding the Codebase 

Before running anything, **pause**.

Day 6 is not about ‚Äúgetting output fast.‚Äù It‚Äôs about understanding **how the system is designed**.

A typical structure of this repo looks like:

üëâ **[Codebase]**

# What We‚Äôre Building

We‚Äôre building a **multi-agent AI Travel Planner** that can:
- 

Research destinations using live web search
- 

Fetch weather forecasts for travel dates
- 

Plan routes and transportation
- 

Generate personalized day-by-day itineraries
- 

Find booking links for activities
- 

Export plans to calendars and text files

This is **not a chatbot**.

This is a **coordinated system of AI agents**, each doing one job well.

## Introduction: What is an AI Agent? {#introduction}

### What is an AI Agent?

An **AI Agent** is an autonomous software program that can:
- 

perceive its environment
- 

reason about goals
- 

take actions using tools
- 

and complete multi-step tasks

Unlike a chatbot that simply answers questions, an AI agent **actively works** toward an outcome.

In this project, that outcome is: üëâ _Planning an entire trip from scratch._

**Key Characteristics of AI Agents**
- 

**Autonomy** ‚Äì runs without step-by-step human instructions
- 

**Goal-Oriented** ‚Äì optimizes for a clear objective (a complete travel plan)
- 

**Reactive** ‚Äì adapts to user inputs and constraints
- 

**Proactive** ‚Äì gathers information on its own
- 

**Tool-Using** ‚Äì calls APIs, searches the web, formats outputs
- 

**Multi-Step Reasoning** ‚Äì breaks a complex task into stages

### Real-World Analogy

Think of a professional travel planner who:
- 

Research destinations online
- 

Checks weather forecasts
- 

Plans routes and logistics
- 

Creates a daily itinerary
- 

Finds booking links
- 

Recommends what to pack

That‚Äôs exactly what our **AI Travel Agent** does ‚Äî but faster, cheaper, and 24/7.

## Understanding the Frameworks 

Before we build, let‚Äôs understand the tools powering this system.

### 1. Agno Framework ‚Äì The Agent Orchestrator

**What is Agno?** Agno is a Python framework designed specifically for **building AI agents**.

Instead of writing massive prompts, Agno lets you define:
- 

agents
- 

roles
- 

instructions
- 

tools
- 

and execution flows

Think of Agno as the **conductor** coordinating a team of AI specialists.

**Why Agno?**
- 

Clean, beginner-friendly API
- 

Built for multi-agent systems
- 

Easy tool integration
- 

Works with OpenAI models
- 

Handles orchestration, retries, and structure

**Key Agno Concepts**
- 

**Agent** ‚Äì a specialized AI worker
- 

**Model** ‚Äì the LLM (GPT-4o)
- 

**Instructions** ‚Äì system-level behavior rules
- 

**Role** ‚Äì what the agent is responsible for
- 

**Run** ‚Äì executing an agent with structured input

### 2. OpenAI GPT-4o ‚Äì The Brain

The **LLM is the brain**, not the agent.

GPT-4o provides:
- 

reasoning
- 

synthesis
- 

natural language generation

**Why GPT-4o?**
- 

Strong reasoningËÉΩÂäõ
- 

Handles long context
- 

Production-grade reliability
- 

Generates readable, human-like plans

**In this project, GPT-4o:**
- 

understands travel preferences
- 

synthesizes research results
- 

converts raw data into itineraries

### 3. Streamlit ‚Äì The User Interface

Streamlit lets you build **full web apps using only Python**.

**Why Streamlit?**
- 

No frontend frameworks needed
- 

Interactive widgets out of the box
- 

Built-in state management
- 

Perfect for AI demos and MVPs

**Role in this project**
- 

Collects user input
- 

Displays itineraries
- 

Shows weather & activities
- 

Handles file downloads

### 4. DuckDuckGo Search ‚Äì The Research Engine

DuckDuckGo provides **free web search** without API keys.

**Why DuckDuckGo?**
- 

No cost
- 

No rate limits
- 

Simple Python integration

**Used for:**
- 

finding attractions
- 

discovering activities
- 

collecting travel tips

### 5. BeautifulSoup ‚Äì Content Parsing

Search results are noisy.

BeautifulSoup extracts **meaningful text** from webpages so agents get better context.

### 6. Open-Meteo API ‚Äì Weather Data

Open-Meteo provides:
- 

free global weather forecasts
- 

no API key required

Used to:
- 

fetch weather for travel dates
- 

enable weather-aware planning
- 

generate packing tips

### 7. iCalendar (ICS) ‚Äì Export Format

iCalendar lets users:
- 

import itineraries into Google Calendar
- 

sync with Apple / Outlook

This turns AI output into **real-world utility**.

## Project Overview 

### What We‚Äôre Building

A **multi-agent AI travel planning system** that:
- 

Researches destinations
- 

Analyzes weather
- 

Plans routes and logistics
- 

Creates day-by-day itineraries
- 

Finds booking links
- 

Exports plans

This is **not one giant prompt**.

It‚Äôs a **system of agents**.

**GitHub Repository:** [repo link]

### Key Features

- 

Multi-agent architecture
- 

Live web research
- 

Weather-aware recommendations
- 

Logistics optimization
- 

Booking links
- 

Multiple export formats
- 

Deep personalization

### User Experience Flow

- 

User enters preferences
- 

Agents gather and analyze data
- 

Planner synthesizes results
- 

User receives a complete travel plan

## Step-by-Step Build Process 

### Step 1: Project Setup

- 

Create a Python project
- 

Set up a virtual environment
- 

Install dependencies (Streamlit, Agno, OpenAI, DuckDuckGo, BeautifulSoup, requests, iCalendar)

### Step 2: Design the Agent Architecture

We use **five specialized agents**:
- 

**Research Agent** ‚Äì finds destination info
- 

**Weather Agent** ‚Äì analyzes forecasts
- 

**Logistics Agent** ‚Äì optimizes routes
- 

**Planner Agent** ‚Äì creates itinerary
- 

**Activities Agent** ‚Äì finds booking links

**Why multi-agent?**
- 

specialization beats mega-prompts
- 

easier debugging
- 

scalable architecture

### Step 3: Build Search Functionality

- 

Generate search queries
- 

Fetch results from DuckDuckGo
- 

Enrich snippets with BeautifulSoup
- 

Produce clean research summaries

### Step 4: Define Agents

Each agent defines:
- 

role
- 

instructions
- 

model
- 

input format
- 

output expectations

This keeps agents **disciplined**.

### Step 5: Weather Integration

- 

Convert destination ‚Üí coordinates
- 

Fetch weather from Open-Meteo
- 

Map weather codes
- 

Generate packing & activity advice

### Step 6: Orchestrate the Workflow

Execution pipeline:

```
Research ‚Üí Weather ‚Üí Logistics ‚Üí Planning ‚Üí Activities

```

The **orchestrator**:
- 

controls order
- 

passes structured outputs
- 

prevents chaos

### Step 7: Build the UI

- 

Sidebar for preferences & API keys
- 

Main view for results
- 

Expandable weather & activities sections
- 

Download buttons

### Step 8: Error Handling & Timeouts

- 

Protect agent calls with timeouts
- 

Handle API failures gracefully
- 

Keep the UI responsive

## Key Concepts Explained 

### Agent Anatomy (Very Important)

Every agent in this system has:
- 

**Role** ‚Äì what it does
- 

**Instructions** ‚Äì how it thinks
- 

**Tools** ‚Äì what it can call
- 

**Brain (LLM)** ‚Äì GPT-4o
- 

**Memory / Context** ‚Äì passed explicitly
- 

**Input** ‚Äì structured data
- 

**Output** ‚Äì structured results

Agents are **specialists**, not generalists.

### What Is Orchestration?

Agents **do not talk to each other directly**.

The orchestrator:
- 

runs agents in order
- 

passes outputs forward
- 

maintains system state

This is how hallucinations are reduced.

### Data Flow

```
User Input
 ‚Üí Research
 ‚Üí Weather
 ‚Üí Logistics
 ‚Üí Planning
 ‚Üí Activities
 ‚Üí Output + Export

```

## Features and Capabilities 

### Intelligent Research

- 

dynamic queries
- 

real-time data

### Weather-Aware Planning

- 

daily forecasts
- 

indoor alternatives

### Logistics Optimization

- 

efficient routes
- 

realistic pacing

### Personalized Itineraries

- 

style & budget aware
- 

balanced schedules

### Booking Integration

- 

Viator / GetYourGuide-style links

### Export Formats

- 

calendar (.ics)
- 

text
- 

complete guides

## Deployment and Usage 

### Prerequisites

- 

Python 3.8+
- 

OpenAI API key
- 

Internet access

### Running Locally

- 

activate virtual environment
- 

run Streamlit
- 

Enter API key
- 

generate itinerary

### Deployment Options

- 

Streamlit Cloud

## Conclusion 

### What You Learned

By building this agent, you learned:
- 

How multi-agent systems work
- 

How to orchestrate AI workflows
- 

How to combine LLMs with real APIs
- 

How to build full AI products

### Why This Matters

AI agents are the future of software.

They don‚Äôt just respond. They **reason, act, and complete workflows**.

This Travel Agent is not the goal ‚Äî it‚Äôs the **template**.

Change the domain, and you can build:
- 

research agents
- 

PM copilots
- 

finance planners
- 

ops automation systems

### Next Steps

- 

Add hotel agents
- 

Add budget estimators
- 

Add multi-city planning
- 

deploy & share
- 

build your own agentic product

## Get Started Today

**GitHub Repository:** [repo link]

You now know how real AI systems are built.

**Happy building üöÄ**]]><![CDATA[üöÄ Day 5: Building a Multi-Agent AI PM Research & PRD System Using n8n]]>https://srilaxmi.substack.com/p/day-5-building-a-multi-agent-ai-pmhttps://srilaxmi.substack.com/p/day-5-building-a-multi-agent-ai-pmFri, 26 Dec 2025 11:42:15 GMTWelcome to **Day 5 of building AI Agents / Projects**.

So far, we‚Äôve built **individual AI agents**. Today, we build something **much closer to how real AI systems work in production**.

Not one agent. Not one prompt.

üëâ **A multi-agent orchestration system** that reasons, routes, validates, uses tools, remembers context, and persists outputs **only when needed**.

This is the kind of **internal tooling** used by:
- 

Product teams
- 

Founders
- 

Strategy & research orgs

## üß† What We‚Äôre Building Today

A **PM-grade AI Research & PRD system** that can:
- 

Understand user intent
- 

Decide which expert agent should respond
- 

Route queries intelligently
- 

Generate:
- 

Market research
- 

User research
- 

Full 2-page PRDs

- 

Ask for confirmation before saving
- 

Persist outputs only when approved

All built using **n8n + AI agents**.

No frontend. No backend. Just **AI + orchestration + workflows**.

## ü§ñ Why This Is an AI Agent (Not a Chatbot)

An AI agent is **not** a single LLM call.

A real agent:
- 

Accepts unstructured input
- 

Applies decision logic
- 

Uses tools (search, memory, files)
- 

Routes tasks intelligently
- 

Produces structured outputs
- 

Takes conditional actions

That‚Äôs exactly what we‚Äôre building today.

## üß© Agent Architecture (High Level)

This system has **four agents**:
- 

**Orchestration Agent** (the brain)
- 

**Market Research Agent**
- 

**User Research Analyst**
- 

**PRD Generator Agent**

‚ö†Ô∏è Only **one agent is called at a time**, based on user intent.

This is deliberate. This is how reliable agent systems are built.

## üß™ Prerequisites (Important)

Before starting, make sure you have:
- 

An active **n8n account**
- 

An **OpenAI API key**
- 

Set up  **Tavily API key ( **find the instructions below)
- 

The **n8n workflow JSON file**

üëâ **Download the workflow JSON here** _(Don‚Äôt forget to star the repo)_

‚ö†Ô∏è You do **NOT** need to build this flow manually.

## Step 1: Import the Workflow (Mandatory)

This tutorial uses a **production-ready JSON template**.

### How to import:

- 

Open your **n8n dashboard**
- 

Click **Create Workflow**
- 

Open the menu (‚ãÆ)
- 

Select **Import from clipboard**
- 

Paste the JSON
- 

Click **Import**

‚úÖ The full workflow will instantly appear on your canvas.

Do **not** run it yet.

## üß≠ Step 2: Orchestration Agent (The Brain)

This is the **most important node** in the entire workflow.

### What it does:

- 

Reads the user‚Äôs message
- 

Classifies intent
- 

Routes to exactly **one agent**:
- 

Market Research
- 

User Research
- 

PRD Generator

It **never answers questions for itself**.

### üß† Orchestration Agent ‚Äì System Prompt

You will find the **exact prompt inside the JSON file**  for the Orchestration Agent node.

Core idea (excerpt):

```
Act like an advanced Orchestration Agent designed to intelligently route user queries.

Analyze the user‚Äôs intent and dispatch the request to exactly ONE tool:
- Market Research Analyst
- User Research Analyst
- PRD Generator

Never modify tool outputs.
Never answer directly.

```

üìå **Refer to the JSON for the complete routing logic and examples.**

This turns your system into a **decision-making AI**, not a chatbot.

## üìä Step 3: Market Research Agent (Uses Tavily)

This agent behaves like a **senior strategy analyst**.

You will find the **exact prompt inside the JSON file**.

### What it handles:

- 

Competitor analysis
- 

Market size (TAM / SAM / SOM)
- 

Pricing intelligence
- 

Market trends
- 

Strategic recommendations

### üîç Tavily Usage (Critical)

LLMs **do not have real-time market knowledge**.

So for anything involving:
- 

Competitors
- 

Pricing pages
- 

Market reports
- 

Industry trends

üëâ This agent **must call Tavily**.

In the workflow image, you‚Äôll see:
- 

A **Tavily Search Tool** connected directly to the Market Research Agent.

The flow is:
- 

User asks a market question
- 

Agent calls **Tavily**
- 

Fetches real-world data
- 

Synthesizes insights
- 

Returns PM-ready analysis

üìå The **full Market Research prompt** (including Tavily instructions) is inside the JSON.

### Step A: Create a Tavily Account

- 

Go to üëâ 

https://tavily.com
- 

Click **Sign up**
- 

Create an account using:
- 

Email, or
- 

GitHub / Google login

Once logged in, you‚Äôll land on the Tavily dashboard.

###  Step B: Generate Your Tavily API Key

- 

Inside the Tavily dashboard, go to **API Keys**
- 

Click **Create API Key**
- 

Copy the generated key

‚ö†Ô∏è Treat this like a secret. Do **not** commit it to GitHub.

### Step C: Add Tavily Credentials in n8n

#### Now connect Tavily to n8n.

- 

Open **n8n**
- 

Go to **Credentials**
- 

Click **Create new credential**
- 

Search for **Tavily**
- 

Paste your **Tavily API Key**
- 

Save

‚úÖ Tavily is now available as a tool inside your workflows.

## üßë‚Äçüíª Step 4: User Research Analyst (Also Uses Tavily)

This agent behaves like a **UX research lead**.

### What it handles:

- 

User pain points
- 

Behavioral patterns
- 

Personas & JTBD
- 

UX issues
- 

Sentiment analysis

### üîç Tavily Usage for User Research

Here, Tavily is used to:
- 

Scan public reviews
- 

Analyze forums & Reddit threads
- 

Look at complaints and feedback
- 

Understand sentiment at scale

This allows the agent to:
- 

Go beyond assumptions
- 

Reference real user signals
- 

Ground UX insights in reality

üìå You‚Äôll see **Tavily connected to the User Research Agent** in the workflow image.

üìå The **complete User Research prompt** lives inside the JSON.

## üß† Step 4.1: What ‚ÄúMemory‚Äù Means in This Workflow

You‚Äôll notice **Simple Memory nodes** connected to every agent.

This is **not chat history**.

This is **agent memory**.

### üß© What Memory Does

Memory allows an agent to:
- 

Retain relevant context
- 

Avoid repeating work
- 

Stay consistent across steps
- 

Support multi-turn reasoning

Each agent has **its own memory**:
- 

Orchestration memory
- 

Market Research memory
- 

User Research memory
- 

PRD Generator memory

This isolation is intentional.

### üß† Why Memory Matters

Without memory:
- 

Agents repeat research
- 

PRDs lose context
- 

Outputs become inconsistent

With memory:
- 

Research compounds
- 

PRDs build on insights
- 

The system feels ‚Äúaware.‚Äù

This is **foundational to production AI systems**.

## üßæ Step 5: PRD Generator Agent

This agent generates a **full 2-page Product Requirements Document**.

### Key rules:

- 

Triggered **only** when the user explicitly asks:
- 

‚ÄúGenerate a PRD‚Äù
- 

‚ÄúCreate a product requirements document.‚Äù

- 

Pulls from:
- 

Market Research memory
- 

User Research memory

- 

Uses a structured PRD template
- 

Outputs PM-ready documentation

üìå The **golden PRD prompt** is fully defined inside the JSON.

This is **agent chaining done right**.

## üó£ Step 6: Ask Before Saving (Human-in-the-Loop)

After any agent responds, the system asks:

**‚ÄúDo you want me to store this in a file?‚Äù**

### Why this exists:

- 

Prevents unnecessary persistence
- 

Respects user intent
- 

Mirrors enterprise workflows

## üö¶ Step 7: Conditional Logic (Yes / No)

- 

**Yes** ‚Üí Output is converted to a text file
- 

**No** ‚Üí System responds and exits

This is **production-grade AI behavior**.

## üéØ Day 6 Takeaway

You didn‚Äôt build ‚Äúanother AI demo‚Äù.

You built:
- 

A multi-agent system
- 

Intelligent routing
- 

Tool-augmented research (Tavily)
- 

Agent memory
- 

Human-in-the-loop control
- 

Conditional persistence

This is **how internal AI platforms are built**.

More coming next üöÄ Happy building!

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

]]><![CDATA[Day 4: Building a Full-Stack AI Journal App with Vibe Coding in Bolt]]>https://srilaxmi.substack.com/p/day-4-building-a-full-stack-ai-journalhttps://srilaxmi.substack.com/p/day-4-building-a-full-stack-ai-journalWed, 24 Dec 2025 09:03:14 GMT

_**Frontend, backend, database, auth, and AI ‚Äî without writing traditional backend code.**_

In the last few days, we‚Äôve been building AI Agents step by step:

üëâ **Day 4 is different.** Today, we‚Äôre building a **complete full-stack AI application** using **Vibe coding** in Bolt.

No backend setup. No infra diagrams. No DevOps rabbit holes.

Just **clear product intent ‚Üí working software**.

## What Does ‚ÄúFull-Stack‚Äù Mean?

A **full-stack app** includes everything needed to run a real product:

### 1. Frontend

What users see and interact with:
- 

UI
- 

Design
- 

Forms
- 

Buttons
- 

Editor
- 

Animations

### 2. Backend

The logic behind the scenes:
- 

Saving data
- 

Fetching data
- 

Calling APIs
- 

Running AI models

### 3. Database

Where data lives:
- 

Journal entries
- 

Dates
- 

Moods
- 

AI insights
- 

User preferences

### 4. Authentication

Who the user is:
- 

Login
- 

Signup
- 

User-specific data isolation

### 5. AI Layer

Intelligence on top:
- 

LLMs (Large Language Models)
- 

Analysis
- 

Insights
- 

Personalization

**Today‚Äôs goal:** Build **all five layers** using Bolt ‚Äî by describing _what we want_, not _how to implement it_.

## What We‚Äôre Building Today

A **personal journaling app** inspired by late-night caf√© vibes:
- 

Calm
- 

Intimate
- 

Reflective
- 

Private
- 

AI-assisted (but not intrusive)

This app includes:
- 

Calendar-based journal entries
- 

Mood tracking
- 

Rich-text editor
- 

Writing streaks
- 

Persistent storage
- 

Authentication
- 

Optional AI reflections

## Step 1: Start a New Bolt Project

Create a new project in Bolt and choose the default React template.

https://bolt.new/

You‚Äôll see:
- 

File Explorer

 on the left
- 

Live preview panel
- 

A chat interface where Bolt acts as your builder

At this stage, **don‚Äôt touch code**. We‚Äôll build everything using prompts.

## Step 2: Give Bolt the Core App Prompt

This prompt defines:
- 

Product vision
- 

UX
- 

UI
- 

Features
- 

Mood

üëâ Paste this **exact prompt** into Bolt:

### Prompt 1 ‚Äî Core App

```
Design a personal journaling app inspired by late-night caf√© vibes‚Äîcalm, intimate, and reflective. The interface should feel warm and inviting, with soft amber and golden lighting accents, subtle shadows, and cozy contrast.

Use smooth, rounded UI components, generous spacing, and gentle micro-interactions (fade-ins, slow transitions, soft hover states) to create a relaxing writing experience.

Core features should include:
‚Äì A calendar-based journal view with daily entries
‚Äì Mood tracking with minimal, expressive icons
‚Äì A rich-text editor supporting formatting (bold, italics, lists, highlights) without visual clutter
‚Äì Daily writing streaks presented in a motivating but non-gamified way
- previous entries to be seen in the UI

The color palette should lean toward warm browns, muted oranges, soft creams, and low-saturation neutrals, avoiding harsh contrasts. Overall, the app should feel like sitting alone in a quiet caf√© at night‚Äîsafe, personal, and focused.

```

### What Bolt Does Automatically

From the screenshots:
- 

Builds the UI with warm amber tones
- 

Adds mood pills (Calm, Happy, Reflective, etc.)
- 

Creates a calendar view
- 

Adds a distraction-free editor
- 

Implements writing streak logic
- 

Displays previous entries

This is **vibe coding**:

You describe the feeling and intent ‚Äî Bolt figures out the structure.

## Step 3: Database ‚Äî What Is Supabase and Why Bolt Uses It?

### What Is Supabase?

**Supabase** is an open-source backend platform that provides:
- 

PostgreSQL database
- 

Authentication
- 

Row-level security
- 

APIs out of the box

Think of it as:

‚ÄúFirebase, but with SQL and more control.‚Äù

### Why Bolt Uses Supabase

Bolt automatically:
- 

Provisions a Supabase project
- 

Creates tables
- 

Handles migrations
- 

Connects auth with data

From the screenshots, you can see tables like:
- 

`journal_entries`
- 

`user_preferences`
- 

`ai_insights`

You never write SQL ‚Äî Bolt infers schema from your app.

## Step 4: Authentication Setup

In **Project Settings ‚Üí Authentication**, Bolt enables:
- 

Email + password login
- 

User-specific data isolation
- 

Optional anonymous access

This is crucial for a journaling app:
- 

Private
- 

Secure
- 

Personal
- 

No social pressure

Each user only sees **their own entries**.

## Step 5: Secrets ‚Äî What They Are and Where to Get Them

### What Are Secrets?

**Secrets** are sensitive values like:
- 

API keys
- 

Database URLs
- 

Private credentials

They should **never** be exposed in frontend code.

Bolt provides a secure secrets manager.

### Secret 1: OpenAI API Key

#### What Is an OpenAI LLM?

An **LLM (Large Language Model)** is what powers ChatGPT-like intelligence:
- 

Text understanding
- 

Pattern detection
- 

Emotional tone analysis
- 

Summarization

We use OpenAI **only for reflection**, not advice.

#### Where to Get the OpenAI API Key

- 

Go to üëâ 

https://platform.openai.com
- 

Create an account
- 

Go to **API Keys**
- 

Create a new secret key
- 

Copy it

Add it in Bolt as:

```
OPENAI_API_KEY = your_key_here

```

### Secret 2: Supabase Keys

#### How to Get Supabase Keys (Quick)

#### Step 1: Open Your Supabase Project

- 

In **Bolt ‚Üí Project Settings ‚Üí Database**
- 

Click **Open in Supabase** (or **View Database**)
- 

This opens your project in the Supabase dashboard

#### Step 2: Copy the Required Keys

#### In **Supabase ‚Üí Project Settings ‚Üí API**, copy:

https://supabase.com/
- 

**Project URL** ‚Üí `SUPABASE_URL`
- 

**anon public key** ‚Üí `SUPABASE_ANON_KEY`
- 

**service_role key** ‚Üí `SUPABASE_SERVICE_ROLE_KEY`

Then go to **Project Settings ‚Üí Database** in Supabase and copy:
- 

**Connection string** ‚Üí `SUPABASE_DB_URL`

Add all of these in **Bolt ‚Üí Project Settings ‚Üí Secrets**.

## Step 6: Add the AI Reflection Layer

Once the core app is working, we¬† **layer on¬†AI gently**.

üëâ Paste this prompt:

### Prompt 2 ‚Äî AI Layer

```
Add a subtle AI reflection layer to the journaling app. Using an OpenAI LLM, the AI gently analyzes journal entries (with user consent) to surface emotional patterns, recurring themes, mood trends, and tone shifts.

Insights should feel calm, empathetic, and observational‚Äînever diagnostic or prescriptive. The AI acts like a quiet late-night companion, offering short reflections and optional prompts without interrupting the writing flow.

AI insights should appear in soft, minimal cards that blend into the warm caf√© aesthetic.

```

### System Prompt (Very Important)

This controls AI behavior and **prevents unsafe output**.

```
You are a reflective journaling assistant.

Gently analyze user journal entries to surface patterns, emotions, and themes.
Be calm, empathetic, and non-judgmental.
Do not diagnose, prescribe, or give advice.
Prefer reflection over instruction.
Keep responses short and soothing.
Your goal is to help the user feel seen and understood.

```

This is **responsible AI design**.

## Step 7: How Data Flows (Simple Mental Model)

- 

User writes a journal entry
- 

Entry is saved to Supabase
- 

Mood + date are stored
- 

If AI is enabled:
- 

Entry sent to OpenAI
- 

Reflection generated
- 

Saved to `ai_insights`

- 

UI displays insights softly

Everything is:
- 

User-scoped
- 

Persistent
- 

Secure

## Step 8: Publish the App

Click **Publish**.

Bolt:
- 

Builds the app
- 

Hosts it
- 

Gives you a public URL
- 

Supports custom domains

You‚Äôve now shipped a **real full-stack AI product**.

## Why This Matters

This project proves:
- 

You don‚Äôt need backend expertise to build backend systems
- 

Product thinking > framework knowledge
- 

AI should _support_, not dominate
- 

Vibe coding works when the intent is clear

## What‚Äôs Next?

From here, you could add:
- 

Weekly reflection summaries
- 

Mood heatmaps
- 

Export to PDF
- 

Encryption
- 

Multi-device sync
- 

SaaS plans

But most importantly ‚Äî You‚Äôve learned how to **think full-stack without fear**.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

]]><![CDATA[Day 3 of Building AI Projects - Build a Custom GPT ]]>https://srilaxmi.substack.com/p/day-3-of-building-ai-projects-buildhttps://srilaxmi.substack.com/p/day-3-of-building-ai-projects-buildTue, 23 Dec 2025 10:19:36 GMTOn **Day 1 and Day 2**, we built hands-on AI projects using **n8n** and **Zapier**‚Äîautomating workflows, connecting tools, and reducing busywork.

**Day 3 is about building an AI product.**

Not an automation. Not a one-off prompt. But a **Custom GPT** that people actually use‚Äîand keep coming back to.

Today, I‚Äôll break down:
- 

What a Custom GPT really is
- 

How to create one (step by step)
- 

How documents, instructions, and publishing work
- 

The **exact prompt** I used
- 

Why my GPT ( **PM Interview Expert**) is now used by **15,000+ Product Managers**
- 

Practice GPT ideas you can build yourself

## What Is a Custom GPT (In Simple Terms)?

A **Custom GPT** is your knowledge + your instructions wrapped into a reusable AI assistant.

It has **three core components**:
- 

**Instructions** ‚Üí how the GPT behaves
- 

**Documents (Knowledge)** ‚Üí what it knows
- 

**Publishing settings** ‚Üí who can use it

You‚Äôre not training a new model. You‚Äôre **productizing your expertise**.

Think of it like this:

Prompts = one-time Custom GPTs = reusable products

## Where to Create a Custom GPT 

You create Custom GPTs here üëá

üîó **Create a GPT:** https://chat.openai.com/gpts/editor

(You‚Äôll need ChatGPT Plus / Team / Enterprise to create one.)

## Why I Built a Custom GPT for PM Interview Prep

PM interviews are uniquely hard.

They test:
- 

Product thinking
- 

Metrics & analytics
- 

Estimation
- 

Technical fundamentals
- 

Communication

Most candidates:
- 

Memorize frameworks
- 

Read blog posts
- 

Still struggle to **structure answers live**

I wanted something better.

So I built **PM Interview Expert**‚Äîa Custom GPT trained on:
- 

My personal PM frameworks
- 

Real interview questions
- 

Sample strong answers
- 

Rubrics for evaluation

Today:
- 

‚úÖ **15,000+ PMs have used it**
- 

‚úÖ It‚Äôs one of the **top PM interview GPTs**
- 

‚úÖ Used by Associate ‚Üí Senior PMs globally

üîó **Try it here:** https://chat.openai.com/g/g-X9Zal2ygw-pm-interview-expert

## What Can a PM Interview Expert Help With?

### üß† Product Sense

- 

How would you improve Spotify as a podcast app?
- 

What‚Äôs your favorite product and why?

### üìê Estimation

- 

How much money does Spotify make in a year?
- 

Estimate the number of songs played per day.
- 

What will the market size of Alexa be in 2025?

### üìä Analytical / Metrics

- 

How would you measure success for TikTok?
- 

Facebook messages dropped 10% in 2 days. Why?
- 

Gmail signups are down 5%. What data do you need?

### ‚öôÔ∏è Technical (PM-level)

- 

What happens when you type google.com in a browser?
- 

Explain APIs to your grandfather.
- 

How does Google Maps compute ETA?
- 

Types of load-balancing algorithms?

## Step-by-Step: How to Create Your Own Custom GPT

### **Step 1: Open the GPT Builder**

Go to: üëâ https://chat.openai.com/gpts/editor Click **Create**

You‚Äôll see two tabs:
- 

**Create** ‚Üí chat-based setup
- 

**Configure** ‚Üí where the real magic happens

## Step 2: Paste This Prompt (Starter Prompt)

In the **Create** tab, paste this üëá

```
I want to create a Custom GPT called ‚ÄúPM Interview Expert‚Äù.

It should act as an experienced Product Manager and interview coach.

Target audience:
- Product Manager candidates (Associate ‚Üí Senior)

Core use case:
- Help users practice PM interviews across Product Sense, Analytical, Estimation, and Technical rounds.

Behavior:
- Ask clarifying questions when prompts are ambiguous
- Structure answers like real interview responses
- Use clear frameworks and step-by-step reasoning
- Never invent metrics or facts; state assumptions explicitly

Coaching mode:
- Evaluate user answers
- Highlight strengths
- Identify gaps
- Provide a refined model answer

Tone:
- Calm, confident, practical
- Like a senior PM interviewer

I will upload my own PM frameworks and sample answers as documents.

```

This sets the **direction**.

## Step 3: Instructions (The Brain of Your GPT)

Now go to **Configure ‚Üí Instructions** and paste this in full:

```
You are ‚ÄúPM Interview Expert,‚Äù an interview coach for Product Manager candidates.

Your goal:
Help users practice PM interviews across Product Sense, Analytical, Estimation, and Technical rounds.

GLOBAL RULES
- Ask clarifying questions when needed
- Never invent real-world data
- State assumptions clearly
- Keep answers concise and structured

PRODUCT SENSE
1. Clarify goal and user segment
2. Define problem
3. Success metrics
4. Key insights
5. Solution ideas
6. Prioritization
7. Tradeoffs
8. MVP and rollout

ANALYTICAL / RCA
1. Restate metric change
2. Data needed
3. Hypothesis tree
4. Debug plan
5. Likely causes
6. Fixes

ESTIMATION
1. Define target
2. State assumptions
3. Step-by-step math
4. Sanity check

TECHNICAL
1. Simple explanation
2. Technical breakdown
3. Tradeoffs
4. Examples

COACHING MODE
- Grade answers: Strong / Mixed / Weak
- Highlight strengths
- Suggest improvements
- Provide a better model answer

```

This is what makes your GPT **non-generic**.

## Step 4: Documents (Knowledge Files)

You can upload **up to 20 documents**.

Best documents to add:
- 

Frameworks
- 

Sample answers
- 

Question banks
- 

Evaluation rubrics
- 

Notes from real interviews

üí° Tip: Clean text (Docs / Markdown) works best. Avoid slides with multiple columns.

## Step 5: Conversation Starters (UX Matters)

Add examples like:
- 

‚ÄúGive me a Product Sense question and interview me.‚Äù
- 

‚ÄúEvaluate my answer and suggest improvements.‚Äù
- 

‚ÄúRun a 15-minute mock PM interview.‚Äù
- 

‚ÄúAsk me an estimation question.‚Äù

This dramatically improves usage.

## Step 6: Publishing Your GPT

Under **Publish settings**, you can choose:
- 

Only me
- 

Anyone with a link
- 

Public (listed)

Once published, your GPT gets a **shareable link** like:

```
https://chat.openai.com/g/g-xxxxxxxx

```

That‚Äôs how **PM Interview Expert** reached **15,000+ users**.

## Practice: Custom GPT Ideas (Beyond Product Management)

Once you understand how Custom GPTs work, you‚Äôll realize they‚Äôre **role-based AI tools**, not just ‚Äúchatbots‚Äù.

Below are **high-impact Custom GPT ideas for different personas**, along with _how to build each one_.

Each of these can be built in **20‚Äì40 minutes**.

## 1Ô∏è‚É£ Resume & Career Coach GPT (Non-Tech / General)

### Who it‚Äôs for

- 

Students
- 

Career switchers
- 

Early professionals

### What it does

- 

Reviews resumes
- 

Suggests role-specific improvements
- 

Helps write bullet points
- 

Prepares interview answers

### How to build it

**Instructions**
- 

Act as a career coach
- 

Ask role, experience level, and target company
- 

Give actionable, concise feedback

**Documents to upload**
- 

Resume templates
- 

Strong bullet examples
- 

STAR method examples
- 

Common resume mistakes

**Conversation starters**
- 

‚ÄúReview my resume for a marketing role.‚Äù
- 

‚ÄúRewrite this bullet to sound more impactful.‚Äù
- 

‚ÄúPrepare me for an HR interview.‚Äù

## 2Ô∏è‚É£ Personal Finance Explainer GPT

### Who it‚Äôs for

- 

Beginners to investing
- 

Young professionals
- 

Non-finance backgrounds

### What it does

- 

Explains finance concepts simply
- 

Helps with budgeting
- 

Explains tax, SIPs, stocks, and mutual funds
- 

Avoids financial jargon

### How to build it

**Instructions**
- 

Explain concepts using analogies
- 

Avoid giving legal or investment advice
- 

Ask about the country and risk appetite

**Documents to upload**
- 

Finance explainers
- 

Budgeting frameworks
- 

Common financial terms glossary

**Conversation starters**
- 

‚ÄúExplain SIPs like I‚Äôm 10‚Äù
- 

‚ÄúHow should I budget my salary?‚Äù
- 

‚ÄúDifference between stocks and mutual funds?‚Äù

## 3Ô∏è‚É£ Health & Fitness Habit Coach GPT (Non-Medical)

### Who it‚Äôs for

- 

Busy professionals
- 

Beginners to fitness
- 

People building habits

### What it does

- 

Builds workout routines
- 

Creates habit plans
- 

Tracks consistency
- 

Motivates without shaming

### How to build it

**Instructions**
- 

Never give medical advice
- 

Focus on habits, routines, and motivation
- 

Ask about lifestyle and constraints

**Documents to upload**
- 

Workout templates
- 

Habit-building frameworks
- 

Fitness myths vs facts

**Conversation starters**
- 

‚ÄúCreate a 15-minute daily workout.‚Äù
- 

‚ÄúHelp me build a walking habi.t‚Äù
- 

‚ÄúHow do I stay consistent?‚Äù

## 4Ô∏è‚É£ Writing & Blogging Coach GPT

### Who it‚Äôs for

- 

Content creators
- 

Newsletter writers
- 

Bloggers

### What it does

- 

Improves writing clarity
- 

Suggests hooks
- 

Edits tone and structure
- 

Helps overcome writer‚Äôs block

### How to build it

**Instructions**
- 

Ask audience and platform (Substack, LinkedIn, blog)
- 

Suggest multiple hooks
- 

Edit without changing voice

**Documents to upload**
- 

Writing frameworks
- 

Sample great posts
- 

Headline swipe files

**Conversation starters**
- 

‚ÄúImprove this intro.‚Äù
- 

‚ÄúGive me 5 hooks for this idea.‚Äù
- 

‚ÄúRewrite this for LinkedIn.‚Äù

## 5Ô∏è‚É£ Study Companion GPT (Students / Exams)

### Who it‚Äôs for

- 

College students
- 

Exam prep candidates
- 

Self-learners

### What it does

- 

Explains concepts step-by-step
- 

Creates quizzes
- 

Summarizes notes
- 

Tests understanding

### How to build it

**Instructions**
- 

Teach concept ‚Üí ask a question ‚Üí correct mistakes
- 

Adjust depth based on user responses

**Documents to upload**
- 

Study notes
- 

Syllabi
- 

Practice questions

**Conversation starters**
- 

‚ÄúExplain this topic simply.‚Äù
- 

‚ÄúQuiz me on this chapter.‚Äù
- 

‚ÄúSummarize my notes.‚Äù

## 6Ô∏è‚É£ Startup Idea Validator GPT

### Who it‚Äôs for

- 

Founders
- 

Indie hackers
- 

First-time builders

### What it does

- 

Evaluates startup ideas
- 

Identifies target users
- 

Finds risks and assumptions
- 

Suggests MVPs

### How to build it

**Instructions**
- 

Think like an early-stage investor
- 

Challenge assumptions politely
- 

Focus on clarity, not hype

**Documents to upload**
- 

Startup frameworks
- 

MVP examples
- 

Market sizing guides

**Conversation starters**
- 

‚ÄúValidate this startup idea.‚Äù
- 

‚ÄúWho is the real customer?‚Äù
- 

‚ÄúWhat assumptions am I making?‚Äù

## 7Ô∏è‚É£ Language Practice GPT (Conversational)

### Who it‚Äôs for

- 

Language learners
- 

Non-native speakers

### What it does

- 

Simulates conversations
- 

Corrects grammar gently
- 

Improves fluency

### How to build it

**Instructions**
- 

Act as a friendly conversation partner
- 

Correct mistakes after the response
- 

Encourage speaking, not perfection

**Documents to upload**
- 

Common phrases
- 

Grammar rules
- 

Example conversations

**Conversation starters**
- 

‚ÄúTalk to me in simple English.‚Äù
- 

‚ÄúCorrect my sentences.‚Äù
- 

‚ÄúPractice an interview conversation‚Äù

## Key Pattern to Notice

Every good Custom GPT has:
- 

**One clear user persona**
- 

**One primary job**
- 

**Strong instructions**
- 

**Relevant documents**
- 

**Good conversation starters**

That‚Äôs it.

## Final Reminder

Custom GPTs are not about prompts. They are about **designing behavior**.

If you can clearly answer:
- 

Who is this for?
- 

What problem does it solve?
- 

How should it respond?

You can build a valuable GPT.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

### 

]]><![CDATA[Day 2 ‚Äì Building AI Agents: Automating Your Daily AI Briefs with Zapier]]>https://srilaxmi.substack.com/p/day-2-building-ai-agents-automatinghttps://srilaxmi.substack.com/p/day-2-building-ai-agents-automatingMon, 22 Dec 2025 03:45:57 GMTWelcome to **Day 2 of building AI agents**.

On **Day 1**, we focused on understanding _what AI agents are_ and how tools like **n8n** help you orchestrate them end-to-end.

In this tutorial, you‚Äôll learn how to build a **real AI agent workflow** using **Zapier (conceptually similar to n8n)** that:
- 

Collects AI newsletters automatically
- 

Uses an LLM to reason over unstructured data
- 

Produces a structured daily brief
- 

Delivers it where you actually work (Slack)

Even if you‚Äôre building in **n8n**, this tutorial maps **1:1 conceptually**:
- 

Schedule Trigger ‚Üí Cron node
- 

Gmail Search ‚Üí Gmail / IMAP node
- 

AI Analysis ‚Üí OpenAI / LLM node
- 

Slack Message ‚Üí Slack node

Subscribe now

## **What We‚Äôre Building Today**

A **Daily AI Newsletter Summary Agent** that runs every morning and answers:

‚ÄúWhat happened in AI yesterday that I should care about?‚Äù

### What the automation does:

- 

‚è∞ Runs daily at 9 AM
- 

üì© Finds all AI newsletters from yesterday
- 

ü§ñ Summarizes them using AI
- 

üí¨ Sends a clean, structured brief to Slack

## **Prerequisites**

Before beginning this lab, ensure you have completed the following:
- 

A Zapier account (or n8n if you‚Äôre mapping this later)
- 

Gmail account with an **‚ÄúAI Newsletters‚Äù** label
- 

Slack workspace with admin access
- 

OpenAI API key (or Zapier‚Äôs built-in OpenAI)

## **Step 1: Set Up the Daily Schedule Trigger**

### What This Step Does

This trigger fires every morning at your specified time (9 AM) to kick off the entire workflow.

### Configuration

- 

Create a new Zap and select **Schedule by Zapier**
- 

Choose **Every Day**
- 

Set **Time of Day** to **9:00 AM**
- 

Set **Trigger on weekends** (Yes / No)
- 

Click **Continue**

### Why This Matters

Using a scheduled trigger instead of a ‚ÄúNew Email‚Äù trigger ensures you receive **one consolidated daily brief**, not multiple notifications throughout the day.

In n8n terms: this is your **Cron / Time-based orchestration layer**.

## **Step 2: Search for Yesterday‚Äôs AI Newsletter Emails**

### What This Step Does

This step searches your Gmail inbox for all emails labeled **‚ÄúAI Newsletters‚Äù** from the last 24 hours.

### Configuration

- 

Add Action ‚Üí **Gmail**
- 

Choose **Find Email**
- 

Search string:

```
label:"AI Newsletters" newer_than:1d

```

### Breaking Down the Search Query

ComponentPurpose `label:"AI Newsletters"`Filters relevant newsletters `newer_than:1d`Only yesterday‚Äôs emails

### Gmail Search Operator Tips

- 

`from:newsletter@example.com`
- 

`subject:AI`
- 

`has:attachment`

## **Step 3: Summarize Emails with AI**

### What This Step Does

This step uses OpenAI‚Äôs GPT-4o mini model to **reason over multiple emails** and return a structured summary.

### Configuration

- 

Add Action ‚Üí **AI by Zapier**
- 

Choose **Analyze and Return Data**
- 

Provider: OpenAI
- 

Model: GPT-4o mini
- 

Prompt:

```
You are an AI newsletter summarizer. Analyze all the emails provided and create a comprehensive daily summary.

For each email, extract and structure the following:
1. Subject/Title
2. Key Points (3‚Äì5 bullets)
3. Sender/Source
4. Action Items & Links

Format as a structured brief.

```

### Input Mapping

- 

Subject ‚Üí `{{step_2__subject}}`
- 

Sender ‚Üí `{{step_2__from__name}}`
- 

Body (plain + HTML)

### Output Schema

- 

subject
- 

key_points
- 

sender
- 

action_items
- 

links

This is the **‚Äúreasoning core‚Äù** of your AI agent.

## **Step 4: Send the Formatted Brief to Slack**

### What This Step Does

Post the AI-generated brief into Slack in a readable format.

### Configuration

- 

Add Action ‚Üí **Slack**
- 

Choose **Send Channel Message**
- 

Select channel
- 

Message template:
- 

Send as bot: Yes
- 

Bot name: AI Newsletter Bot

```
üì∞ AI Newsletter Daily Brief

SUBJECT:
{{step_3__subject}}

FROM:
{{step_3__sender}}

KEY POINTS:
{{step_3__key_points}}

ACTION ITEMS:
{{step_3__action_items}}

LINKS:
{{step_3__links}}

```

- 

## **Testing Your Zap**

Test each step sequentially:
- 

Schedule trigger fires
- 

Gmail returns emails
- 

AI produces structured output
- 

Slack receives a message

Verify formatting and content accuracy.

This is my Zap response

## **Troubleshooting Guide**

### Gmail returns no results

- 

Confirm label exists
- 

Test without `newer_than:1d`

### AI output incomplete

- 

Ensure the email body is passed correctly
- 

Simplify the prompt if needed

### Slack message fails

- 

Confirm bot permissions
- 

Confirm channel access

## **Advanced Customizations**

- 

Filter only Substack emails:

```
from:@substack.com

```

- 

Multiple labels
- 

Multiple Slack channels
- 

Add Formatter for cleanup
- 

Change the schedule timing

## **Best Practices**

**Do**
- 

Test before enabling
- 

Review summaries initially
- 

Start simple

**Don‚Äôt**
- 

Over-optimize early
- 

Post directly to #general
- 

Expect perfect AI output on day one

## **Conclusion**

By Day 2, you‚Äôve built a **real AI agent workflow** that:
- 

Runs on a schedule
- 

Consumes unstructured data
- 

Uses an LLM for reasoning
- 

Produces structured output
- 

Delivers value automatically

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

]]><![CDATA[üöÄ Day 1: Building AI Agents ‚Äî Create an AI-Powered ATS Resume Reviewer & Writer Using n8n]]>https://srilaxmi.substack.com/p/day-1-building-ai-agents-create-anhttps://srilaxmi.substack.com/p/day-1-building-ai-agents-create-anFri, 19 Dec 2025 04:08:41 GMTWelcome to **Day 1 of building AI Agents**.

Over the next **30 days**, we‚Äôll build **real, production-grade AI agents** or **platforms**‚Äî not chat demos, not toy examples ‚Äî but agents that **reason, validate, decide, and take actions**.

My goal is that by the end of 30 days, you‚Äôll be able to build AI agents or full AI products and become well-versed in using tools like n8n, Make, Lovable, Cursor, CrewAI, Langchain, Autogen, and more.

Today‚Äôs agent: üëâ An **AI-powered ATS Resume Reviewer & Writer**, built using **n8n**.

No backend. No frontend. Just **AI + workflows + automation**.

## ü§ñ What Is an AI Agent?

An **AI agent** is more than an LLM response.

An agent:
- 

Accepts structured inputs
- 

Applies rules and constraints
- 

Uses tools (APIs, documents, databases)
- 

Makes decisions
- 

Produces structured outputs
- 

Can trigger actions automatically

This tutorial teaches you **agent architecture**, not just prompting.

## üß† AI Agent Categories (What We‚Äôll Build in 30 Days)

### **Category 1: Consumer Agents (Built-In)**

**Examples**
- 

ChatGPT Agent
- 

Claude 4
- 

Grok
- 

Gemini 4

Best for:
- 

Quick research
- 

Writing docs
- 

One-off tasks

Limitations:
- 

No automation
- 

No system control
- 

No workflows

### **Category 2: No-Code / Low-Code Agent Builders** ‚úÖ _(Today)_

**Examples**
- 

Zapier Agents
- 

Lindy
- 

Relay.app
- 

Make.com
- 

**n8n**

These agents:
- 

Combine workflows + AI reasoning
- 

Allow structured, repeatable automation
- 

Power most real-world AI use cases today

### **Category 3: Developer-First Platforms**

**Examples**
- 

LangChain
- 

CrewAI
- 

AutoGen
- 

Swarm

Used when:
- 

Building customer-facing AI products
- 

Engineering teams need full control

We‚Äôll reach this later.

## üß∞ What is n8n?

## **n8n** is a workflow automation platform.

Think of it as:

Zapier + logic + code + AI ‚Äî all in one

With n8n, you can:
- 

Call APIs
- 

Run JavaScript
- 

Use LLMs safely
- 

Add decision logic
- 

Build full AI agents visually

Most importantly: üëâ n8n lets you **control AI behavior** (prompts, validation, parsing, errors)

That‚Äôs why it‚Äôs ideal for learning agents.

## üß™ Prerequisites

Before beginning this lab, ensure you have:
- 

**Set up your n8n account**
- 

**Generate an OpenAI API key**
- 

**Downloaded the n8n workflow JSON file** üëâ Click Here. Don‚Äôt forget to star the GitHub repo. 

## üü¢ Step 1: Set Up Your n8n Account

If you‚Äôre new to n8n:
- 

Create an n8n account (cloud or self-hosted)
- 

Log in to your **n8n dashboard**

Once logged in, continue below.

## üü¢ Step 2: Import the Workflow

- 

Click **Create Workflow**
- 

Open the menu (three dots/hamburger icon)
- 

Select **Import from File**
- 

Upload the downloaded JSON workflow

‚úÖ The workflow will appear on your canvas.

Do **not** run it yet.

## üîê Step 3: Configure Google Docs Access (Google Cloud Console)

This workflow creates and writes to **Google Docs**, so we must configure **Google OAuth correctly**.

This step is **mandatory**.

### üß© Why This Step Exists

Google APIs:
- 

Do NOT work with just an email login
- 

Require OAuth credentials
- 

Must be explicitly authorized

This setup allows your AI agent to:
- 

Create Google Docs
- 

Insert content programmatically
- 

Return a shareable document link

## üü¢ Step 3.1: Create a Google Cloud Project

- 

Go to **Google Cloud Console**
- 

Click **Select Project ‚Üí New Project**
- 

Give it a name (e.g. `n8n-ai-agents`)
- 

Create the project

## üü¢ Step 3.2: Enable Google Docs API

Inside your new project:
- 

Go to **APIs & Services ‚Üí Library**
- 

Search for **Google Docs API**
- 

Click **Enable**

(Optional but recommended)
- 

Also, enable the **Google Drive API**

## üü¢ Step 3.3: Configure OAuth Consent Screen

- 

Go to **APIs & Services ‚Üí OAuth Consent Screen**
- 

Choose **External**
- 

Fill required fields:
- 

App name (e.g. `n8n AI Agent`)
- 

User support email
- 

Developer email

- 

Save and continue
- 

Add scopes:
- 

`https://www.googleapis.com/auth/documents`
- 

`https://www.googleapis.com/auth/drive.file`

- 

Save

üìå You do NOT need verification for personal use.

## üü¢ Step 3.4: Create OAuth Credentials

- 

Go to **APIs & Services ‚Üí Credentials**
- 

Click **Create Credentials ‚Üí OAuth Client ID**
- 

Application type: **Web application**
- 

Add redirect URI:

```
https://<your-n8n-domain>/rest/oauth2-credential/callback

```

(If using n8n cloud, this URL is shown inside n8n)
- 

Create credentials
- 

Copy:
- 

Client ID
- 

Client Secret

## üü¢ Step 3.5: Configure Google Credential in n8n

- 

Open **Credentials** in n8n
- 

Create new credential ‚Üí **Google OAuth2 API**
- 

Paste:
- 

Client ID
- 

Client Secret

- 

Click **Connect / Authenticate**
- 

Log in to Google and approve access

‚úÖ Google Docs access is now configured.

## üü¢ Step 4: Input Fields (Why This Step Exists)

### Node: **Edit Fields (Set Node)**

Defines:
- 

`resume_text`
- 

`job_description`
- 

`candidate_name`
- 

`target_role`

This node exists to:
- 

Centralize inputs
- 

Make the agent reusable
- 

Support future forms / APIs

## ‚ö†Ô∏è IMPORTANT: Replace Sample Resume & JD

The workflow includes **sample data**.

You MUST replace:

```
resume_text ‚Üí Your resume (plain text)
job_description ‚Üí Target job description
candidate_name ‚Üí Your name
target_role ‚Üí Role title

```

If you skip this: ‚ùå The AI optimizes the sample resume ‚ùå Results are meaningless

## üßπ Step 5: Clean & Normalize Text

### Node: **Code in JavaScript**

Why this exists:
- 

Removes invisible characters
- 

Normalizes bullets
- 

Fixes spacing
- 

Prevents AI confusion

Clean inputs ‚Üí predictable AI outputs.

## üö¶ Step 6: Input Validation

### Node: **If**

Rules:
- 

Resume ‚â• 500 chars
- 

JD ‚â• 300 chars

Why:
- 

Prevent hallucinations
- 

Avoid wasted tokens
- 

Enforce quality

This is **production-grade agent design**.

## ü§ñ Step 7: ATS Evaluation (AI Brain #1)

### Node: **Message a model**

Purpose:
- 

Structured ATS-style scoring
- 

Identify strengths & gaps
- 

Output strict JSON

Evaluation is separated from writing to improve reliability.

## üß© Step 8: Parse AI Output

### Node: **Parse ATS JSON**

Why:
- 

LLMs sometimes break JSON
- 

Parsing protects downstream steps
- 

Agents must fail safely

## ‚úçÔ∏è Step 9: Resume Rewriting (AI Brain #2)

### Node: **Tailor Resume**

Purpose:
- 

Rewrite the resume using gaps
- 

Maintain truth
- 

Preserve ATS formatting

This is **agent chaining**:

One AI analyzes ‚Üí another AI acts

## üìÑ Step 10: Export to Google Docs

Why Google Docs:
- 

Shareable
- 

Editable
- 

Recruiter-friendly

The agent:
- 

Creates a doc
- 

Inserts a tailored resume
- 

Returns a live URL

## ‚úÖ Step 11: Final Output

Returns:
- 

ATS score
- 

Dimension scores
- 

Strengths & gaps
- 

Google Doc link

Ready for:
- 

Frontends
- 

APIs
- 

Notifications
- 

Scaling into a product

## üéØ Day 1 Takeaway

You didn‚Äôt just build a resume tool.

You built a **real AI agent** with:
- 

Validation
- 

Decision logic
- 

Tool usage
- 

Multiple AI roles
- 

Safe automation

More on the way!!! Happy building:)

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Why Midjourney Chose Discord? A Creative Haven for AI Art]]>https://srilaxmi.substack.com/p/why-midjourney-chose-discord-a-creativehttps://srilaxmi.substack.com/p/why-midjourney-chose-discord-a-creativeThu, 04 Jan 2024 05:47:20 GMTMidjourney, the popular AI art generator, has picked an unusual home: Discord. This choice might seem odd against the sleek, dedicated apps of today. Yet, it's a strategic move that's as creative as the art produced.

**Building a Creative Community:**

Midjourney isn't just about churning out AI-powered masterpieces; it's about fostering a collaborative space where creativity thrives. With its built-in communities and real-time interaction, Discord becomes more than just a platform - it's a vibrant, ever-evolving art studio. Imagine tossing prompt ideas with artists from across the globe, witnessing AI art, and receiving immediate feedback on your creations.

_**Discord nurtures a sense of community and continuous creative exchange, unlike isolated apps.**_

**Utilizing Ready Resources:**

Building and maintaining a separate platform is a resource-intensive task. Discord, on the other hand, offered a ready-made solution with robust image hosting, organized channels, and built-in chat functionalities. This allowed Midjourney to focus on refining the core AI engine while leveraging Discord's strengths to create a unique user experience.

**Learning and Improving Together:**

The partnership with Discord encourages a playful, experimental approach. Users learn by doing‚Äîtrying different prompts, sharing results, and collaborating. This not only makes AI art more accessible but also fun! Additionally, by continuously learning from user interactions and feedback, Midjourney improves, adapting to what users enjoy and find effective.

**Added Benefits of Discord:**
- 

**Continuous Learning from Feedback:** Midjourney's use of Discord allows it to evolve from user input constantly. This means the AI learns what's working and what's not, thanks to the vast amount of feedback provided by the community.
- 

**Better Prompts Lead to Better Art:** Users see which prompts yield the best art, leading them to craft better prompts over time. This collective learning helps everyone generate more stunning results.

**Challenges and the Future:**

While Discord's lively nature can be daunting for some, and dependency on a third-party platform raises sustainability questions, the benefits are clear. Midjourney's adoption of Discord has transformed it into a dynamic, collaborative space that fosters the growth of AI art.

**Subscribe to the AI & Product Newsletter on Substack to get access to subscriber-only content.**AI & Product NewsletterExplore the future of AI, product management, tech, and startups with weekly deep dives delivered straight to your inbox. Stay one step ahead of the curve by subscribing now.By Sri Laxmi

### A subscription gets you:

- 

Weekly deep dives on AI product
- 

Weekly product management content
- 

Full archives

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[From Note-Taking App to AI Savior: Clueso Founder Neil Bala on Building with User Focus]]>https://srilaxmi.substack.com/p/from-note-taking-app-to-ai-saviorhttps://srilaxmi.substack.com/p/from-note-taking-app-to-ai-saviorSun, 31 Dec 2023 04:05:29 GMTWelcome, AI enthusiasts, to another exciting episode of AI Product Builders! This week, we delve into the fascinating world of **Clueso**, an AI-powered platform that's revolutionizing how companies create documentation and video tutorials. We had the pleasure of chatting with Clueso's founder, Neil Bala, and glean**ed** invaluable insights on building and scaling an AI product with user needs at the heart.

**Clueso: Bridging the Knowledge Gap with AI**

Imagine generating professional product guides and tutorials in a fraction of the time, without needing a dedicated tech writer or video editor. That's Clueso's magic! By simply recording a screencast, their AI automatically crafts a step-by-step article and a polished video tutorial. This empowers companies, especially startups and small businesses, to deliver top-notch user education and reduce customer churn, all while saving precious time and resources.

**From Desk Lamp to Clueso: Pivoting for Impact**

Neil's journey with Clueso is as inspiring as it is insightful. Originally, he and his co-founders built Desk Lamp, a note-taking app for students. However, they encountered challenges with monetization due to their target audience's price sensitivity. This valuable experience led them to pivot towards a bigger problem: the lack of efficient user education tools for companies. Clueso was born from this realization, driven by a passion for bridging the knowledge gap between products and their users.

**Key Takeaways from Neil's Founder Wisdom:**

Neil's insightful words resonated deeply throughout our conversation. Here are some key nuggets for aspiring AI product builders:
- 

**Embrace public building:** Share your journey, engage with potential users and investors, and build excitement together.
- 

**Customer validation reigns supreme:** Ensure you're truly solving a real problem by regularly seeking and acting upon user feedback.
- 

**Monetization fuels growth:** Don't wait too long to find a sustainable revenue model. Demonstrate your product's value and secure resources for continuous development.
- 

**Co-founder synergy is vital:** Surround yourself with complementary skills and a shared vision to navigate the startup rollercoaster.

**Beyond Documentation: Clueso's Impact**

Clueso's impact extends far beyond efficient documentation. Companies using their platform have reported a significant drop in support tickets related to product usage, and faster onboarding times thanks to readily available clear guides. They've even empowered users to choose their preferred learning format, further enhancing the user experience.

**A Glimpse into the Future: What's Next for Clueso?**

Neil shared their exciting vision for Clueso's future. They're actively exploring integrations with various platforms, expanding their language support, and delving into advanced AI features like personalized knowledge delivery. The goal is to continuously refine Clueso into the ultimate user education assistant, ensuring seamless product adoption and empowering every user to unlock their full potential.

**Wrapping Up: AI for User Empowerment**

Neil Bala and Clueso are pioneers in leveraging AI to democratize user education. Their story is a testament to the power of focusing on user needs, adapting to market demands, and embracing innovation. Clueso is not just a platform; it's a beacon of hope for businesses striving to bridge the knowledge gap and cultivate a seamless user experience.

We at AI Product Builders are thrilled to have shared this insightful conversation with you. Join us next week as we explore another corner of the ever-evolving AI landscape!

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Navigating the AI Revolution: Essential Skills for Product Managers in the AI Era ]]>https://srilaxmi.substack.com/p/navigating-the-ai-revolution-essentialhttps://srilaxmi.substack.com/p/navigating-the-ai-revolution-essentialTue, 14 Nov 2023 03:11:37 GMTIn the dynamic landscape of technology, artificial intelligence (AI) stands as the driving force reshaping industries and revolutionizing the business landscape. As the relentless march of AI continues, product managers find themselves at the forefront of this technological wave, compelled to acquire new skills that will not only keep them afloat but propel their careers to new heights.

- 

**AI Fundamentals Understanding:**

To effectively communicate with data scientists and engineers, product managers need to grasp the core concepts of AI, including machine learning (ML) and generative AI. While coding proficiency is not essential, understanding AI fundamentals empowers PMs to build AI products successfully. They must comprehend the strengths and limitations of different AI models, stay up-to-date with the latest advancements, and bridge the gap between technical teams and non-technical stakeholders.

**Where to start?** _**:**_
- 

Understanding the basics of machine learning algorithms (e.g., linear regression, decision trees).
- 

Familiarity with generative AI concepts, such as GANs (Generative Adversarial Networks).
- 

Familiarity with different AI models that are being used right now

_**Steps to Acquire:**_
- 

Take online courses: Platforms like Coursera, edX, and Stanford offer introductory courses on machine learning and AI.
- 

Attend workshops and conferences: Participate in events where AI experts share insights and practical knowledge.
- 

Collaborate with AI teams: Engage in cross-functional collaborations to gain hands-on experience and insights from AI professionals.

- 

**Finding use-cases around AI:**

Identifying innovative AI applications relies on a deep understanding of the target audience and their pain points. Product managers must actively explore diverse industries and domains to draw inspiration for novel AI use cases. They foster a culture of innovation within their product teams, encouraging open discussions about AI possibilities. Additionally, they develop the ability to discern when AI may not be the optimal solution, saving resources and preventing over-engineering.

**Where to start?** _**:**_
- 

Identifying AI applications in healthcare for predictive diagnostics.
- 

Exploring AI-driven personalization in e-commerce for enhanced customer experiences.
- 

Explore recommendation models 

Check out my post AI use cases - https://www.linkedin.com/posts/sri-laxmi-b5875bba_ai-innovation-technologyleaders-activity-7122080809703899136-iYzS?utm_source=share&utm_medium=member_desktop

_**Steps to Acquire:**_
- 

Industry research: Stay updated on industry trends and emerging technologies in various sectors.
- 

Foster a culture of innovation: Encourage team members to brainstorm and explore unconventional AI applications.
- 

Networking: Connect with professionals from diverse industries to gain insights into their challenges and potential AI solution

****

- 

**Data Literacy:**

Data literacy is a fundamental requirement for AI product managers. They need to develop a deep understanding of customer data to ensure its relevance, availability, and quality for AI applications. Asking the right questions and considering prior examples (supervised learning) or the need for learning without precedents (unsupervised learning) are crucial aspects of leveraging data effectively for AI solutions.

**Where to start?**

- 

Analyzing customer data to identify patterns for targeted marketing strategies.
- 

Understanding the difference between structured and unstructured data.
- 

Understand how to acquire data to train your models
- 

Understand how data can impact model quality

_**Steps to Acquire:**_
- 

Hands-on projects: Work on real-world projects that involve cleaning, analyzing, and interpreting data.
- 

Collaborate with data teams: Engage with data scientists and analysts to understand the practical aspects of working with data.
- 

Start playing with your customer data

- 

**AI Model Evaluation Expertise:**

As AI products flood the market, product managers must possess the expertise to evaluate AI models comprehensively. They establish metrics such as accuracy, precision, and recall, and also analyze model bias and fairness. By implementing automated testing and monitoring systems, they ensure consistent model performance over time. The user experience is a priority, with a focus on minimizing errors and continuously assessing and improving the models.

**Where to start?**
- 

Understand the different metrics used to measure model accuracy, quality, performance, etc
- 

Addressing bias in an AI algorithm used for resume screening. 

_**Steps to Acquire:**_
- 

Learn model evaluation metrics: Understand metrics like F1 score, ROC-AUC, and confusion matrices.
- 

Hands-on experimentation: Experiment with AI models using platforms like TensorFlow or PyTorch.
- 

Continuous learning: Stay updated on advancements in AI model evaluation techniques through research papers and conferences.

- 

**Responsible AI Awareness:**

With growing concerns about data privacy, product managers are responsible for designing AI solutions with robust data encryption, access controls, and auditing features to protect user information. Keeping up-to-date with evolving data privacy laws and regulations is crucial to ensure compliance. Collaborating with legal and compliance teams, they develop privacy policies and consent mechanisms, while also educating stakeholders about data protection best practices.

_**Steps to Acquire:**_
- 

Collaborate with legal teams: Work closely with legal and compliance teams to understand regulatory requirements.
- 

Stay informed: Regularly review updates on data privacy laws and industry best practices.

- 

**Proficiency in using AI tools:**

Product managers need to familiarize themselves with a range of AI tools and platforms available for various tasks, from data analysis to content generation. Embracing AI as an enabler of productivity rather than a threat to job roles, they train team members on the effective use of AI tools. Staying updated on the latest AI applications and tools is crucial, allowing PMs to continuously enhance their engineering skills.

   _**Steps to Acquire:**_
- 

Start using AI tools in your work 
- 

Understand how other AI tools work and the technology behind it

By combining theoretical knowledge with practical experience, product managers can effectively acquire and hone these essential AI skills, positioning themselves as adept leaders in the AI-driven landscape.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

Subscribe now

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Figma X Generative AI]]>https://srilaxmi.substack.com/p/figma-x-generative-aihttps://srilaxmi.substack.com/p/figma-x-generative-aiWed, 08 Nov 2023 03:32:12 GMT

Figma, renowned for its innovative product design applications, has recently unveiled a game-changing addition to its arsenal. FigJam AI, a suite of generative AI tools, promises to revolutionize the way teams collaborate on whiteboard projects, rendering them more efficient and accessible. This breakthrough technology, introduced in open beta, provides ready-to-use templates for various design and planning endeavors. FigJam AI's introduction marks a significant stride towards automating the creation of collaborative whiteboard projects, freeing up valuable time for creative tasks.

                                                                   [image: Figma]

### The Evolving Landscape

FigJam is Figma's collaborative whiteboard platform, a versatile tool designed for teams to work on a multitude of projects, from design tasks to meeting organization and brainstorming sessions. It has garnered popularity since its launch in 2021, boasting a user base that extends beyond traditional designers. The application leverages a digital sticky note concept to facilitate idea sharing and organization, making it a versatile workspace for diverse teams. However, as the platform's adoption grew, so did the challenges of navigating and managing the growing number of digital sticky notes.

### Empowering Creativity with AI

Recognizing these challenges, Figma introduced three generative AI features to FigJam, designed to facilitate project initiation and organization. These features aim to empower users to initiate collaborative projects more effectively, organize their ideas in a structured manner, and effortlessly distill key insights from a sea of sticky notes.

**1. Generate**: The Generate feature simplifies the creation of FigJam boards by providing suggested prompts for various templates, such as flowcharts, icebreakers, brainstorming sessions, and meeting planners. Users can also describe their desired board content in their own words, with the AI providing default descriptions for added convenience. This feature streamlines the board creation process and ensures that users have a solid starting point for their projects.

**2. Sort:** FigJam AI's Sort function automatically categorizes sticky notes based on common themes. This intelligent organization tool brings structure to an otherwise chaotic whiteboard, making it easier to find and work with related ideas. For example, after a brainstorming session, designers can effortlessly sort sticky notes into thematic groups, enhancing the overall organization of the project.

**3. Summarize:** The Summarize feature is a powerful addition that automatically generates a concise summary of information derived from groups of sticky notes. This simplifies the task of extracting key themes and insights from extensive brainstorming sessions, saving valuable time and effort in the process.

                                                                             [image: Figma]

### Unleashing the Power of OpenAI

FigJam AI relies on the robust capabilities of OpenAI's GPT-4, a large language model that has been fine-tuned to understand Figma and FigJam-specific concepts, such as diagrams and calendar objects. OpenAI's technology is a pivotal component in realizing the potential of AI-driven whiteboard collaboration. The use of AI enables FigJam to provide intelligent suggestions, simplifying project creation and management.

### Figma's Holistic Approach

Unlike many competitors who superficially integrate AI features, Figma adopts a holistic approach to enhancing its products. Rather than simply adding AI as a veneer to existing tools, Figma's AI features are the result of thoughtful internal exploration and hackathons. These features are carefully crafted to serve the specific needs of users who rely on Figma for productive cross-team collaboration, extending its utility beyond traditional design tasks.

### Conclusion

Figma's FigJam AI represents a significant leap in collaborative whiteboard technology, driven by the innovative use of generative AI. By automating the creation, organization, and summarization of whiteboard projects, Figma empowers teams to collaborate more efficiently and creatively. With a strong foundation in OpenAI technology, Figma's holistic approach to AI integration ensures that the tools are tailored to the diverse needs of its user base, setting it apart in the competitive landscape of collaborative design software. The introduction of FigJam AI ushers in a new era of streamlined and effective team collaboration, offering a promising glimpse of the future possibilities in the realm of creative workspaces.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[From Prompt to Perfection: How Copy.ai Enhances Your Writing Workflow]]>https://srilaxmi.substack.com/p/from-prompt-to-perfection-how-copyaihttps://srilaxmi.substack.com/p/from-prompt-to-perfection-how-copyaiTue, 31 Oct 2023 04:10:04 GMT1) What is Copy.ai?

Copy.ai is an innovative writing tool powered by advanced AI algorithms. Using generative AI, Copy.ai assists users in generating compelling and engaging written content across various platforms. From creating ad copy to drafting blog posts, landing page content, or social media captions, the capabilities of Copy.ai seamlessly blend human creativity with AI's computational power.

## 2) Use Cases of Copy.ai

Copy.ai offers a wide range of use cases, making it a valuable tool for individuals and businesses alike. 
- 

**Advertising Copy**: Copy.ai helps in crafting persuasive and attention-grabbing advertising copy for various platforms such as Google Ads, Facebook Ads, Instagram posts, and more.
- 

**Content Writing**: From blog posts to articles, Copy.ai assists in generating engaging and informative content on any topic, saving significant time and effort.
- 

**Email Marketing**: Writing compelling email subject lines and body text is crucial. Copy.ai streamlines the process by suggesting captivating content and boosting open and click-through rates.
- 

**Product Descriptions**: Copy.ai enables the creation of compelling product descriptions that highlight features, benefits, and key selling points, maximizing conversion rates.
- 

**Social Media Captions**: Engage your audience on platforms like Instagram, Twitter, or LinkedIn with captivating copy and catchy captions tailored to your brand's voice.

## 3) Prompts for Copy.ai with Examples

Copy.ai provides a multitude of prompts and templates to kickstart your writing process. Here are a few examples:
- 

**Blog Introduction**: "In this article, we will explore the top 5 strategies to enhance productivity."
- 

**Marketing Headline**: "Revolutionize your life with our cutting-edge technology."
- 

**Product Descriptions**: "Introducing the all-new smartphone that combines style and performance like never before."
- 

**Creative Writing Ideas**: "Write a short story about a mysterious island that grants wishes."

Subscribe now

## 4) Copy.ai stands out among other writing tools due to its unique features that elevate the content creation experience. 

1. **Versatile Writing Prompts**: Copy.ai provides a wide range of writing prompts and templates tailored to various industries and formats. Whether you need ad copy, blog introductions, email subject lines or social media captions, Copy.ai has you covered with dynamic suggestions that spark creativity.

**2. Language Translation: **Copy.ai offers a built-in language translation feature, allowing you to seamlessly translate your content into multiple languages. This functionality is particularly useful for global businesses or content creators looking to reach a broader audience.

**3. Tone and Style Adjustments:** Copy.ai lets you customize the tone and style of your generated content to match your brand's voice or the desired writing style. Whether you want your content to be professional, conversational, or humorous, Copy.ai adapts to your preferences.

4. **Word and Sentence-Level Editing:** Copy.ai allows you to edit generated content at the word and sentence level, giving you full control over the final output. You can make adjustments, add or remove information, or rephrase sentences to ensure the content aligns perfectly with your intentions.

**8. Workflow integration**: This has to be my favorite so far. Copy.ai has found a wonderful use case around AI for content writers by introducing workflow integration. You can customize your workflows and run your content work on autopilot. 

### 

### 5) Risks of Tools like Copy.ai

While Copy.ai is an incredibly powerful tool, there are a few risks associated with AI-powered content generation:
- 

**Loss of Human Touch:** The automated nature of AI writing tools may result in content that lacks the nuance and authenticity that human writers bring.
- 

**Plagiarism Concerns:** Users must exercise caution to ensure that the generated content is original and doesn't infringe upon copyright or ethical boundaries.
- 

**Algorithmic Bias:** As AI models are trained on existing data, biases present in the training data may inadvertently be reflected in the generated content. Care must be taken to address potential bias issues.

In conclusion, Copy.ai offers tremendous opportunities for individuals and organizations looking to streamline their writing process. With its broad range of use cases, versatility, and user-friendly interface, Copy.ai empowers content creators to generate persuasive and engaging copy, saving time and effort. However, it's essential to remember the limitations and risks associated with AI writing tools to ensure the quality and ethical standards of the generated content. With its ability to transform the content creation landscape, Copy.ai emerges as an indispensable tool for professionals across industries. By combining the strengths of human creativity and AI-driven efficiency, Copy.ai empowers users to generate persuasive, engaging, and high-quality content. However, it's essential to navigate the potential limitations and risks associated with AI writing tools, ensuring the ethical and authentic production of content. With Copy.ai, the future of writing assistance has arrived.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

]]><![CDATA[Getting to Know Your Virtual Friends with Character.ai]]>https://srilaxmi.substack.com/p/getting-to-know-your-virtual-friendshttps://srilaxmi.substack.com/p/getting-to-know-your-virtual-friendsTue, 24 Oct 2023 03:32:44 GMTWhat is Character.ai?

Character.ai is an AI chatbot platform that has been designed to simulate conversations with fictional characters. Using advanced natural language processing and generative AI models, Character.ai can understand questions and hold nuanced discussions on a wide range of topics. Some of the virtual characters you can chat with include famous literary characters, celebrities, historical figures, and more.

The conversations with Character.ai feel very natural and life-like. The AI is able to recall details from the character's backstory and demonstrate their unique personality. It's almost like you are actually talking to the character directly! The AI also has broad general knowledge that allows it to discuss almost any subject at a very high level.

### My Experience Using Character.ai

When I first started chatting with some of the characters on Character.ai, I was really impressed by how life-like and knowledgeable the AI seemed. I was able to recall small details about the characters and incorporate them naturally into our discussion. The AI also demonstrated unique personality traits that were consistent with how the character is portrayed.

One fun conversation I had was chatting with Spiderman about his superpowers and adventures fighting crime in New York City. The level of depth and realism in the AI's responses made it feel like I was getting insights directly from Spiderman! Overall, Character.AI provides a really engaging and immersive experience for interacting with virtual characters. It will be exciting to see how conversational AI advances in the future.

### Technology behind Character.ai

Character.ai relies on advanced natural language processing (NLP) techniques and Generative AI models to power its conversational capabilities. Specifically, it utilizes deep learning models, such as transformer-based architectures, that have been trained on large-scale datasets. These models enable the AI to understand and generate human-like responses in real time.

The underlying technology involves training these models on vast amounts of text data, which helps them acquire language patterns and contextual understanding. The training process involves running the data through multiple iterations to optimize the models' ability to generate coherent and contextually appropriate responses. This allows the AI to converse with users and simulate interactions as if the user is talking to a virtual character.

**To train each character within Character.ai, the AI models are trained on a diverse range of data sources. These sources typically include:**
- 

**Books and literature:** Character.ai incorporates a variety of literary works, from classic novels to contemporary fiction, to capture the essence and nuances of different characters.
- 

**Movies and TV shows:** Transcripts and scripts from popular movies and TV shows are utilized to grasp the personality traits, dialogue patterns, and unique characteristics associated with the chosen characters.
- 

**Interviews and biographies: **Data from interviews with actors, authors, and experts, as well as biographical information, provide insights into a character's background, experiences, and thought processes.
- 

**Online content and articles:** Online content, articles, and other relevant sources are leveraged to further enhance the knowledge base and ensure updated information for each character.

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

### **Most used characters on Character.ai?**

Character.ai offers a wide range of virtual characters to chat with, and the popularity of characters can vary depending on individual interests and preferences. However, some of the most commonly used characters on Character.AI include:
- 

Classic literary characters like Sherlock Holmes, Jane Austen heroines, and characters from Shakespeare's plays.
- 

Famous historical figures such as Abraham Lincoln, Cleopatra, and Albert Einstein.
- 

Popular fictional characters from movies and TV shows, like Harry Potter, Darth Vader, and Captain Jack Sparrow.
- 

Iconic personalities from different fields, such as Albert Einstein, Marie Curie, and Leonardo da Vinci. 

### How is each character different from one another?

Character.ai creates unique personalities for each virtual character, making them distinct from one another. These differences are based on the character's traits, background, and experiences. Here's how each character is different:
- 

**Personalities:** Each character has a distinct personality, which is developed based on their characteristics as portrayed in books, movies, or historical records. For example, Sherlock Holmes is known for his logical thinking and attention to detail, while Captain Jack Sparrow is known for his unpredictable and witty behavior.
- 

**Knowledge and expertise:** Characters vary in terms of their domain expertise. For instance, Marie Curie would have in-depth knowledge of scientific concepts and discoveries, while Darth Vader would have insights into the Star Wars universe.
- 

**Background and experiences:** The AI models used in Character.AI are trained on extensive datasets that include information about each character's background and experiences. This enables the AI to generate responses that align with the character's unique story, adding depth and authenticity to the conversations.

However, while exploring the wonders of Character.ai, it is important to be mindful of potential challenges. Privacy concerns may arise, as conversations may involve sharing personal information. It is crucial for developers and users to prioritize data privacy and security measures to ensure a safe and trustworthy experience.

Additionally, although the AI models are trained on extensive datasets, including books and interviews, there is always a possibility of misinformation or biased information being conveyed in the AI's responses. Critical thinking and verification of information are essential when interacting with virtual characters on Character. AI.

In conclusion, Character.AI demonstrates how advanced AI is transforming digital conversations. Being able to chat with fictional characters in such a life-like way opens up new possibilities for storytelling and interactive experiences.

#### A few of my favorite characters

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Spotify X Generative AI]]>https://srilaxmi.substack.com/p/spotify-x-generative-aihttps://srilaxmi.substack.com/p/spotify-x-generative-aiFri, 13 Oct 2023 03:43:49 GMTRemember when creating a playlist was an art form? Hours spent pouring over albums, debating song orders, crafting mixed tapes and CDs for your crush or road trip. Well, gone are the days of meticulously curating playlists by hand. Spotify is leveraging Generative AI to deliver personalized playlists and podcasts tailored precisely to each listener. Let's explore the three latest developments showcasing Spotify's dedication to an AI-powered future.

### **1. AI-Generated Playlists with Prompts**

Spotify users currently have access to a variety of personalized playlists, such as Discover Weekly, Daily Mix, and Release Radar. These playlists are generated using algorithms that take into account the user's listening history and preferences. However, users do not have the ability to directly control the content of these playlists.

Tired of Spotify's recommended playlists that seem to miss the mark? Soon you may be able to conjure up the perfect playlist simply by describing what you want. Recent  discoveries hint that Spotify is developing "AI playlists" based entirely on your prompts. Fancy a upbeat mix for your workout? An indie folk compilation for winding down? Or a genre-spanning party playlist? Spotify's AI could deliver playlists tailored to your exact specifications.

While Spotify hasn't officially confirmed these plans, the groundwork for such AI playlists may have been laid with the introduction of Niche mixes. These mixes allow users to build unique playlists based on textual descriptions alone, such as genre, vibe, or aesthetic. Although these mixes are not currently AI-powered, Spotify has hinted at a future where AI-generated playlists might be built using prompts.

This development highlights Spotify's dedication to leveraging AI to enhance music personalization, a journey that goes beyond just the AI DJ feature that garnered much attention

#### **How the improvement helped users:**

AI-generated playlists with prompts would give users more control over their personalized listening experience. Users could create playlists based on their own specific criteria, such as genre, mood, or activity. This would make it easier for users to find the perfect music for any occasion.

#### **Potential threats to users:**

One potential threat to users is that AI-generated playlists could be biased. For example, if the user only creates playlists based on their existing preferences, they may not be exposed to new music or genres.

Another potential threat is that AI-generated playlists could be used to manipulate users. For example, if a company wanted to promote a new song or album, they could create playlists that are biased towards that artist's music.

Subscribe now

### **2. The AI DJ **

Spotify's AI DJ feature represents a significant step towards the streamer's AI-powered future. Launched ahead of Spotify's Stream On event in early 2023, the AI DJ curates a personalized music selection combined with spoken commentary in a life like AI-generated voice. This innovative feature is underpinned by cutting-edge AI technologies, including large language models and generative voice, all integrated into Spotify's existing personalization and machine learning framework.

The AI DJ is designed to understand users so well that it can effortlessly play the music they desire with a simple tap. This marks a shift in how users engage with music on the platform, especially with its prominent placement in the revamped app.

Spotify's ability to make the AI DJ sound realistic is a game-changer. The voice was created using technology acquired from Sonantic, with a level of authenticity that sets it apart from earlier AI attempts like Google's Duplex. This technology not only captures different emotions but also imitates natural human pauses for breathing, intonations, and excitement for specific genres. This realistic AI voice is a testament to Spotify's dedication to creating a more immersive listening experience.

### **3. Podcast Voice Translation with AI**

Moving beyond music, Spotify is venturing into the realm of podcasts with its AI-powered Voice Translation feature. This groundbreaking tool uses AI, including OpenAI's voice generation technology, to translate podcasts into multiple languages while maintaining the original speaker's style and characteristics. This approach ensures a more authentic and natural listening experience compared to traditional dubbing.

As part of the pilot for Voice Translation, Spotify collaborated with renowned podcasters to generate AI-powered voice translations in languages like Spanish, French, and German. This initiative will enable podcasters' voices to be heard worldwide, breaking down language barriers and expanding the reach of podcast content.

The feedback from early adopters has been promising, reinforcing Spotify's belief that AI can forge deeper connections between creators and listeners. This project is just the beginning, with plans to extend access to more creators and languages in the future.

### In Conclusion

Spotify's journey into AI-driven personalization is far from over. From AI-generated playlists with prompts to lifelike AI DJ voices and innovative podcast translations, Spotify is committed to offering its users a more immersive and tailored experience. While these developments are exciting, they are only a glimpse of what the future holds for AI in the world of music and podcast streaming. As Spotify continues to innovate and explore the possibilities of AI, users can look forward to more personalized and engaging content in the coming years.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[Revolutionizing Photoshop: Adobe's Leap into Generative AI]]>https://srilaxmi.substack.com/p/revolutionizing-photoshop-adobeshttps://srilaxmi.substack.com/p/revolutionizing-photoshop-adobesThu, 05 Oct 2023 03:03:00 GMTIn the ever-evolving world of technology and creative innovation, Adobe has once again raised the bar for digital content creation. With the integration of generative AI powered by Firefly, Adobe Photoshop has undergone a groundbreaking transformation, offering a slew of new features that will forever change the way creators approach image editing. In this blog, we delve into the exciting enhancements that Adobe has introduced and explore how these features are poised to make Photoshop an even more indispensable tool for artists and designers.

## Generative AI Takes Center Stage:

On May 23, 2023, Adobe ushered in a new era for Photoshop by infusing it with the power of generative AI. This update introduces a host of Firefly-based features that promise to redefine image manipulation. Here's a glimpse of what's in store:

1. **Extend Beyond Borders**: Photoshop users can now effortlessly extend images beyond their original boundaries with Firefly-generated backgrounds. This feature opens up endless possibilities for creating stunning compositions and immersive visuals.

**2. Object Addition with AI:** Generative AI now allows users to seamlessly integrate objects into their images. Whether you want to add a playful twist to a photo or blend elements seamlessly, this tool empowers you to do so with unprecedented ease and precision.

**3. Precision in Object Removal:**The new generative fill feature provides an unparalleled level of precision when removing objects from images. Bid farewell to the limitations of content-aware fill as this advanced tool takes your object removal capabilities to the next level.

Subscribe now

## The Magic of Natural Language Prompts:

One of the most exciting aspects of this integration is the ability to use natural language text prompts to guide Firefly in generating images or objects. Imagine describing your vision in words, and with a few keystrokes, witnessing it come to life on your screen. While generative AI can yield unpredictable results, Adobe offers users three variations for each prompt to choose from, ensuring creative flexibility.

### A Sneak Peek at the Creative Potential:

While generative AI results can be a mixed bag, some outcomes were nothing short of impressive. For instance, Firefly was able to generate a realistic puddle beneath a running corgi, considering the lighting conditions and even adding a convincing reflection. It's evident that Firefly excels at enhancing landscapes, though it may stumble with text-based requests. Check out the image I generated using my vision and memories from Munich.

_**Prompt** - ‚ÄúCreate a surreal and dreamy nighttime cityscape with neon-lit skyscrapers reflecting in a calm, glassy river. The city is Munich‚Äù_Photo credits - Adobe

## How did Adobe train their models?

 Firefly draws its creative prowess from a vast repository of over 100 million images, including Adobe's stock images, licensed visuals, and public domain pictures. This extensive dataset forms the foundation of Firefly's ability to produce high-quality, visually captivating AI-generated content.

Adobe Stock, a treasure trove of creative assets, provides the backbone for Firefly's training. Contributors to Adobe Stock, who typically receive 33% of royalties when their images are sold or used, play a pivotal role in shaping Firefly's capabilities.

## How is it helping creators/artists/designers?

#### Design recommendations:

For creators, this means you don't have to rely only on your own instincts and skills. Firefly can be like your digital design assistant, guiding you toward creating designs that not only look good but also function optimally for users.

#### Collaboration: 

In today's fast-paced design world, teamwork is crucial. Adobe Firefly recognizes this and offers features that make it a breeze for teams to collaborate.

With Firefly, creators and team members can work together in real-time. They can easily share ideas, mark areas for improvement, and suggest changes. This eliminates the need for long, confusing email chains or chats, ensuring that everyone stays on the same page throughout the design process.

#### Seamless Integration with Adobe Creative Cloud

Adobe Firefly seamlessly fits into the Adobe Creative Cloud suite, enhancing its capabilities and opening up endless possibilities for designers. Whether you're already familiar with tools like Photoshop, Illustrator, or XD or if you're new to Adobe's world, Firefly provides a familiar and user-friendly interface that lets you use your existing skills and workflows without any hassle.

## Safety and Responsibility:

Adobe has prioritized safety in the use of generative AI. By drawing from a curated training set of images, including Adobe Stock and other commercially safe sources, the results are intended to be reliable and free from objectionable content. Additional safeguards, such as excluding certain terms and words, ensure that the generated content remains within appropriate boundaries.

## The Future Beyond Photoshop:

While these features mark a significant leap for Photoshop, Adobe has even bigger plans. The company is actively exploring the extension of Firefly's capabilities to Lightroom, its popular photo management tool. This expansion promises to unlock new creative avenues for photographers and digital artists.

## Conclusion:

With the integration of Firefly's generative AI, Adobe Photoshop has redefined the boundaries of image editing. Natural language prompts, precision object removal, and object addition with AI are just the beginning of this transformative journey. Adobe's commitment to safety and responsible AI usage ensures that creators can push the limits of their creativity without crossing any ethical lines. As we await further developments and the eventual integration of Firefly into Lightroom, it's clear that Adobe remains at the forefront of empowering digital artists and photographers with cutting-edge technology. The future of creativity has arrived, and it's more exciting than ever.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]><![CDATA[YouTube x Generative AI : AI-Powered Tools for Content Creators]]>https://srilaxmi.substack.com/p/youtube-x-generative-ai-ai-poweredhttps://srilaxmi.substack.com/p/youtube-x-generative-ai-ai-poweredTue, 26 Sep 2023 01:58:16 GMT**AI Insights for Creative Spark**

Introduction of "AI Insights for Creators," a tool designed to streamline the brainstorming process. By leveraging generative AI, this tool suggests video topics based on data derived from viewer preferences and trending content. This breakthrough innovation is poised to be a game-changer for content creators who often grapple with the challenge of ideation.

_**Advantage for Content Creators**:_ This tool not only jumpstarts the creative process but also saves valuable time and resources. Creators can confidently generate ideas that align with audience interests, reducing the uncertainty and guesswork associated with content planning.

## **Dream Screen: Fueling Creativity with AI**

Another exciting addition is "Dream Screen," which is set to empower users in the Shorts platform. This tool harnesses the power of AI to generate video or image backgrounds based on text input. Imagine typing in whimsical requests like "a panda drinking coffee" or fantastical scenarios like "underwater castles," and witnessing them come to life on screen. Dream Screen opens up new creative horizons, making it easier for individuals to produce engaging content without needing extensive production expertise.

_**Advantage for Content Creators:**_ Dream Screen eliminates the need for elaborate sets or backgrounds, allowing creators to focus on their content's essence. It offers a cost-effective solution for producing visually captivating videos, broadening the possibilities for creative expression.

## **Revolutionizing Music Selection and Dubbing**

YouTube is also expanding its Creator Music feature with AI-enhancements. Creators will soon be able to employ AI tools to simplify the process of finding suitable music for their videos. With a description-based search, they can quickly discover the perfect soundtrack that fits their vision. This feature promises to expedite music selection and licensing, making it a breeze for creators to enhance their content.

_**Advantage for Content Creators**:_ This AI-driven music selection tool not only saves time but also helps creators avoid copyright issues by suggesting suitable, licensed tracks. It enhances the overall quality of videos while simplifying the often complex task of music selection.

Additionally, YouTube is introducing an **AI-dubbing tool called "Aloud.**" This intuitive tool simplifies the process of dubbing content into different languages, offering creators the ability to reach a global audience effortlessly. By providing a one-click solution, Aloud is set to become an invaluable asset for content localization and expansion.

_**Advantage for Content Creators:**_ Aloud expands the reach of creators by making content accessible to diverse language-speaking audiences. It saves the time and resources that would otherwise be spent on manual dubbing, enabling creators to scale their content effectively.

## **A Bright Future for Content Creation**

These AI-driven innovations, poised to launch next year, mark a significant step forward in YouTube's mission to empower content creators and make content creation more accessible. With tools that inspire, simplify, and amplify creativity, YouTube is set to nurture a vibrant and diverse ecosystem of content that resonates with audiences worldwide. The future of content creation has arrived, and it's fueled by the power of AI, offering a multitude of advantages for content creators.

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.]]>

## Assistant

I've extracted all the posts from the Substack newsletter. It looks like there are actually **16 posts** (not 11 as mentioned). Here's the complete list:

---

## **Day 11: Building AI Agents - Build an AI-Powered Personal Finance Agent**  
*Published: Jan 15, 2026*

This comprehensive guide walks through building a multi-agent personal finance system using CrewAI, LangChain, and Streamlit. The system includes a Spending Analyst Agent and a Financial Advisor Agent that work together to analyze bank statements, categorize transactions, and provide personalized financial recommendations.

---

## **Day 10: Multi-Agent Competitor Analysis Agent using CrewAI**  
*Published: Jan 9, 2026*

A detailed tutorial on building a competitor analysis system that automates research, SWOT analysis, and report generation. Uses three specialized agents (Research, Analysis, Report) coordinated by CrewAI, with Streamlit for the UI and SerpAPI for web search.

---

## **Day 9: Building a Customer Support Agent with LangGraph**  
*Published: Jan 5, 2026*

Explores building a customer support agent with sentiment analysis and intelligent query routing. The agent categorizes queries (Technical, Billing, General), analyzes sentiment, and escalates negative cases to human agents. Important note: this is a foundational agent that uses LLM general knowledge (no RAG implementation included yet).

---

## **Day 8: Building a News TL;DR Agent with LangGraph**  
*Published: Jan 2, 2026*

A production-grade news summarization agent that uses NewsAPI for article discovery and web scraping for full text. Features intelligent retry logic, decision-making capabilities, and stateful workflows orchestrated by LangGraph.

---

## **Day 7: AI Deep Research Agent**  
*Published: Dec 31, 2025*

Build a Market Research Agent using the Agno framework. The system generates research questions, searches multiple sources (Google, Perplexity), synthesizes findings, and compiles professional reports. Includes three agents: Question Generator, Research Agent, and Report Compiler.

---

## **Day 6: Multi-Agent AI Travel Planner**  
*Published: Dec 30, 2025*

A comprehensive travel planning system with five specialized agents (Research, Weather, Logistics, Planner, Activities). Features live web search via DuckDuckGo, weather integration with Open-Meteo, route optimization, and calendar export functionality.

---

## **Day 5: Multi-Agent AI PM Research & PRD System Using n8n**  
*Published: Dec 26, 2025*

A PM-grade AI system with four agents: Orchestration Agent, Market Research Agent, User Research Analyst, and PRD Generator. Features intelligent routing, Tavily integration for real-time data, agent memory, and human-in-the-loop persistence control.

---

## **Day 4: Building a Full-Stack AI Journal App with Vibe Coding in Bolt**  
*Published: Dec 24, 2025*

A complete full-stack application built using Bolt's vibe coding approach. Includes calendar-based journaling, mood tracking, rich-text editor, Supabase backend, authentication, and optional AI reflection layer using OpenAI.

---

## **Day 3: Build a Custom GPT**  
*Published: Dec 23, 2025*

A guide to creating Custom GPTs, featuring the author's "PM Interview Expert" GPT (used by 15,000+ PMs). Covers instructions, knowledge documents, conversation starters, and includes 7 practice GPT ideas for different use cases.

---

## **Day 2: Automating Your Daily AI Briefs with Zapier**  
*Published: Dec 22, 2025*

Build an automation workflow that collects AI newsletters, summarizes them with AI, and delivers structured daily briefs to Slack. Covers scheduled triggers, Gmail search, AI analysis, and Slack integration.

---

## **Day 1: AI-Powered ATS Resume Reviewer & Writer Using n8n**  
*Published: Dec 19, 2025*

The first tutorial in the series, building a complete AI agent workflow in n8n that evaluates resumes against job descriptions, provides ATS scoring with detailed dimensions, and automatically rewrites resumes in Google Docs format.

---

## **Why Midjourney Chose Discord? A Creative Haven for AI Art**  
*Published: Jan 4, 2024*

An analysis of Midjourney's strategic choice to build on Discord, covering community building, resource efficiency, continuous learning from feedback, and the benefits of their collaborative approach.

---

## **From Note-Taking App to AI Savior: Clueso Founder Neil Bala on Building with User Focus**  
*Published: Dec 31, 2023*

An interview with Clueso founder Neil Bala about pivoting from a student note-taking app to an AI-powered documentation platform. Covers founder wisdom, customer validation, monetization, and co-founder dynamics.

---

## **Navigating the AI Revolution: Essential Skills for Product Managers in the AI Era**  
*Published: Nov 14, 2023*

A guide to essential skills for PMs in the AI era: AI fundamentals, finding AI use cases, data literacy, model evaluation, responsible AI, and AI tool proficiency.

---

## **Figma x Generative AI**  
*Published: Nov 8, 2023*

Explores FigJam AI's three generative features: Generate (creates boards), Sort (organizes sticky notes), and Summarize (extracts insights). Powered by OpenAI's GPT-4 and designed for better collaboration.

---

## **From Prompt to Perfection: How Copy.ai Enhances Your Writing Workflow**  
*Published: Oct 31, 2023*

An overview of Copy.ai's capabilities including advertising copy, content writing, email marketing, and social media captions. Features workflow integration, language translation, and tone adjustments.

---

## **Getting to Know Your Virtual Friends with Character.ai**  
*Published: Oct 24, 2023*

An exploration of Character.ai's chatbot platform that simulates conversations with fictional, historical, and celebrity characters. Covers the technology, training data sources, and user experience.

---

## **Spotify x Generative AI**  
*Published: Oct 13, 2023*

Details Spotify's AI initiatives: AI-generated playlists with prompts, the AI DJ feature with realistic voice, and podcast voice translation. Covers how these features enhance user experience.

---

## **Revolutionizing Photoshop: Adobe's Leap into Generative AI**  
*Published: Oct 5, 2023*

Examines Adobe's Firefly integration into Photoshop with features like extend beyond borders, object addition/removal, and natural language prompts. Trained on 100+ million images with emphasis on safety.

---

## **YouTube x Generative AI: AI-Powered Tools for Content Creators**  
*Published: Sep 26, 2023*

Covers YouTube's AI tools for creators: AI Insights for brainstorming, Dream Screen for AI-generated backgrounds, AI-enhanced music selection, and Aloud for AI dubbing into multiple languages.

---

All posts are from the **AI & Product Newsletter** by Sri Laxmi, focusing on AI product management, agent development, and practical AI tools. Would you like me to dive deeper into any specific post or extract more detailed content from any of them?

## User

i need full content

## Assistant

Here's the complete content of all posts from the AI & Product Newsletter:

---

# **Day 11: Building AI Agents - Build an AI-Powered Personal Finance Agent**

**Published:** January 15, 2026

## **Introduction: What Are AI Agents?**

An **AI Agent** is an autonomous software program that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to understand context, reason about problems, and generate intelligent responses.

### **Key Characteristics of AI Agents:**

- **Autonomy**: They can operate independently without constant human intervention
- **Perception**: They can read and understand various data formats (text, files, APIs)
- **Reasoning**: They use LLMs to analyze information and make decisions
- **Action**: They can execute tasks, generate reports, and provide recommendations
- **Goal-Oriented**: They work towards specific objectives defined by their role

### **Real-World Analogy**

Think of an AI agent like a **smart assistant**:
- A traditional program is like a calculator: you input numbers, it gives you a result
- An AI agent is like a financial advisor: you show them your bank statement, they understand the context, analyze patterns, and provide personalized advice

## **Why Multi-Agent Systems?**

Instead of one "jack-of-all-trades" agent, we use **multiple specialized agents** that collaborate. Each agent has a specific role and expertise, making the system more effective and reliable.

### **Our Finance Agent System Uses Two Agents:**

#### **1. Spending Analyst Agent**
- **Role**: Financial data analyst
- **Expertise**: Pattern recognition, categorization, data analysis
- **Responsibilities**:
  - Categorizes transactions (groceries, dining, bills, etc.)
  - Identifies spending patterns and trends
  - Calculates totals, averages, and percentages
  - Finds the largest transactions

#### **2. Financial Advisor Agent**
- **Role**: Personal financial advisor
- **Expertise**: Budgeting, financial planning, recommendations
- **Responsibilities**:
  - Creates personalized recommendations
  - Suggests realistic budgets
  - Identifies savings opportunities
  - Develops 30-day action plans

### **Why This Approach Works Better:**

- **Specialization**: Each agent focuses on what they do best
- **Quality**: Specialized agents produce better results than generalists
- **Modularity**: Easy to improve or replace individual agents
- **Collaboration**: Agents can build on each other's work
- **Scalability**: Easy to add more agents for new features

## **Technology Stack & Frameworks:**

### **Core Frameworks**

#### **1. CrewAI üöÄ**
- **What it is**: A framework for orchestrating multi-agent AI systems
- **Why do we use it**:
  - Simplifies agent coordination and task management
  - Handles agent communication and workflow
  - Built specifically for multi-agent scenarios
  - Provides clean abstractions for agents, tasks, and crews

**Key Features:**
- Agent definition and management
- Task orchestration
- Sequential and hierarchical process flows
- Built-in memory and caching

#### **2. LangChain üîó**
- **What it is**: A framework for building LLM-powered applications
- **Why do we use it**:
  - Provides standardized interfaces to LLMs
  - Handles API communication with OpenAI
  - Manages prompts and responses
  - Enables tool integration

**Key Features:**
- LLM abstraction layer
- Prompt management
- Chain composition
- Tool integration

#### **3. Streamlit üìä**
- **What it is**: A Python framework for building web applications
- **Why we use it**:
  - Rapid UI development (no HTML/CSS/JS needed)
  - Built-in components for data visualization
  - Easy file upload handling
  - Perfect for AI/ML demos and dashboards

**Key Features:**
- Simple Python-based UI
- Interactive widgets
- File upload support
- Real-time updates

### **Supporting Libraries**

#### **pandas & numpy**
- Data manipulation and analysis
- Used for processing CSV/Excel files
- Statistical calculations

#### **pdfplumber & openpyxl**
- PDF text extraction
- Excel file reading
- File format handling

#### **python-dotenv**
- Environment variable management
- Secure API key storage

#### **plotly**
- Interactive data visualization
- Charts and graphs for spending analysis

## **Project Architecture Overview**

### **System Flow**

```
User Uploads Bank Statement
         ‚Üì
Streamlit UI (streamlit_app.py)
         ‚Üì
Smart Processor (smart_processor.py)
    - Extracts transactions
    - Normalizes data format
    - Returns JSON
         ‚Üì
CrewAI Orchestrator (crew.py)
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
Spending Analyst   Financial Advisor
    Agent              Agent
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Results Displayed
```

### **Component Responsibilities**

- **User Interface Layer** (`streamlit_app.py`)
  - Handles file uploads
  - Displays results
  - User interaction

- **Data Processing Layer** (`smart_processor.py`)
  - Reads various file formats
  - Extracts transaction data
  - Normalizes to standard format
  - Handles currency detection

- **Orchestration Layer** (`crew.py`)
  - Coordinates agent execution
  - Manages task flow
  - Handles agent communication

- **Agent Layer** (`agents.py`)
  - Defines agent personalities
  - Sets roles and goals
  - Configures LLM connections

- **Task Layer** (`tasks.py`)
  - Defines what each agent should do
  - Provides instructions and context
  - Sets expected outputs

## **Understanding the Code Structure**

### **File-by-File Overview**

#### `streamlit_app.py` - The User Interface

**Purpose**: Creates the web interface that users interact with

**Key Components**:
- File upload widget for bank statements
- Progress indicators during analysis
- Results display sections
- Styling and layout

**What it does**:
- Accepts file uploads (CSV, Excel, PDF)
- Calls the processor to extract data
- Triggers the CrewAI analysis
- Displays formatted results

#### `smart_processor.py` - The Data Extractor

**Purpose**: Converts various bank statement formats into standardized transaction data

**Key Components**:
- File type detection (CSV, Excel, PDF)
- Data extraction methods
- Currency detection
- Amount normalization

**What it does**:
- Detects file format
- Reads file content
- Extracts transaction data (Date, Description, Amount)
- Normalizes amounts and dates
- Returns a JSON array of transactions

**Key Classes**:
- `SmartBankStatementProcessor`: Main processor class

**Key Methods**:
- `process_file()`: Main entry point
- `_extract_from_dataframe()`: Processes tabular data
- `_ai_extract_transactions()`: Uses LLM for PDF extraction
- `_parse_amount()`: Normalizes currency amounts

#### `agents.py` - Agent Definitions

**Purpose**: Defines the personality, role, and capabilities of each AI agent

**Key Components**:
- LLM configuration
- Agent role definitions
- Backstories (personality)
- Goals and behaviors

**What it defines**:

**Spending Analyst Agent**:
- **Role**: Spending Behavior Analyst
- **Goal**: Identify patterns and categorize expenses
- **Backstory**: Expert financial data analyst
- **Capabilities**: Pattern recognition, categorization

**Financial Advisor Agent**:
- **Role**: Personal Financial Advisor
- **Goal**: Provide personalized recommendations
- **Backstory**: Certified financial advisor
- **Capabilities**: Budgeting, planning, recommendations

#### `tasks.py` - Task Definitions

**Purpose**: Defines specific tasks for each agent with detailed instructions

**Key Components**:
- Task descriptions
- Input data context
- Output format specifications
- Instructions for agents

**What it defines**:

**Analysis Task** (for Spending Analyst):
- Receives transaction JSON
- Instructions to categorize and analyze
- Format for output (categories, totals, insights)
- Emphasis on using real numbers

**Recommendation Task** (for Financial Advisor):
- Receives analysis results
- Instructions to create recommendations
- Format for budgets and action plans
- Emphasis on personalization

#### `crew.py` - Orchestration

**Purpose**: Coordinates the multi-agent workflow

**Key Components**:
- Crew creation
- Task sequencing
- Agent coordination
- Result aggregation

**What it does**:
- Creates the first crew with Spending Analyst
- Executes analysis task
- Creates a second crew with a Financial Advisor
- Passes analysis results to advisor
- Executes the recommendation task
- Returns combined results

**Key Functions**:
- `analyze_finances()`: Main orchestration function
- Creates sequential crews
- Manages data flow between agents
- Combines results

## **Setting Up Your Environment**

### **Prerequisites**

- **Python 3.8+**: Modern Python with latest features
- **OpenAI API Key**: Access to GPT-4 (we'll cover this next)
- **Git**: For cloning the repository
- **Terminal/Command Line**: For running commands

### **Step-by-Step Setup**

#### **1. Clone the Repository**

```
git clone <repository-url>
cd "personal Finance agent"
```

#### **2. Create Virtual Environment**

**Why?** Isolates project dependencies from the system Python

```
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

#### **3. Install Dependencies**

```
pip install -r requirements.txt
```

**What gets installed**:
- CrewAI framework
- LangChain and OpenAI integration
- Streamlit for UI
- Data processing libraries (pandas, pdfplumber, etc.)

#### **4. Configure Environment Variables**

```
# Create .env file
touch .env
```

Add your API key (see next section):

```
OPENAI_API_KEY=sk-your-key-here
```

#### **5. Run the Application**

```
streamlit run streamlit_app.py
```

The app will open at http://localhost:8501

## **Getting API Keys**

### **OpenAI API Key Setup**

#### **Step 1: Create an OpenAI Account**
- Go to platform.openai.com
- Sign up or log in
- Verify your email if required

#### **Step 2: Add Payment Method**
- Navigate to **Settings** ‚Üí **Billing**
- Add a payment method (credit card)
- Set up usage limits (recommended: $10-20/month for testing)

**Why payment is needed**: GPT-4 is a paid service (pay-per-use)

#### **Step 3: Generate API Key**
- Go to the **API Keys** section
- Click **"Create new secret key."**
- Name it (e.g., "Finance Agent")
- **Copy the key immediately** (you won't see it again!)

#### **Step 4: Add to Project**
- Create `.env` file in project root
- Add: `OPENAI_API_KEY=sk-your-actual-key-here`
- **Never commit this file to Git!**

### **API Key Security Best Practices**

‚úÖ **DO**:
- Store in `.env` file
- Add `.env` to `.gitignore`
- Use environment variables in production
- Rotate keys periodically

‚ùå **DON'T**:
- Commit keys to Git
- Share keys publicly
- Hardcode in source files
- Use same key for multiple projects

### **Understanding API Costs**

**GPT-4 Pricing** (as of 2024):
- Input: ~$0.03 per 1K tokens
- Output: ~$0.06 per 1K tokens
- Typical analysis: ~$0.10-0.50 per bank statement

**Cost Optimization Tips**:
- Use GPT-3.5-turbo for simpler tasks (10x cheaper)
- Cache results when possible
- Set monthly spending limits
- Monitor usage in the OpenAI dashboard

## **Next Steps & Extensions**

### **Immediate Improvements**

- **Add More Agents**
  - Budget Tracker Agent: Monitors spending against budgets
  - Trend Analyst Agent: Identifies long-term patterns
  - Alert Agent: Flags unusual spending

- **Enhanced Features**
  - Multi-month analysis
  - Recurring transaction detection
  - Savings goal tracking
  - Export reports as PDF

- **Better UI**
  - Interactive charts (Plotly)
  - Category breakdowns
  - Spending trends over time
  - Comparison views

### **Advanced Extensions**

- **Database Integration**
  - Store transaction history
  - Track spending over time
  - Generate monthly reports

- **Real-time Monitoring**
  - Connect to bank APIs
  - Automatic transaction import
  - Daily spending alerts

- **Multi-Account Support**
  - Multiple bank accounts
  - Credit card integration
  - Investment account tracking

- **AI Enhancements**
  - Custom categorization rules
  - Predictive spending forecasts
  - Personalized savings strategies

## **Conclusion**

You've now built a sophisticated multi-agent AI system that can analyze personal finances! This project demonstrates:

‚úÖ **Multi-agent orchestration** with CrewAI  
‚úÖ **Intelligent data processing** with AI  
‚úÖ **User-friendly interface** with Streamlit  
‚úÖ **Real-world application** solving actual problems

### **Key Takeaways**

- **AI Agents** are autonomous programs that can reason and act
- **Multi-agent systems** are more powerful than single agents
- **CrewAI** simplifies agent coordination
- **Proper prompts** are crucial for good results
- **Real-world apps** need robust error handling

### **What You've Learned**

- How to structure a multi-agent system
- How to process various file formats
- How to create effective agent prompts
- How to build a production-ready UI
- How to integrate multiple frameworks and tools

**Keep experimenting, keep building, and keep learning!** üöÄ

## **Appendix: Quick Reference**

### **Project Structure**

```
personal Finance agent/
‚îú‚îÄ‚îÄ streamlit_app.py      # UI layer
‚îú‚îÄ‚îÄ smart_processor.py     # Data extraction
‚îú‚îÄ‚îÄ agents.py              # Agent definitions
‚îú‚îÄ‚îÄ tasks.py               # Task definitions
‚îú‚îÄ‚îÄ crew.py                # Orchestration
‚îú‚îÄ‚îÄ requirements.txt       # Dependencies
‚îî‚îÄ‚îÄ .env                   # API keys (not in Git)
```

### **Key Commands**

```
# Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run
streamlit run streamlit_app.py

# Check logs
# View terminal output for agent execution details
```

---

# **Day 10: Multi-Agent Competitor Analysis Agent using CrewAI**

**Published:** January 9, 2026

## **Introduction: What Are AI Agents?**

### **Understanding AI Agents**

An **AI Agent** is an autonomous software entity that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to reason, plan, and execute tasks dynamically.

Think of an AI agent as a digital employee:
- **Traditional Program**: "If X, do Y" (rigid, predefined)
- **AI Agent**: "Analyze the situation, understand the goal, and figure out the best approach" (flexible, intelligent)

### **Why Multi-Agent Systems?**

A **multi-agent system** utilizes multiple specialized agents that work together, each with distinct roles and expertise. This approach offers several advantages:
- Specialization
- Parallel processing
- Modularity
- Scalability

### **Real-World Analogy**

Imagine a business consulting firm:
- **Research Agent** = Market researcher gathering data
- **Analysis Agent** = Strategic analyst interpreting findings
- **Report Agent** = Senior consultant synthesizing insights

Each has unique skills, but together they deliver comprehensive results.

## **System Overview**

### **What We're Building**

A **Competitor Analysis System** that automatically:
- Discovers competitors in any industry
- Gathers data (pricing, features, reviews)
- Performs SWOT and competitive comparisons
- Generates executive-ready reports

### **Key Features**

- Automated research
- AI-powered SWOT analysis
- PDF export
- Streamlit web interface
- Configurable competitor depth

### **Agent Workflow**

- **Research Agent**:
  - Searches for competitors using SerpAPI
  - Gathers company information, pricing, and reviews
  - Collects market positioning data
  - Output: Structured competitor dataset

- **Analysis Agent**:
  - Receives competitor data from Research Agent
  - Performs SWOT analysis for each competitor
  - Creates competitive comparison matrices
  - Identifies market trends and gaps
  - Output: Comprehensive competitive analysis

- **Report Agent**:
  - Synthesizes research and analysis
  - Generates an executive summary
  - Creates strategic recommendations
  - Identifies opportunities and threats
  - Output: Final professional report

## **Frameworks and Technologies**

### **CrewAI ‚Äî The Orchestration Layer**

**What it is** CrewAI is a framework for orchestrating role-playing, autonomous AI agents in a collaborative environment.

**Why do we use it**
- Agent coordination
- Task sequencing
- Memory
- Tool integration
- Workflow control

**Core Concepts**
- Agents
- Tasks
- Crew
- Tools

### **Streamlit ‚Äî The Interface**

Streamlit enables rapid UI development using Python with built-in state management, widgets, and deployment support.

### **OpenAI ‚Äî The Reasoning Engine**

We use OpenAI GPT models for reasoning, analysis, and report synthesis.

**Model choice**
- `gpt-4-turbo-preview` ‚Üí complex reasoning
- `gpt-3.5-turbo` ‚Üí lighter tasks, lower cost

### **SerpAPI ‚Äî Research Without Scraping**

Provides structured Google search data safely and reliably.

### **ReportLab ‚Äî PDF Generation**

A pure-Python solution for generating professionally formatted PDF reports.

## **Architecture Deep Dive**

### **System Architecture**

```
Streamlit UI
     ‚Üì
CrewAI Orchestrator
     ‚Üì
Research Agent ‚Üí Analysis Agent ‚Üí Report Agent
     ‚Üì
PDF / UI Output
```

### **The Three-Agent System**

#### **Research Agent üîé**
Focuses on competitor discovery, pricing, reviews, and positioning.

#### **Analysis Agent üìä**
Performs SWOT, comparison matrices, and trend analysis.

#### **Report Agent üìù**
Synthesizes findings into executive-ready insights.

## **Setting Up API Keys**

### **OpenAI API Key**

- Create a key from the OpenAI dashboard
- Store in `.env`
- Never commit secrets

```
OPENAI_API_KEY=sk-xxxx
```

### **SerpAPI Key**

Free tier includes 100 searches/month.

```
SERPAPI_API_KEY=xxxx
```

## **Code Structure Overview**

```
Competitor analysis agent/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ agents.py
‚îú‚îÄ‚îÄ tasks.py
‚îú‚îÄ‚îÄ tools.py
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

Each file has a **single responsibility**, making the system easy to extend and debug.

## **How It Works: The Multi-Agent Workflow**

### **Phase-by-Phase Execution**

- User inputs company and industry
- Agents are instantiated
- The research agent gathers data
- The analysis agent interprets findings
- The report agent generates insights
- UI renders results + export options

## **Getting Started**

### **Prerequisites**

- Python 3.9+
- OpenAI API key
- SerpAPI key

### **Run Locally**

```
pip install -r requirements.txt
streamlit run app.py
```

Open: http://localhost:8501

## **Conclusion**

### **What We Built**

A **production-ready multi-agent competitor analysis system** that automates research, analysis, and reporting with minimal human input.

### **Key Takeaways**

- Multi-agent systems scale better than monolithic prompts
- Clear agent roles reduce hallucination
- Tooling is as important as prompting
- UX matters even for internal AI tools

**Happy Building üöÄ**

---

# **Day 9: Building a Customer Support Agent with LangGraph**

**Published:** January 5, 2026

## **Introduction**

In today's fast-paced business environment, customer support has become a critical differentiator. Companies that respond quickly and accurately to customer inquiries gain a significant competitive advantage. However, scaling human support teams is expensive and challenging.

Enter AI agents‚Äîintelligent systems that can automate customer interactions while maintaining quality and consistency. In this comprehensive tutorial, we'll build a sophisticated customer support agent using LangGraph, a powerful framework for creating complex AI workflows.

## **Part 1: What is an AI Agent?**

### **Understanding AI Agents**

An **AI agent** is an autonomous software system that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike simple chatbots that follow rigid scripts, AI agents use large language models (LLMs) to understand context, reason about problems, and generate appropriate responses.

### **Key Characteristics of AI Agents**

- **Autonomy**: They can operate independently without constant human intervention
- **Reactivity**: They respond to changes in their environment (like new customer queries)
- **Proactivity**: They can take initiative when appropriate
- **Social Ability**: They interact with users in natural language
- **Goal-Oriented**: They work towards specific objectives (like resolving customer issues)

### **Types of AI Agents**

- **Simple Reflex Agents**: React to current situations based on predefined rules
- **Model-Based Agents**: Maintain internal models of the world
- **Goal-Based Agents**: Work towards achieving specific goals
- **Utility-Based Agents**: Optimize for the best outcome
- **Learning Agents**: Improve performance over time

Our customer support agent is a **goal-based agent** that uses a graph-based workflow to process customer queries intelligently.

## **Part 2: Why Build This Customer Support Agent?**

### **Current Implementation Scope**

**Important**: The current implementation is a foundational customer support agent that:
- Uses OpenAI's LLM with general knowledge (no company-specific documentation)
- Does NOT include RAG (Retrieval-Augmented Generation) capabilities
- Provides a framework that can be extended with RAG and other features

This makes it perfect for learning LangGraph and as a starting point for building more sophisticated agents.

### **

## User

i want all posts in a copyable markdown format

## Assistant

# Complete AI & Product Newsletter Posts - Markdown Format

---

# Post 1: Day 11 of building AI agents: Build an AI-Powered Personal Finance Agent

**Published:** January 15, 2026

## **Introduction: What Are AI Agents?**

An **AI Agent** is an autonomous software program that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to understand context, reason about problems, and generate intelligent responses.

### **Key Characteristics of AI Agents:**

- **Autonomy**: They can operate independently without constant human intervention
- **Perception**: They can read and understand various data formats (text, files, APIs)
- **Reasoning**: They use LLMs to analyze information and make decisions
- **Action**: They can execute tasks, generate reports, and provide recommendations
- **Goal-Oriented**: They work towards specific objectives defined by their role

### **Real-World Analogy**

Think of an AI agent like a **smart assistant**:
- A traditional program is like a calculator: you input numbers, it gives you a result
- An AI agent is like a financial advisor: you show them your bank statement, they understand the context, analyze patterns, and provide personalized advice

## **Why Multi-Agent Systems?**

Instead of one "jack-of-all-trades" agent, we use **multiple specialized agents** that collaborate. Each agent has a specific role and expertise, making the system more effective and reliable.

### **Our Finance Agent System Uses Two Agents:**

#### **1. Spending Analyst Agent**

- **Role**: Financial data analyst
- **Expertise**: Pattern recognition, categorization, data analysis
- **Responsibilities**:
  - Categorizes transactions (groceries, dining, bills, etc.)
  - Identifies spending patterns and trends
  - Calculates totals, averages, and percentages
  - Finds the largest transactions

#### **2. Financial Advisor Agent**

- **Role**: Personal financial advisor
- **Expertise**: Budgeting, financial planning, recommendations
- **Responsibilities**:
  - Creates personalized recommendations
  - Suggests realistic budgets
  - Identifies savings opportunities
  - Develops 30-day action plans

### **Why This Approach Works Better:**

- **Specialization**: Each agent focuses on what they do best
- **Quality**: Specialized agents produce better results than generalists
- **Modularity**: Easy to improve or replace individual agents
- **Collaboration**: Agents can build on each other's work
- **Scalability**: Easy to add more agents for new features

## **Technology Stack & Frameworks :**

### **Core Frameworks**

#### **1. CrewAI üöÄ**

- **What it is**: A framework for orchestrating multi-agent AI systems
- **Why do we use it**:
  - Simplifies agent coordination and task management
  - Handles agent communication and workflow
  - Built specifically for multi-agent scenarios
  - Provides clean abstractions for agents, tasks, and crews

**Key Features:**
- Agent definition and management
- Task orchestration
- Sequential and hierarchical process flows
- Built-in memory and caching

#### **2. LangChain üîó**

- **What it is**: A framework for building LLM-powered applications
- **Why do we use it**:
  - Provides standardized interfaces to LLMs
  - Handles API communication with OpenAI
  - Manages prompts and responses
  - Enables tool integration

**Key Features:**
- LLM abstraction layer
- Prompt management
- Chain composition
- Tool integration

#### **3. Streamlit üìä**

- **What it is**: A Python framework for building web applications
- **Why we use it**:
  - Rapid UI development (no HTML/CSS/JS needed)
  - Built-in components for data visualization
  - Easy file upload handling
  - Perfect for AI/ML demos and dashboards

**Key Features:**
- Simple Python-based UI
- Interactive widgets
- File upload support
- Real-time updates

### **Supporting Libraries**

#### **pandas & numpy**

- Data manipulation and analysis
- Used for processing CSV/Excel files
- Statistical calculations

#### **pdfplumber & openpyxl**

- PDF text extraction
- Excel file reading
- File format handling

#### **python-dotenv**

- Environment variable management
- Secure API key storage

#### **plotly**

- Interactive data visualization
- Charts and graphs for spending analysis

## **Project Architecture Overview {#architecture}**

### **System Flow**

```
User Uploads Bank Statement
         ‚Üì
Streamlit UI (streamlit_app.py)
         ‚Üì
Smart Processor (smart_processor.py)
    - Extracts transactions
    - Normalizes data format
    - Returns JSON
         ‚Üì
CrewAI Orchestrator (crew.py)
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
Spending Analyst   Financial Advisor
    Agent              Agent
    ‚îÇ                 ‚îÇ
    ‚Üì                 ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Results Displayed
```

### **Component Responsibilities**

- **User Interface Layer** (`streamlit_app.py`)
  - Handles file uploads
  - Displays results
  - User interaction

- **Data Processing Layer** (`smart_processor.py`)
  - Reads various file formats
  - Extracts transaction data
  - Normalizes to standard format
  - Handles currency detection

- **Orchestration Layer** (`crew.py`)
  - Coordinates agent execution
  - Manages task flow
  - Handles agent communication

- **Agent Layer** (`agents.py`)
  - Defines agent personalities
  - Sets roles and goals
  - Configures LLM connections

- **Task Layer** (`tasks.py`)
  - Defines what each agent should do
  - Provides instructions and context
  - Sets expected outputs

## **Understanding the Code Structure **

### **File-by-File Overview**

#### `streamlit_app.py`** - The User Interface**

**Purpose**: Creates the web interface that users interact with

**Key Components**:
- File upload widget for bank statements
- Progress indicators during analysis
- Results display sections
- Styling and layout

**What it does**:
- Accepts file uploads (CSV, Excel, PDF)
- Calls the processor to extract data
- Triggers the CrewAI analysis
- Displays formatted results

**Key Functions**:
- File upload handling
- Progress tracking
- Error management
- Results rendering

#### `smart_processor.py`** - The Data Extractor**

**Purpose**: Converts various bank statement formats into standardized transaction data

**Key Components**:
- File type detection (CSV, Excel, PDF)
- Data extraction methods
- Currency detection
- Amount normalization

**What it does**:
- Detects file format
- Reads file content
- Extracts transaction data (Date, Description, Amount)
- Normalizes amounts and dates
- Returns a JSON array of transactions

**Key Classes**:
- `SmartBankStatementProcessor`: Main processor class
- Handles multiple file formats intelligently
- Uses AI for PDF extraction when needed

**Key Methods**:
- `process_file()`: Main entry point
- `_extract_from_dataframe()`: Processes tabular data
- `_ai_extract_transactions()`: Uses LLM for PDF extraction
- `_parse_amount()`: Normalizes currency amounts

#### `agents.py`** - Agent Definitions**

**Purpose**: Defines the personality, role, and capabilities of each AI agent

**Key Components**:
- LLM configuration
- Agent role definitions
- Backstories (personality)
- Goals and behaviors

**What it defines**:

**Spending Analyst Agent**:
- **Role**: Spending Behavior Analyst
- **Goal**: Identify patterns and categorize expenses
- **Backstory**: Expert financial data analyst
- **Capabilities**: Pattern recognition, categorization

**Financial Advisor Agent**:
- **Role**: Personal Financial Advisor
- **Goal**: Provide personalized recommendations
- **Backstory**: Certified financial advisor
- **Capabilities**: Budgeting, planning, recommendations

**Key Concepts**:
- **Role**: What the agent is (job title)
- **Goal**: What the agent should achieve
- **Backstory**: Personality and expertise (helps LLM understand context)
- **LLM**: The language model powering the agent (GPT-4)

#### `tasks.py`** - Task Definitions**

**Purpose**: Defines specific tasks for each agent with detailed instructions

**Key Components**:
- Task descriptions
- Input data context
- Output format specifications
- Instructions for agents

**What it defines**:

**Analysis Task** (for Spending Analyst):
- Receives transaction JSON
- Instructions to categorize and analyze
- Format for output (categories, totals, insights)
- Emphasis on using real numbers

**Recommendation Task** (for Financial Advisor):
- Receives analysis results
- Instructions to create recommendations
- Format for budgets and action plans
- Emphasis on personalization

**Key Concepts**:
- **Description**: What the agent should do (detailed instructions)
- **Agent**: Which agent performs this task
- **Expected Output**: What format should the result be in
- **Context**: Data passed to the agent

#### `crew.py`** - Orchestration**

**Purpose**: Coordinates the multi-agent workflow

**Key Components**:
- Crew creation
- Task sequencing
- Agent coordination
- Result aggregation

**What it does**:
- Creates the first crew with Spending Analyst
- Executes analysis task
- Creates a second crew with a Financial Advisor
- Passes analysis results to advisor
- Executes the recommendation task
- Returns combined results

**Key Functions**:
- `analyze_finances()`: Main orchestration function
- Creates sequential crews
- Manages data flow between agents
- Combines results

**Key Concepts**:
- **Crew**: A group of agents working together
- **Process**: How agents execute (sequential, hierarchical)
- **Kickoff**: Starting the crew execution
- **Sequential**: Tasks run one after another

## **Setting Up Your Environment **

### **Prerequisites**

- **Python 3.8+**: Modern Python with latest features
- **OpenAI API Key**: Access to GPT-4 (we'll cover this next)
- **Git**: For cloning the repository
- **Terminal/Command Line**: For running commands

### **Step-by-Step Setup**

#### **1. Clone the Repository**

```
git clone <repository-url>
cd "personal Finacne agent"
```

#### **2. Create Virtual Environment**

**Why?** Isolates project dependencies from the system Python

```
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**What this does**: Creates a clean Python environment just for this project

#### **3. Install Dependencies**

```
pip install -r requirements.txt
```

**What gets installed**:
- CrewAI framework
- LangChain and OpenAI integration
- Streamlit for UI
- Data processing libraries (pandas, pdfplumber, etc.)

#### **4. Configure Environment Variables**

```
# Create .env file
touch .env
```

Add your API key (see next section):

```
OPENAI_API_KEY=sk-your-key-here

```

#### **5. Run the Application**

```
streamlit run streamlit_app.py
```

The app will open at http://localhost:8501

## **Getting API Keys **

### **OpenAI API Key Setup**

#### **Step 1: Create an OpenAI Account**

- Go to platform.openai.com
- Sign up or log in
- Verify your email if required

#### **Step 2: Add Payment Method**

- Navigate to **Settings** ‚Üí **Billing**
- Add a payment method (credit card)
- Set up usage limits (recommended: $10-20/month for testing)

**Why payment is needed**: GPT-4 is a paid service (pay-per-use)

#### **Step 3: Generate API Key**

- Go to the **API Keys** section
- Click **"Create new secret key."**
- Name it (e.g., "Finance Agent")
- **Copy the key immediately** (you won't see it again!)

#### **Step 4: Add to Project**

- Create `.env` file in project root
- Add: `OPENAI_API_KEY=sk-your-actual-key-here`
- **Never commit this file to Git!**

### **API Key Security Best Practices**

‚úÖ **DO**:
- Store in `.env` file
- Add `.env` to `.gitignore`
- Use environment variables in production
- Rotate keys periodically

‚ùå **DON'T**:
- Commit keys to Git
- Share keys publicly
- Hardcode in source files
- Use same key for multiple projects

### **Understanding API Costs**

**GPT-4 Pricing** (as of 2024):
- Input: ~$0.03 per 1K tokens
- Output: ~$0.06 per 1K tokens
- Typical analysis: ~$0.10-0.50 per bank statement

**Cost Optimization Tips**:
- Use GPT-3.5-turbo for simpler tasks (10x cheaper)
- Cache results when possible
- Set monthly spending limits
- Monitor usage in the OpenAI dashboard

## **Next Steps & Extensions {#next-steps}**

### **Immediate Improvements**

- **Add More Agents**
  - Budget Tracker Agent: Monitors spending against budgets
  - Trend Analyst Agent: Identifies long-term patterns
  - Alert Agent: Flags unusual spending

- **Enhanced Features**
  - Multi-month analysis
  - Recurring transaction detection
  - Savings goal tracking
  - Export reports as PDF

- **Better UI**
  - Interactive charts (Plotly)
  - Category breakdowns
  - Spending trends over time
  - Comparison views

### **Advanced Extensions**

- **Database Integration**
  - Store transaction history
  - Track spending over time
  - Generate monthly reports

- **Real-time Monitoring**
  - Connect to bank APIs
  - Automatic transaction import
  - Daily spending alerts

- **Multi-Account Support**
  - Multiple bank accounts
  - Credit card integration
  - Investment account tracking

- **AI Enhancements**
  - Custom categorization rules
  - Predictive spending forecasts
  - Personalized savings strategies

### **Learning Resources**

**CrewAI Documentation**:
- Official Docs
- GitHub Examples

**LangChain Resources**:
- LangChain Docs
- Tutorials

**Streamlit Guides**:
- Streamlit Docs
- Gallery

## **Conclusion**

You've now built a sophisticated multi-agent AI system that can analyze personal finances! This project demonstrates:

‚úÖ **Multi-agent orchestration** with CrewAI ‚úÖ **Intelligent data processing** with AI ‚úÖ **User-friendly interface** with Streamlit ‚úÖ **Real-world application** solving actual problems

### **Key Takeaways**

- **AI Agents** are autonomous programs that can reason and act
- **Multi-agent systems** are more powerful than single agents
- **CrewAI** simplifies agent coordination
- **Proper prompts** are crucial for good results
- **Real-world apps** need robust error handling

### **What You've Learned**

- How to structure a multi-agent system
- How to process various file formats
- How to create effective agent prompts
- How to build a production-ready UI
- How to integrate multiple frameworks and tools

**Keep experimenting, keep building, and keep learning!** üöÄ

## **Appendix: Quick Reference**

### **Project Structure**

```
personal Finacne agent/
‚îú‚îÄ‚îÄ streamlit_app.py      # UI layer
‚îú‚îÄ‚îÄ smart_processor.py     # Data extraction
‚îú‚îÄ‚îÄ agents.py              # Agent definitions
‚îú‚îÄ‚îÄ tasks.py               # Task definitions
‚îú‚îÄ‚îÄ crew.py                # Orchestration
‚îú‚îÄ‚îÄ requirements.txt       # Dependencies
‚îî‚îÄ‚îÄ .env                   # API keys (not in Git)

```

### **Key Commands**

```
# Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run
streamlit run streamlit_app.py

# Check logs
# View terminal output for agent execution details
```

### **Important Files**

- `.env`: Contains your API key (never commit!)
- `requirements.txt`: All Python dependencies
- `agents.py`: Define your AI agents
- `tasks.py`: Define what agents should do

---

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

## **Frequently Asked Questions (FAQ)**

### What is an AI agent in simple terms?

An **AI agent** is an intelligent software system that can understand information, make decisions, and take actions on its own to achieve a goal. Unlike traditional programs that follow fixed rules, AI agents use large language models (LLMs) to reason, adapt, and respond intelligently to different situations.

### How is an AI agent different from a chatbot?

A chatbot mainly **responds to questions**, while an AI agent can **analyze data, make decisions, and perform tasks**. In this project, AI agents don't just answer queries‚Äîthey analyze bank statements, detect spending patterns, and generate personalized financial advice.

### What is a multi-agent system?

A **multi-agent system** is a setup where multiple AI agents, each with a specific role, work together to solve a problem. Instead of one general-purpose agent, tasks are divided among specialized agents, resulting in better accuracy, scalability, and maintainability.

### Why use multiple AI agents instead of a single agent?

Using multiple AI agents improves results because of:
- **Specialization**: Each agent focuses on what it does best
- **Higher quality outputs**: Specialists outperform generalists
- **Scalability**: New agents can be added easily
- **Modularity**: Individual agents can be upgraded or replaced

This finance system uses one agent for **spending analysis** and another for **financial recommendations**, making insights more reliable.

### What does the Spending Analyst Agent do?

The **Spending Analyst Agent** processes transaction data and:
- Categorizes expenses (groceries, rent, dining, etc.)
- Identifies spending trends and patterns
- Calculates totals, averages, and percentages
- Detects large or unusual transactions

It focuses purely on **data analysis**, not advice.

### What does the Financial Advisor Agent do?

The **Financial Advisor Agent** takes the analyzed data and:
- Creates personalized budgeting suggestions
- Identifies saving opportunities
- Recommends spending improvements
- Generates a practical 30-day financial action plan

This agent focuses on **decision-making and guidance**, not raw analysis.

### What frameworks are used to build this AI finance agent?

This project uses:
- **CrewAI** for orchestrating multiple AI agents
- **LangChain** for interacting with large language models and tools
- **Streamlit** for building the web-based user interface

Together, these frameworks make it easy to build, manage, and scale multi-agent AI applications.

### Can this AI agent read PDF and Excel bank statements?

Yes. The system supports **CSV, Excel, and PDF** bank statements. It automatically detects the file type, extracts transactions, normalizes the data, and converts everything into a structured JSON format for analysis.

### Is my financial data stored or saved anywhere?

No. By default, the application processes data **in-memory only**. Your bank statement is analyzed during the session and not stored in any database unless you explicitly add storage features.

### Do I need coding experience to use this app?

To **use** the app, no coding experience is required. To **build or extend** the system, basic Python knowledge is helpful, especially for working with frameworks like Streamlit, LangChain, and CrewAI.

### Is an OpenAI API key required?

Yes. The system uses OpenAI models to power reasoning and PDF extraction. You'll need:
- An OpenAI account
- A valid API key
- A small budget (typically under $1 per analysis for testing)

### How much does it cost to run this AI finance agent?

Costs depend on usage, but typically:
- One bank statement analysis costs around **$0.10‚Äì$0.50**
- Costs can be reduced by caching results or using cheaper models for simpler tasks

You can set monthly spending limits in your OpenAI dashboard.

### Can this project be used in production?

Yes, with some enhancements. For production use, consider adding:
- Secure authentication
- Database storage
- Rate limiting
- Error monitoring
- API-based bank integrations

The current version is ideal for **learning, demos, and prototypes**.

### Can I add more AI agents to this system?

Absolutely. The architecture is designed for extension. You can easily add agents such as:
- Budget Tracking Agent
- Fraud or Anomaly Detection Agent
- Savings Goal Agent
- Long-term Trend Analysis Agent

This is one of the biggest advantages of a multi-agent design.

### What skills will I learn from this project?

By building this system, you learn:
- How AI agents work
- Multi-agent orchestration patterns
- Real-world LLM application design
- File processing and data normalization
- Prompt design and task decomposition
- Building AI-powered web apps

### Who is this project best suited for?

This project is ideal for:
- AI/ML engineers
- Product managers exploring AI agents
- Developers learning multi-agent systems
- Anyone building real-world LLM applications
- Learners transitioning from chatbots to agentic AI

If you're interested in building **practical, real-world AI agents**, this finance agent is a great place to start üöÄ

---

# Post 2: Day 10 of building AI agents: Multi-Agent Competitor Analysis Agent using Crew AI

**Published:** January 9, 2026

## **Introduction: What Are AI Agents?**

### **Understanding AI Agents**

An **AI Agent** is an autonomous software entity that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike traditional programs that follow rigid instructions, AI agents use Large Language Models (LLMs) to reason, plan, and execute tasks dynamically.

Think of an AI agent as a digital employee:
- **Traditional Program**: "If X, do Y" (rigid, predefined)
- **AI Agent**: "Analyze the situation, understand the goal, and figure out the best approach" (flexible, intelligent)

### **Why Multi-Agent Systems?**

A **multi-agent system** utilizes multiple specialized agents that work together, each with distinct roles and expertise. This approach offers several advantages:
- Specialization
- Parallel processing
- Modularity
- Scalability

### **Real-World Analogy**

Imagine a business consulting firm:
- **Research Agent** = Market researcher gathering data
- **Analysis Agent** = Strategic analyst interpreting findings
- **Report Agent** = Senior consultant synthesizing insights

Each has unique skills, but together they deliver comprehensive results.

## **System Overview**

### **What We're Building**

A **Competitor Analysis System** that automatically:
- Discovers competitors in any industry
- Gathers data (pricing, features, reviews)
- Performs SWOT and competitive comparisons
- Generates executive-ready reports

### **Key Features**

- Automated research
- AI-powered SWOT analysis
- PDF export
- Streamlit web interface
- Configurable competitor depth

### **Agent Workflow**

- **Research Agent**:
  - Searches for competitors using SerpAPI
  - Gathers company information, pricing, and reviews
  - Collects market positioning data
  - Output: Structured competitor dataset

- **Analysis Agent**:
  - Receives competitor data from Research Agent
  - Performs SWOT analysis for each competitor
  - Creates competitive comparison matrices
  - Identifies market trends and gaps
  - Output: Comprehensive competitive analysis

- **Report Agent**:
  - Synthesizes research and analysis
  - Generates an executive summary
  - Creates strategic recommendations
  - Identifies opportunities and threats
  - Output: Final professional report

## **Frameworks and Technologies**

### **CrewAI ‚Äî The Orchestration Layer**

**What it is** CrewAI is a framework for orchestrating role-playing, autonomous AI agents in a collaborative environment.

**Why do we use it**
- Agent coordination
- Task sequencing
- Memory
- Tool integration
- Workflow control

**Core Concepts**
- Agents
- Tasks
- Crew
- Tools

### **Streamlit ‚Äî The Interface**

Streamlit enables rapid UI development using Python with built-in state management, widgets, and deployment support.

### **OpenAI ‚Äî The Reasoning Engine**

We use OpenAI GPT models for reasoning, analysis, and report synthesis.

**Model choice**
- `gpt-4-turbo-preview` ‚Üí complex reasoning
- `gpt-3.5-turbo` ‚Üí lighter tasks, lower cost

### **SerpAPI ‚Äî Research Without Scraping**

Provides structured Google search data safely and reliably.

### **ReportLab ‚Äî PDF Generation**

A pure-Python solution for generating professionally formatted PDF reports.

## **Architecture Deep Dive**

### **System Architecture**

```
Streamlit UI
     ‚Üì
CrewAI Orchestrator
     ‚Üì
Research Agent ‚Üí Analysis Agent ‚Üí Report Agent
     ‚Üì
PDF / UI Output

```

### **The Three-Agent System**

#### **Research Agent üîé**
Focuses on competitor discovery, pricing, reviews, and positioning.

#### **Analysis Agent üìä**
Performs SWOT, comparison matrices, and trend analysis.

#### **Report Agent üìù**
Synthesizes findings into executive-ready insights.

## **Setting Up API Keys**

### **OpenAI API Key**

- Create a key from the OpenAI dashboard
- Store in `.env`
- Never commit secrets

```
OPENAI_API_KEY=sk-xxxx

```

### **SerpAPI Key**

Free tier includes 100 searches/month.

```
SERPAPI_API_KEY=xxxx

```

## **Code Structure Overview**

```
Competitor analysis agent/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ agents.py
‚îú‚îÄ‚îÄ tasks.py
‚îú‚îÄ‚îÄ tools.py
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md

```

Each file has a **single responsibility**, making the system easy to extend and debug.

## **How It Works: The Multi-Agent Workflow**

### **Phase-by-Phase Execution**

- User inputs company and industry
- Agents are instantiated
- The research agent gathers data
- The analysis agent interprets findings
- The report agent generates insights
- UI renders results + export options

## **Getting Started**

### **Prerequisites**

- Python 3.9+
- OpenAI API key
- SerpAPI key

### **Run Locally**

```
pip install -r requirements.txt
streamlit run app.py

```

Open: http://localhost:8501

## **Conclusion**

### **What We Built**

A **production-ready multi-agent competitor analysis system** that automates research, analysis, and reporting with minimal human input.

### **Key Takeaways**

- Multi-agent systems scale better than monolithic prompts
- Clear agent roles reduce hallucination
- Tooling is as important as prompting
- UX matters even for internal AI tools

**Happy Building üöÄ**

_If this helped you understand multi-agent systems better, consider sharing it with others exploring agentic AI._

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

## **Frequently Asked Questions (FAQ)**

### What is a multi-agent system in AI?

A **multi-agent system** is an AI architecture in which multiple autonomous agents collaborate to achieve a shared goal. Each agent has a specific role (such as research, analysis, or reporting) and collaborates through an orchestration framework. Multi-agent systems are commonly used for complex workflows like competitor analysis, customer support, and research automation.

### How is an AI agent different from a chatbot?

A chatbot typically follows predefined conversation flows or single prompts, while an **AI agent** can reason, plan, use tools, and execute multi-step tasks autonomously. In this tutorial, each agent performs a specialized function‚Äîresearching competitors, analyzing data, or generating strategic reports‚Äîwithout manual intervention.

### Why use multiple AI agents instead of one large prompt?

Using multiple agents improves:
- **Accuracy** through specialization
- **Scalability** for complex workflows
- **Maintainability** by isolating responsibilities
- **Parallel processing** for faster execution

A single prompt struggles with long, multi-stage reasoning, while multi-agent systems handle complexity more reliably.

### What is CrewAI, and why is it used in this tutorial?

**CrewAI** is an AI agent orchestration framework that manages:
- Agent roles and goals
- Task sequencing and dependencies
- Memory and context sharing
- Tool usage

It simplifies building production-grade multi-agent systems without writing custom orchestration logic.

### Can this competitor analysis system be used for any industry?

Yes. The system is **industry-agnostic**. You can analyze competitors in:
- SaaS
- Fintech
- E-commerce
- Healthcare
- EdTech
- Consumer apps

The agents dynamically adapt their research and analysis based on the company and industry input.

### How accurate is AI-based competitor analysis?

Accuracy depends on:
- Quality of search data
- Prompt and agent design
- Tool reliability

This system reduces hallucinations by:
- Using real search APIs (SerpAPI)
- Separating research from analysis
- Structuring data before synthesis

It's suitable for **strategic insights**, not legal or financial advice.

### What APIs are required to run this project?

You need:
- **OpenAI API** for reasoning and text generation
- **SerpAPI** for competitor research

Both offer free or low-cost tiers, making this system accessible for experimentation and small-scale use.

### How much does it cost to run this multi-agent system?

Typical costs depend on:
- Number of competitors analyzed
- Analysis depth
- LLM model used

Approximate range:
- Small analysis (2‚Äì3 competitors): a few cents to a few dollars
- Deep analysis (5 competitors): higher but still cost-effective compared to manual research

### Is this system production-ready?

Yes, the architecture is **production-oriented**:
- Modular agent design
- Clear task separation
- Error handling
- Exportable reports
- Configurable depth and limits

For large-scale use, you can add caching, databases, and job queues.

### Can I extend this system with more agents?

Absolutely. You can add:
- Pricing intelligence agents
- Sales positioning agents
- Product feature comparison agents
- Monitoring or alerting agents

The modular design makes extension straightforward.

### Do I need prior AI or ML experience to follow this tutorial?

Basic Python knowledge is helpful, but you **don't need ML expertise**. The tutorial focuses on:
- System design
- Agent roles and workflows
- Practical implementation concepts

It's suitable for product managers, founders, developers, and AI enthusiasts.

### How long does a full competitor analysis take?

Depending on depth:
- **Quick analysis**: 5‚Äì10 minutes
- **Standard analysis**: 10‚Äì20 minutes
- **Deep analysis**: 20‚Äì30 minutes

Most time is spent on research and synthesis, not UI rendering.

### Can this be used as an internal business intelligence tool?

Yes. Many teams use similar systems for:
- Strategy planning
- Market research
- Sales enablement
- Investor decks

You can run it internally or integrate it into existing dashboards.

### What are common challenges when building multi-agent systems?

Common challenges include:
- Hallucinations
- Task overlap between agents
- Poor tool integration
- Long execution times

This tutorial addresses them through clear agent boundaries, structured outputs, and tool-based grounding.

### Is this better than traditional market research tools?

It doesn't replace professional research platforms, but it:
- Automates repetitive work
- Generates faster insights
- Adapts dynamically
- Costs significantly less

It's ideal for **early-stage analysis, strategy exploration, and continuous monitoring**.

---

# Post 3: Day 9 of Building AI Agents: Building a Customer Support Agent with LangGraph

**Published:** January 5, 2026

**Introduction**

In today's fast-paced business environment, customer support has become a critical differentiator. Companies that respond quickly and accurately to customer inquiries gain a significant competitive advantage. However, scaling human support teams is expensive and challenging.

Enter AI agents‚Äîintelligent systems that can automate customer interactions while maintaining quality and consistency. In this comprehensive tutorial, we'll build a sophisticated customer support agent using LangGraph, a powerful framework for creating complex AI workflows.

## **Part 1: What is an AI Agent?**

### **Understanding AI Agents**

An **AI agent** is an autonomous software system that can perceive its environment, make decisions, and take actions to achieve specific goals. Unlike simple chatbots that follow rigid scripts, AI agents use large language models (LLMs) to understand context, reason about problems, and generate appropriate responses.

### **Key Characteristics of AI Agents**

- **Autonomy**: They can operate independently without constant human intervention
- **Reactivity**: They respond to changes in their environment (like new customer queries)
- **Proactivity**: They can take initiative when appropriate
- **Social Ability**: They interact with users in natural language
- **Goal-Oriented**: They work towards specific objectives (like resolving customer issues)

### **Types of AI Agents**

- **Simple Reflex Agents**: React to current situations based on predefined rules
- **Model-Based Agents**: Maintain internal models of the world
- **Goal-Based Agents**: Work towards achieving specific goals
- **Utility-Based Agents**: Optimize for the best outcome
- **Learning Agents**: Improve performance over time

Our customer support agent is a **goal-based agent** that uses a graph-based workflow to process customer queries intelligently.

## **Part 2: Why Build This Customer Support Agent?**

### **Current Implementation Scope**

**Important**: The current implementation is a foundational customer support agent that:
- Uses OpenAI's LLM with general knowledge (no company-specific documentation)
- Does NOT include RAG (Retrieval-Augmented Generation) capabilities
- Provides a framework that can be extended with RAG and other features

This makes it perfect for learning LangGraph and as a starting point for building more sophisticated agents.

### **The Problem**

Traditional customer support faces several challenges:
- **High Volume**: Companies receive thousands of queries daily
- **24/7 Expectations**: Customers expect round-the-clock support
- **Consistency**: Ensuring all agents provide accurate, consistent information
- **Cost**: Scaling human support teams is expensive
- **Response Time**: Long wait times frustrate customers

### **The Solution**

Our AI agent addresses these challenges by:
- **Automating Routine Queries**: Handling common questions instantly
- **Categorizing Issues**: Automatically routing queries to appropriate handlers
- **Sentiment Analysis**: Identifying frustrated customers for priority escalation
- **Consistent Responses**: Providing accurate, uniform information every time
- **Scalability**: Handling unlimited queries without additional cost

### **Real-World Impact**

- **Reduced Response Time**: From hours to seconds
- **Cost Savings**: Automating 60-80% of routine queries
- **Improved Satisfaction**: Instant responses improve customer experience
- **Human Focus**: Agents can focus on complex issues requiring human judgment

## **Part 3: Understanding LangGraph**

### **What is LangGraph?**

**LangGraph** is a library for building stateful, multi-actor applications with LLMs. It extends LangChain by adding:
- **State Management**: Maintains context throughout the conversation
- **Graph-Based Workflows**: Visual representation of agent logic
- **Conditional Routing**: Dynamic decision-making based on state
- **Cycles and Loops**: Support for iterative processes

### **Why LangGraph for Customer Support?**

- **Complex Workflows**: Customer support requires multiple steps (categorize ‚Üí analyze ‚Üí respond)
- **State Management**: Need to track query, category, sentiment, and response
- **Conditional Logic**: Different paths based on query type and sentiment
- **Extensibility**: Easy to add new handlers or modify workflow

### **Our Workflow Architecture**

```
Customer Query
    ‚Üì
[Categorize] ‚Üí Technical, Billing, or General
    ‚Üì
[Analyze Sentiment] ‚Üí Positive, Neutral, or Negative
    ‚Üì
[Route Query] ‚Üí Decision point
    ‚îú‚îÄ Negative ‚Üí [Escalate to Human]
    ‚îú‚îÄ Technical ‚Üí [Handle Technical]
    ‚îú‚îÄ Billing ‚Üí [Handle Billing]
    ‚îî‚îÄ General ‚Üí [Handle General]
    ‚Üì
[Generate Response]

```

## **Part 4: Project Structure and Files**

Let's explore the codebase at a high level to understand how everything fits together.

### **File Overview**

Our customer support agent consists of several key files, each serving a specific purpose:

#### **1. `app.py`** - The Main Application**

**Purpose**: Contains the core agent logic and workflow definition.

**Key Components**:
- **State Definition**: `State` TypedDict that holds query information throughout the workflow
- **Node Functions**: Individual processing steps (categorize, analyze_sentiment, handle_technical, etc.)
- **Graph Construction**: Builds the LangGraph workflow with nodes and edges
- **Main Execution**: CLI interface for running queries

**What it does**:
- Defines the workflow structure
- Implements each processing step
- Compiles the graph into an executable application
- Provides command-line interface for testing

**Note**: This file does NOT include RAG functionality. It uses only the LLM's general knowledge. See Part 6 for how to add RAG capabilities.

#### **2. `config.py`** - Configuration Management**

**Purpose**: Handles environment variables and configuration settings.

**Key Components**:
- Loads environment variables from `.env` file
- Validates required configuration (like API keys)
- Provides configuration validation function

**What it does**:
- Centralizes configuration management
- Ensures required settings are present before execution
- Makes it easy to manage different environments

#### **3. `requirements.txt`** - Dependencies**

**Purpose**: Lists all Python packages required for the project.

**Dependencies**:
- `langgraph`: Graph-based workflow orchestration
- `langchain-core`: Core LangChain functionality
- `langchain-openai`: OpenAI integration
- `python-dotenv`: Environment variable management

**What it does**:
- Ensures consistent environment across installations
- Makes dependency management simple with `pip install -r requirements.txt`

#### **4. `.env.example`** - Environment Template**

**Purpose**: Template for environment variables.

**Contents**:
- `OPENAI_API_KEY`: Placeholder for OpenAI API key

**What it does**:
- Shows what environment variables are needed
- Provides a template for users to create their own `.env` file

#### **5. `README.md`** - Documentation**

**Purpose**: Comprehensive project documentation.

**Contents**:
- Project overview and features
- Installation instructions
- Usage examples
- Architecture explanation
- Customization guide

**What it does**:
- Helps users understand and use the project
- Provides examples and troubleshooting tips

### **How Files Work Together**

```
User runs: python app.py "query"
    ‚Üì
app.py loads config.py ‚Üí Validates API key
    ‚Üì
app.py creates workflow ‚Üí Uses LangGraph
    ‚Üì
Workflow processes query ‚Üí Through nodes
    ‚Üì
Returns result ‚Üí Category, Sentiment, Response

```

## **Part 5: How the Agent Works**

### **Step-by-Step Process**

- **Input**: Customer query is received
- **Categorization**: Query is classified as Technical, Billing, or General
- **Sentiment Analysis**: Emotional tone is determined (Positive, Neutral, Negative)
- **Routing**: Based on sentiment and category, query is routed to appropriate handler
- **Response Generation**: Handler generates contextually appropriate response
- **Output**: Customer receives categorized, sentiment-analyzed response

### **Decision Logic**

The agent uses conditional routing:
- **If sentiment is Negative** ‚Üí Escalate to human agent
- **Else if category is Technical** ‚Üí Route to technical handler
- **Else if category is Billing** ‚Üí Route to billing handler
- **Else** ‚Üí Route to general handler

This ensures that frustrated customers get immediate human attention while routine queries are handled automatically.

## **Part 6: Adding Company Documentation (RAG Pipeline)**

### **Important Note**

‚ö†Ô∏è **The current code implementation does NOT include RAG.** This section explains how you can add RAG functionality to enhance the agent with your company's documentation. The existing code uses only the LLM's general knowledge without any document retrieval capabilities.

### **Why Add Company Docs?**

Currently, the agent uses only the LLM's general knowledge. To make it truly useful, we need to integrate your company's specific documentation, policies, and knowledge base. This requires implementing a RAG (Retrieval-Augmented Generation) pipeline, which is not included in the current codebase.

### **What is RAG?**

**RAG (Retrieval-Augmented Generation)** is a technique that:
- **Retrieves** relevant information from your documents
- **Augments** the LLM prompt with this context
- **Generates** responses using both general knowledge and your specific information

### **How RAG Works**

```
Customer Query
    ‚Üì
[Embed Query] ‚Üí Convert to vector representation
    ‚Üì
[Search Vector DB] ‚Üí Find similar document chunks
    ‚Üì
[Retrieve Top-K Chunks] ‚Üí Get most relevant information
    ‚Üì
[Combine with Query] ‚Üí Create augmented prompt
    ‚Üì
[LLM Generation] ‚Üí Response using company docs

```

### **Implementation Steps**

**Note**: The following steps are NOT implemented in the current code. They represent what you would need to do to add RAG functionality.

To add RAG to this agent, you would need to:

- **Document Ingestion**:
  - Load company documents (PDFs, text files, markdown)
  - Split into chunks (typically 500-1000 characters)
  - Generate embeddings for each chunk
  - Store in vector database

- **Retrieval System**:
  - Convert customer query to embedding
  - Search vector database for similar chunks
  - Retrieve top-K most relevant chunks

- **Integration**:
  - Modify handler functions to include retrieved context
  - Update prompts to use company-specific information
  - Ensure responses reference your documentation

- **Vector Database Options**:
  - **ChromaDB**: Simple, in-memory or persistent
  - **FAISS**: Facebook's vector similarity search
  - **Qdrant**: Production-ready vector database
  - **Pinecone**: Managed vector database service

### **Example Integration (Not in Current Code)**

**This is example code showing how you COULD modify the agent to include RAG. This is not part of the current implementation.**

Here's how you would modify a handler function to use RAG:

```
def handle_technical(state: State) -> State:
    # Retrieve relevant documentation
    relevant_docs = vector_db.search(state["query"], top_k=3)
    
    # Create augmented prompt
    prompt = ChatPromptTemplate.from_template(
        "Using the following company documentation:\n{context}\n\n"
        "Provide a technical support response to: {query}"
    )
    
    # Generate response with context
    chain = prompt | ChatOpenAI(temperature=0)
    response = chain.invoke({
        "query": state["query"],
        "context": "\n".join(relevant_docs)
    }).content
    
    return {"response": response}
```

### **Benefits of Adding RAG**

- **Accurate Information**: Responses based on your actual documentation
- **Consistency**: All responses align with company policies
- **Up-to-Date**: Easy to update by adding new documents
- **Brand Voice**: Maintains your company's communication style

## **Part 7: Installation and Setup**

### **Prerequisites**

- Python 3.8 or higher
- OpenAI API key
- pip package manager

### **Step-by-Step Installation**

- **Navigate to the project directory**:

```
cd "agents/customer support"
```

- **Install dependencies**:

```
pip install -r requirements.txt
```

- **Set up environment variables**:

```
cp .env.example .env
```

- Then edit `.env` and add your OpenAI API key:

```
OPENAI_API_KEY=your_actual_api_key_here

```

- **Verify installation**:

```
python app.py
```

### **Running the Agent**

**With example queries**:

```
python app.py
```

**With your own query**:

```
python app.py "Your customer question here"
```

## **Part 8: Usage Examples**

### **Example 1: Technical Query**

```
python app.py "How do I reset my password?"
```

**Result**:
- Category: Technical
- Sentiment: Neutral
- Response: Step-by-step password reset instructions

### **Example 2: Billing Query**

```
python app.py "Where can I find my receipt?"
```

**Result**:
- Category: Billing
- Sentiment: Neutral
- Response: Instructions on accessing receipts

### **Example 3: Escalation Case**

```
python app.py "This is terrible! I want a refund now!"
```

**Result**:
- Category: Billing
- Sentiment: Negative
- Response: Escalated to human agent

## **Part 9: Customization and Extension**

### **Customizing Categories**

To add new categories (e.g., "Shipping"):
- Update the `categorize()` function prompt
- Add a new handler function `handle_shipping()`
- Update `route_query()` to include the new category
- Add the new node to the graph

### **Modifying Sentiment Analysis**

To change sentiment thresholds or add more granular sentiment:
- Update the `analyze_sentiment()` function prompt
- Modify `route_query()` to handle new sentiment levels
- Add corresponding routing logic

### **Adding New Handlers**

To add a new handler for a specific query type:
- Create a new function following the pattern:

```
def handle_new_type(state: State) -> State:
    prompt = ChatPromptTemplate.from_template(
        "Provide response for: {query}"
    )
    chain = prompt | ChatOpenAI(temperature=0)
    response = chain.invoke({"query": state["query"]}).content
    return {"response": response}
```

- Add node to graph: `workflow.add_node("handle_new_type", handle_new_type)`
- Update routing logic in `route_query()`

## **Part 10: Best Practices and Tips**

### **1. Prompt Engineering**

- **Be Specific**: Clear instructions produce better results
- **Use Examples**: Few-shot examples improve accuracy
- **Set Temperature**: Use `temperature=0` for consistent, factual responses

### **2. Error Handling**

- Always validate API keys before execution
- Handle API rate limits gracefully
- Provide helpful error messages to users

### **3. Monitoring**

- Log all queries and responses
- Track categorization accuracy
- Monitor sentiment distribution
- Measure response quality

### **4. Security**

- Never expose API keys in code
- Use environment variables
- Validate user inputs
- Sanitize outputs if displaying in web interfaces

### **5. Performance**

- Cache common responses
- Batch similar queries
- Use streaming for long responses
- Monitor API costs

## **Part 11: Future Enhancements**

### **Potential Improvements**

- **Multi-Language Support**: Add translation capabilities
- **Voice Integration**: Support voice queries and responses
- **Analytics Dashboard**: Visualize query patterns and trends
- **A/B Testing**: Compare different prompt strategies
- **Learning System**: Improve from feedback
- **Integration**: Connect to ticketing systems, CRM, etc.
- **Web Interface**: Build a user-friendly web UI
- **API Endpoint**: Expose as REST API for integration

### **Scaling Considerations**

- **Rate Limiting**: Implement to prevent abuse
- **Caching**: Cache frequent queries
- **Load Balancing**: Distribute load across instances
- **Database**: Store conversation history
- **Monitoring**: Track performance metrics

## **Part 12: Conclusion**

### **What We've Built**

We've created a foundational customer support agent that:
- Automatically categorizes customer queries
- Analyzes sentiment to prioritize urgent issues
- Routes queries to appropriate handlers
- Generates contextually appropriate responses using LLM general knowledge
- Escalates complex or negative cases to humans

**Note**: The current implementation does NOT include RAG. It uses OpenAI's general knowledge. To add company-specific documentation, you would need to implement the RAG pipeline described in Part 6.

### **Key Takeaways**

- **AI Agents** can automate complex workflows using graph-based architectures
- **LangGraph** provides powerful tools for building stateful AI applications
- **RAG** enables agents to use company-specific knowledge
- **Modular Design** makes it easy to extend and customize

### **Next Steps**

- Test the agent with your own queries
- Customize categories and handlers for your use case
- Consider adding RAG for company-specific information
- Integrate with your existing support systems
- Monitor and iterate based on real-world usage

### **Resources**

- LangGraph Documentation
- LangChain Documentation
- OpenAI API Documentation

## **Appendix: Common Questions**

### **Q: Can I use a different LLM provider?**

A: Yes! LangChain supports multiple providers. Replace `ChatOpenAI` with `ChatAnthropic`, `ChatCohere`, or others.

### **Q: How do I handle multiple languages?**

A: Add a language detection step before categorization, then use language-specific prompts or translation.

### **Q: Can I deploy this to production?**

A: Yes, but consider adding error handling, logging, rate limiting, and monitoring first.

### **Q: How much does this cost?**

A: Costs depend on API usage. OpenAI charges per token. Monitor usage and set budgets.

### **Q: Is my data secure?**

A: Data is sent to OpenAI's API. Review their privacy policy and consider on-premise solutions for sensitive data.

_Happy building! If you have questions or want to share your implementation, feel free to reach out._

---

# Post 4: Day 8 of Building AI Agents: Building a News TL;DR Agent with LangGraph

**Published:** January 2, 2026

Welcome to **Day 8** of the _30 Days of Building AI Agents_ series.

Today, we build something that looks **very close to how real AI agent systems work in production**.

Not a clever prompt. Not a linear script.

üëâ **A stateful, decision-making AI agent that can adapt while it runs.**

## **What Are AI Agents (Quick Recap)**

An **AI agent** is not just an LLM call.

An agent is a system that can:
- Understand intent
- Decide _what to do next_
- Use tools
- Evaluate intermediate results
- Change strategy if needed
- Stop when a goal is met

Traditional software executes instructions. Agents **reason through a workflow**.

## **Why News Is a Perfect Agent Problem**

News summarization sounds simple‚Äîuntil you break it down:
- Users ask vague questions
- News changes constantly
- Headlines are misleading
- Summaries without full text are low quality
- One search attempt is often not enough

This makes news summarization a **multi-step, decision-heavy task**‚Äîexactly where agents shine.

## **What We're Building**

A **News TL;DR Agent** that can:
- Accept a natural language query
- Convert intent into structured search logic
- Query multiple news sources
- Scrape full article text
- Decide whether results are sufficient
- Retry intelligently if needed
- Select the most relevant articles
- Generate concise bullet-point summaries

All orchestrated using **LangGraph**.

## **High-Level Architecture**

The system has **three clearly separated layers**:

### **1Ô∏è‚É£ Intelligence Layer**

Handled by **OpenAI** models:
- Understanding intent
- Generating search parameters
- Selecting relevant articles
- Summarizing content

### **2Ô∏è‚É£ Tooling Layer**

Concrete execution:
- NewsAPI ‚Üí article discovery
- Web scraping ‚Üí full text
- Streamlit ‚Üí user interface

### **3Ô∏è‚É£ Orchestration Layer**

Handled by LangGraph:
- State management
- Conditional routing
- Looping and termination

This separation is critical for scaling real agent systems.

## **LangGraph Explained**

Most explanations stop at:

"LangGraph lets you build graphs with LLMs."

That's incomplete.

### **What LangGraph Actually Is**

LangGraph is a framework for building **state machines for LLM systems**.

It lets you combine:
- **Deterministic control flow**
- **Probabilistic LLM reasoning**

In simple terms:

**LangGraph = explicit state + explicit decisions + explicit flow**

### **Why LangGraph Exists**

LLMs are stateless. Every call forgets what happened before.

Real systems need:
- Memory
- Loops
- Retry logic
- Stop conditions
- Inspectability

LangGraph provides all of that.

## **The Three Core LangGraph Primitives**

### **1Ô∏è‚É£ State (Shared Memory)**

State is the **single source of truth** for the entire agent run.

Conceptually:

```
GraphState = {
  "news_query": str,
  "search_attempts_left": int,
  "newsapi_params": dict,
  "articles_metadata": list,
  "scraped_articles": list,
  "selected_articles": list,
  "summaries": list,
  "final_output": str
}
```

Every node:
- Reads from state
- Updates state
- Passes it forward

Why this matters:
- Easy debugging
- Easy replay
- Easy evaluation
- Easy extension (memory, scoring, feedback)

### **2Ô∏è‚É£ Nodes (Pure Functions)**

A node is just:

```
(state) ‚Üí (updated state)
```

Examples:
- Generate search parameters
- Fetch article metadata
- Scrape article text
- Select best articles
- Summarize

Each node should:
- Do **one thing**
- Be replaceable
- Be easy to test

If a node needs a paragraph to explain, it's too big.

### **3Ô∏è‚É£ Edges (Control Flow)**

Edges define **what runs next**.

There are:
- Normal edges (A ‚Üí B)
- Conditional edges (decision-based routing)

This is where _agent behavior_ emerges.

## **The Agent Workflow**

### **Step 1: Intent ‚Üí Search Parameters (LLM)**

The agent asks the LLM:

"Given this user query and previous attempts, what's the best next NewsAPI search?"

This avoids:
- Hardcoded keywords
- Brittle heuristics

LLMs are excellent at translating vague intent into structured queries.

### **Step 2: Retrieve Article Metadata (NewsAPI)**

Using **NewsAPI**, we fetch:
- Titles
- Descriptions
- URLs
- Publish dates

At this stage:
- No summarization
- No relevance decisions

Cheap and fast.

### **Step 3: Scrape Full Article Text**

News APIs rarely return full content.

So the agent:
- Fetches each URL
- Parses HTML
- Extracts clean text

Failures are tolerated. The agent keeps going.

### **Step 4: Decision Point (Critical)**

The agent checks:
- Do I have enough usable articles?
- Do I still have search attempts left?

If not enough signal:
- It loops back
- Generates a _new_ search strategy

This is the moment the system becomes an **agent**, not a script.

### **Step 5: Select Best Articles (LLM)**

The LLM now sees:
- Full text
- Titles + descriptions
- Original user intent

It selects the most relevant articles semantically‚Äînot via keywords.

### **Step 6: Summarize (LLM, Parallel)**

Each selected article is summarized independently:
- Bullet points
- Signal over noise
- No filler

Parallelization keeps things fast.

### **Step 7: Format for Humans**

Final step:
- Clean formatting
- Headings
- Readable output

Agents shouldn't just think well‚Äîthey should communicate well.

## **Project Structure**

```
news-tldr-agent/
‚îú‚îÄ‚îÄ agents.py        # LangGraph nodes + graph
‚îú‚îÄ‚îÄ tools.py         # NewsAPI & scraping
‚îú‚îÄ‚îÄ config.py        # API keys & setup
‚îú‚îÄ‚îÄ utils.py         # Models & helpers
‚îú‚îÄ‚îÄ main.py          # CLI runner
‚îú‚îÄ‚îÄ streamlit_app.py # UI
```

Design rule:

**LLMs, tools, and orchestration must be separate.**

This enables:
- Testing
- Reuse
- Team development
- Scaling to larger systems

## **API Keys: Complete Setup**

### **You Need Two Keys**

- OpenAI (LLM)
- NewsAPI (news discovery)

### **OpenAI API Key**

- Go to https://platform.openai.com/
- Log in or sign up
- Click profile ‚Üí **API Keys**
- Create a new secret key
- Copy it immediately
- Add billing (required)

Key format:

```
sk-xxxxxxxxxxxxxxxx
```

### **NewsAPI Key**

- Go to https://newsapi.org/
- Click **Get API Key**
- Sign up
- Copy your key from the dashboard

Free tier:
- 100 requests/day
- Articles from last 1‚Äì30 days

Perfect for this project.

### **Wiring Keys into the Project**

Create a `.env` file:

```
OPENAI_API_KEY=sk-your-key
NEWSAPI_KEY=your-newsapi-key
```

Load them in `config.py`:

```
from dotenv import load_dotenv
import os

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
```

Add `.env` to `.gitignore`. Never commit keys.

## **Running the Agent**

### **CLI**

```
python main.py "AI news today"
```

### **Streamlit UI**

```
streamlit run streamlit_app.py
```

Watch how:
- Searches evolve
- Decisions are made
- Articles are filtered
- Summaries are produced

## **Why This Pattern Matters**

This architecture generalizes to:
- Research assistants
- Market intelligence agents
- Competitive analysis tools
- Strategy copilots
- Monitoring & alerting agents

Swap tools. Swap prompts.

The **orchestration stays the same**.

## **Key Takeaways**

- LangGraph gives explicit control over reasoning flows
- State makes agents debuggable and extensible
- LLMs should decide _what_, not _when_
- Conditional routing is what creates intelligence

## **Day 8 Complete ‚úÖ**

You now understand:
- How LangGraph actually works
- How real agents are structured
- How to manage state, decisions, and tools
- How to wire everything cleanly

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 5: Day 7 of Building an AI Agents - AI Deep Research Agent

**Published:** December 31, 2025

**‚ö†Ô∏è Before You Start (Important)**

This project **requires basic Python understanding**.

You should be comfortable with:
- Python functions
- Variables, lists, dictionaries
- Reading `.py` files without panic
- Installing packages with `pip`
- Running a Python app from the terminal

üëâ You do **not** need to be an advanced Python engineer

üëâ You **do** need to be comfortable _reading and tweaking code_

If Python is completely new, pause here and do a **1‚Äì2 hour Python crash course** first.

## **üßë‚Äçüíª Step 0: Use a Proper IDE (This Matters)**

You _can_ open this project anywhere. However, for the **best learning experience**, consider using an AI-native IDE.

### **‚úÖ Recommended: Cursor**

Cursor is one of the best IDEs today for AI-first development.

Why Cursor is perfect here:
- It understands your **entire repository**
- You can ask: _"Explain this file."_
- You can say: _"Refactor this agent."_
- You can debug multi-agent logic conversationally
- It's built for reasoning across files, not just autocomplete

üëâ Download: https://cursor.sh

## **üç¥ Step 1: Fork the Repository**

Do **not** clone directly.
- Open the GitHub repository **[Codebase]**
- Click **Fork**
- Fork into your own GitHub account
- Clone _your fork_ locally

This is how real developers work:
- safe experimentation
- clean version control
- freedom to extend

# **Understanding the Codebase**

Before running anything, **pause**.

Day 7 is not about "getting output fast." It's about understanding **how AI agents are designed**.

A typical structure of this repo looks like:

**[Codebase]**

## **Introduction: What is an AI Agent?**

### **What is an AI Agent?**

An **AI Agent** is an autonomous software system that can:
- Understand a goal
- Decide what actions to take
- Use tools to gather information
- Execute tasks step by step
- Produce a final outcome without constant user input

Unlike a chatbot that only responds to messages, an AI agent **acts**.

Think of it as a digital worker that doesn't just answer questions, but **completes jobs**.

### **Key Characteristics of AI Agents**

A true AI agent has the following properties:
- **Autonomy** Once started, it can continue working without repeated prompts.
- **Goal-Oriented** It works toward a defined outcome (for example: "generate a research report").
- **Reactive** It can respond to new information, errors, or partial results.
- **Proactive** It can decide what to do next instead of waiting for instructions.
- **Tool-Using** It can call APIs, search the web, read files, or write outputs.

### **Real-World Analogy**

Imagine hiring a human research analyst.

You don't tell them:

"Search Google now."

You tell them:

"Research this topic and give me a report."

They:
- Decide what questions matter
- Search multiple sources
- Read and filter information
- Synthesize insights
- Present a structured report

That's **exactly** what our AI Research Agent will do ‚Äî just automatically and much faster.

### **Why Build an AI Agent?**

Traditional chatbots:
- Answer one question at a time
- Forget context easily
- Don't use tools unless explicitly told

AI agents:
- Break complex tasks into steps
- Use tools automatically
- Coordinate multiple actions
- Produce complete workflows end-to-end

This is why **real AI products today are agent-based**, not prompt-based.

## **Understanding the Frameworks**

Before writing code, it's important to understand **why each tool exists** in this project.

### **1. Agno Framework** ‚Äì The Agent Orchestrator

**What is Agno?** Agno is a Python framework designed specifically to build **LLM-powered agents**.

Instead of writing messy glue code, Agno lets you define:
- What an agent's role is
- What model does it use
- What instructions guide it
- How does it run safely

**Why Agno?**
- Simple and readable API
- Designed for agent workflows (not chat apps)
- Easy tool integration
- Built-in support for timeouts and failures
- Production-friendly patterns

**Key Agno Concepts**
- **Agent** ‚Üí a role-focused worker
- **Model** ‚Üí the LLM doing reasoning
- **Instructions** ‚Üí system-level behavior rules
- **Run** ‚Üí executing the agent with input

### **2. OpenAI API** ‚Äì The Brain**

The language model is the **reasoning engine** of the agent.

It is responsible for:
- Generating research questions
- Understanding search results
- Synthesizing insights
- Writing professional reports

Important idea:

The LLM **does not fetch data**. It **reasons over data** provided by tools.

### **3. Streamlit** ‚Äì The User Interface**

Streamlit allows us to build a working UI using only Python.

It:
- Collects user input (topic, domain, settings)
- Shows progress
- Displays results
- Allows downloads

Why Streamlit works well here:
- No frontend complexity
- Fast iteration
- Perfect for internal tools and prototypes

### **4. SerpApi** ‚Äì The Search Engine**

SerpApi gives programmatic access to **Google Search results**.

Why this matters:
- Scraping Google is unreliable and unsafe
- SerpApi provides clean JSON results
- Includes links, snippets, and metadata

This is how our agent accesses **real-world information**.

### **5. Perplexity AI (Optional)** ‚Äì Enhanced Search

Perplexity provides AI-synthesized answers across multiple sources.

Used optionally to:
- Improve context
- Add alternative perspectives
- Enhance research depth

## **Project Overview**

### **What We're Building**

A **Market Research Agent** that:
- Accepts a research topic and domain
- Generates relevant research questions
- Searches multiple sources automatically
- Analyzes and synthesizes findings
- Compiles a structured research report
- Exports results in multiple formats

### **Key Features**

- Smart question generation
- Multi-source research
- Parallel execution for speed
- Professional report writing
- Export to PDF / Markdown / JSON
- Session-based research history

### **Technology Stack Summary**

```
Frontend: Streamlit
Backend: Python
Agent Framework: Agno
LLM: OpenAI GPT-4
Search: SerpApi, Perplexity (optional)
Exports: ReportLab
```

## **Step-by-Step Build Process**

### **Step 1: Environment Setup**

#### **1.1 Create a Virtual Environment**

```
mkdir market-research-agent
cd market-research-agent
python -m venv venv
source venv/bin/activate
```

**Why this matters:** Virtual environments prevent dependency conflicts and keep your project isolated.

#### **1.2 Install Dependencies**

```
pip install agno>=2.2.10 streamlit openai requests reportlab python-dotenv
```

Each package has a clear purpose:
- `agno` ‚Üí agent orchestration
- `streamlit` ‚Üí UI
- `openai` ‚Üí LLM access
- `requests` ‚Üí API calls
- `reportlab` ‚Üí PDF exports
- `python-dotenv` ‚Üí API key management

### **Step 2: Project Structure**

```
market-research-agent/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ README.md
```

This minimal structure helps you **focus on logic, not boilerplate**.

### **Step 3: Understanding Agent Architecture**

We use **three agents**, each with a single responsibility.

#### **3.1 Question Generator Agent**

**Purpose:** Convert a topic into structured research questions.

**Flow:**
- Receives topic + domain
- Uses LLM reasoning
- Outputs 3‚Äì10 research questions

This agent **defines the scope** of the entire system.

#### **3.2 Research Agent**

**Purpose:** Answer _one_ question using real data.

**Flow:**
- Receives a question
- Searches Google via SerpApi
- Optionally queries Perplexity
- Synthesizes results using the LLM
- Returns an answer with citations

Each question runs **independently**.

#### **3.3 Report Compiler Agent**

**Purpose:** Turn raw answers into a professional report.

**Flow:**
- Receives all Q&A pairs
- Structures the content
- Writes executive summary + analysis
- Formats output cleanly

This agent transforms **analysis into communication**.

### **Step 4‚Äì8 (High-Level Logic)**

- Agents are created with clear instructions
- Research runs in parallel using async
- Errors are handled gracefully
- Results are stored in the session state
- The final output is exported

## **Key Concepts Explained**

### **Agent Instructions**

Instructions define **how an agent behaves**, not just what it does.

They specify:
- Role
- Tone
- Output format
- Constraints

Better instructions = better results.

### **Agent Orchestration**

Orchestration is the **sequence and coordination** of agents.

```
User Input
‚Üí Question Generator
‚Üí Parallel Research Agents
‚Üí Report Compiler
‚Üí Final Output
```

This pattern is reusable across domains.

### **Tool Integration**

Agents:
- Don't "know" facts
- Call tools
- Reason over results

LLMs are thinkers, not databases.

### **Asynchronous Processing**

Parallel execution dramatically improves speed.

Instead of:
- Question 1 ‚Üí wait
- Question 2 ‚Üí wait

We run **all questions simultaneously**.

### **State Management**

State allows:
- Multi-step workflows
- Progress tracking
- Export functionality
- Research history

Without a state, agents cannot behave like systems.

## **Architecture Deep Dive**

### **Data Flow Summary**

- User enters topic
- Questions are generated
- Research runs in parallel
- Answers are synthesized
- The report is compiled
- Results are displayed and exported

Each layer has a **single responsibility**.

## **Deployment and Usage**

### **Local Development**

```
git clone https://github.com/SriLaxmi1993/Generative-AI-Projects.git
cd Generative-AI-Projects/agents/Market_Research_agent
pip install -r requirements.txt
streamlit run app.py
```

### **Usage Flow**

- Enter API keys
- Define topic and domain
- Generate questions
- Run research
- Compile report
- Export results

## **Conclusion**

### **What You Learned**

By completing this tutorial, you learned:
- How real AI agents are structured
- How tools and LLMs work together
- How orchestration enables scale
- How async improves performance
- How AI products are actually built

### **Final Takeaway**

If you understand this project, you are no longer:
- "Using AI"
- "Prompting models"

You are **building AI Agents**.

That's the real skill.

Happy building üöÄ

---

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 6: Day 6 of Building AI agents: A Multi-Agent AI Travel Planner (Hands-On Edition)

**Published:** December 30, 2025

Welcome to **Day 6** of building real AI projects.

Up to now, this series has been intentionally progressive:
- **Day 1‚Äì2** ‚Üí Automations with n8n & Zapier
- **Day 3** ‚Üí Custom GPTs and prompt-driven systems
- **Day 4-5** ‚Üí Building with AI agents

**Day 6 marks the point at which you cross the builder threshold.**

Today, you're not just _understanding_ agents ‚Äî You're **reading, running, and modifying a real agentic codebase**.

This is how AI products are actually built in startups and product teams.

## **‚ö†Ô∏è Before You Start (Important)**

This project **requires basic Python understanding**.

You should be comfortable with:
- Python functions
- Variables, lists, dictionaries
- Reading `.py` files without panic
- Installing packages with `pip`
- Running a Python app from the terminal

üëâ You do **not** need to be an advanced Python engineer

üëâ You **do** need to be comfortable _reading and tweaking code_

If Python is completely new, pause here and do a **1‚Äì2 hour Python crash course** first.

## **üßë‚Äçüíª Step 0: Use a Proper IDE (This Matters)**

You _can_ open this project anywhere. However, for the **best learning experience**, consider using an AI-native IDE.

### **‚úÖ Recommended: Cursor**

Cursor is one of the best IDEs today for AI-first development.

Why Cursor is perfect here:
- It understands your **entire repository**
- You can ask: _"Explain this file."_
- You can say: _"Refactor this agent."_
- You can debug multi-agent logic conversationally
- It's built for reasoning across files, not just autocomplete

üëâ Download: https://cursor.sh

## **üç¥ Step 1: Fork the Repository**

Do **not** clone directly.
- Open the GitHub repository üëâ **[Codebase]**
- Click **Fork**
- Fork into your own GitHub account
- Clone _your fork_ locally

This is how real developers work:
- safe experimentation
- clean version control
- freedom to extend

# **Understanding the Codebase**

Before running anything, **pause**.

Day 6 is not about "getting output fast." It's about understanding **how the system is designed**.

A typical structure of this repo looks like:

üëâ **[Codebase]**

# **What We're Building**

We're building a **multi-agent AI Travel Planner** that can:
- Research destinations using live web search
- Fetch weather forecasts for travel dates
- Plan routes and transportation
- Generate personalized day-by-day itineraries
- Find booking links for activities
- Export plans to calendars and text files

This is **not a chatbot**.

This is a **coordinated system of AI agents**, each doing one job well.

## **Introduction: What is an AI Agent?**

### **What is an AI Agent?**

An **AI Agent** is an autonomous software program that can:
- perceive its environment
- reason about goals
- take actions using tools
- and complete multi-step tasks

Unlike a chatbot that simply answers questions, an AI agent **actively works** toward an outcome.

In this project, that outcome is: üëâ _Planning an entire trip from scratch._

**Key Characteristics of AI Agents**
- **Autonomy** ‚Äì runs without step-by-step human instructions
- **Goal-Oriented** ‚Äì optimizes for a clear objective (a complete travel plan)
- **Reactive** ‚Äì adapts to user inputs and constraints
- **Proactive** ‚Äì gathers information on its own
- **Tool-Using** ‚Äì calls APIs, searches the web, formats outputs
- **Multi-Step Reasoning** ‚Äì breaks a complex task into stages

### **Real-World Analogy**

Think of a professional travel planner who:
- Research destinations online
- Checks weather forecasts
- Plans routes and logistics
- Creates a daily itinerary
- Finds booking links
- Recommends what to pack

That's exactly what our **AI Travel Agent** does ‚Äî but faster, cheaper, and 24/7.

## **Understanding the Frameworks**

Before we build, let's understand the tools powering this system.

### **1. Agno Framework ‚Äì The Agent Orchestrator**

**What is Agno?** Agno is a Python framework designed specifically for **building AI agents**.

Instead of writing massive prompts, Agno lets you define:
- agents
- roles
- instructions
- tools
- and execution flows

Think of Agno as the **conductor** coordinating a team of AI specialists.

**Why Agno?**
- Clean, beginner-friendly API
- Built for multi-agent systems
- Easy tool integration
- Works with OpenAI models
- Handles orchestration, retries, and structure

**Key Agno Concepts**
- **Agent** ‚Äì a specialized AI worker
- **Model** ‚Äì the LLM (GPT-4o)
- **Instructions** ‚Äì system-level behavior rules
- **Role** ‚Äì what the agent is responsible for
- **Run** ‚Äì executing an agent with structured input

### **2. OpenAI GPT-4o ‚Äì The Brain**

The **LLM is the brain**, not the agent.

GPT-4o provides:
- reasoning
- synthesis
- natural language generation

**Why GPT-4o?**
- Strong reasoning ability
- Handles long context
- Production-grade reliability
- Generates readable, human-like plans

**In this project, GPT-4o:**
- understands travel preferences
- synthesizes research results
- converts raw data into itineraries

### **3. Streamlit ‚Äì The User Interface**

Streamlit lets you build **full web apps using only Python**.

**Why Streamlit?**
- No frontend frameworks needed
- Interactive widgets out of the box
- Built-in state management
- Perfect for AI demos and MVPs

**Role in this project**
- Collects user input
- Displays itineraries
- Shows weather & activities
- Handles file downloads

### **4. DuckDuckGo Search ‚Äì The Research Engine**

DuckDuckGo provides **free web search** without API keys.

**Why DuckDuckGo?**
- No cost
- No rate limits
- Simple Python integration

**Used for:**
- finding attractions
- discovering activities
- collecting travel tips

### **5. BeautifulSoup ‚Äì Content Parsing**

Search results are noisy.

BeautifulSoup extracts **meaningful text** from webpages so agents get better context.

### **6. Open-Meteo API ‚Äì Weather Data**

Open-Meteo provides:
- free global weather forecasts
- no API key required

Used to:
- fetch weather for travel dates
- enable weather-aware planning
- generate packing tips

### **7. iCalendar (ICS) ‚Äì Export Format**

iCalendar lets users:
- import itineraries into Google Calendar
- sync with Apple / Outlook

This turns AI output into **real-world utility**.

## **Project Overview**

### **What We're Building**

A **multi-agent AI travel planning system** that:
- Researches destinations
- Analyzes weather
- Plans routes and logistics
- Creates day-by-day itineraries
- Finds booking links
- Exports plans

This is **not one giant prompt**.

It's a **system of agents**.

**GitHub Repository:** [repo link]

### **Key Features**

- Multi-agent architecture
- Live web research
- Weather-aware recommendations
- Logistics optimization
- Booking links
- Multiple export formats
- Deep personalization

### **User Experience Flow**

- User enters preferences
- Agents gather and analyze data
- Planner synthesizes results
- User receives a complete travel plan

## **Step-by-Step Build Process**

### **Step 1: Project Setup**

- Create a Python project
- Set up a virtual environment
- Install dependencies (Streamlit, Agno, OpenAI, DuckDuckGo, BeautifulSoup, requests, iCalendar)

### **Step 2: Design the Agent Architecture**

We use **five specialized agents**:
- **Research Agent** ‚Äì finds destination info
- **Weather Agent** ‚Äì analyzes forecasts
- **Logistics Agent** ‚Äì optimizes routes
- **Planner Agent** ‚Äì creates itinerary
- **Activities Agent** ‚Äì finds booking links

**Why multi-agent?**
- specialization beats mega-prompts
- easier debugging
- scalable architecture

### **Step 3: Build Search Functionality**

- Generate search queries
- Fetch results from DuckDuckGo
- Enrich snippets with BeautifulSoup
- Produce clean research summaries

### **Step 4: Define Agents**

Each agent defines:
- role
- instructions
- model
- input format
- output expectations

This keeps agents **disciplined**.

### **Step 5: Weather Integration**

- Convert destination ‚Üí coordinates
- Fetch weather from Open-Meteo
- Map weather codes
- Generate packing & activity advice

### **Step 6: Orchestrate the Workflow**

Execution pipeline:

```
Research ‚Üí Weather ‚Üí Logistics ‚Üí Planning ‚Üí Activities
```

The **orchestrator**:
- controls order
- passes structured outputs
- prevents chaos

### **Step 7: Build the UI**

- Sidebar for preferences & API keys
- Main view for results
- Expandable weather & activities sections
- Download buttons

### **Step 8: Error Handling & Timeouts**

- Protect agent calls with timeouts
- Handle API failures gracefully
- Keep the UI responsive

## **Key Concepts Explained**

### **Agent Anatomy (Very Important)**

Every agent in this system has:
- **Role** ‚Äì what it does
- **Instructions** ‚Äì how it thinks
- **Tools** ‚Äì what it can call
- **Brain (LLM)** ‚Äì GPT-4o
- **Memory / Context** ‚Äì passed explicitly
- **Input** ‚Äì structured data
- **Output** ‚Äì structured results

Agents are **specialists**, not generalists.

### **What Is Orchestration?**

Agents **do not talk to each other directly**.

The orchestrator:
- runs agents in order
- passes outputs forward
- maintains system state

This is how hallucinations are reduced.

### **Data Flow**

```
User Input
 ‚Üí Research
 ‚Üí Weather
 ‚Üí Logistics
 ‚Üí Planning
 ‚Üí Activities
 ‚Üí Output + Export
```

## **Features and Capabilities**

### **Intelligent Research**
- dynamic queries
- real-time data

### **Weather-Aware Planning**
- daily forecasts
- indoor alternatives

### **Logistics Optimization**
- efficient routes
- realistic pacing

### **Personalized Itineraries**
- style & budget aware
- balanced schedules

### **Booking Integration**
- Viator / GetYourGuide-style links

### **Export Formats**
- calendar (.ics)
- text
- complete guides

## **Deployment and Usage**

### **Prerequisites**

- Python 3.8+
- OpenAI API key
- Internet access

### **Running Locally**

- activate virtual environment
- run Streamlit
- Enter API key
- generate itinerary

### **Deployment Options**

- Streamlit Cloud

## **Conclusion**

### **What You Learned**

By building this agent, you learned:
- How multi-agent systems work
- How to orchestrate AI workflows
- How to combine LLMs with real APIs
- How to build full AI products

### **Why This Matters**

AI agents are the future of software.

They don't just respond. They **reason, act, and complete workflows**.

This Travel Agent is not the goal ‚Äî it's the **template**.

Change the domain, and you can build:
- research agents
- PM copilots
- finance planners
- ops automation systems

### **Next Steps**

- Add hotel agents
- Add budget estimators
- Add multi-city planning
- deploy & share
- build your own agentic product

## **Get Started Today**

**GitHub Repository:** [repo link]

You now know how real AI systems are built.

**Happy building üöÄ**

---

# Post 7: üöÄ Day 5: Building a Multi-Agent AI PM Research & PRD System Using n8n

**Published:** December 26, 2025

Welcome to **Day 5 of building AI Agents / Projects**.

So far, we've built **individual AI agents**. Today, we build something **much closer to how real AI systems work in production**.

Not one agent. Not one prompt.

üëâ **A multi-agent orchestration system** that reasons, routes, validates, uses tools, remembers context, and persists outputs **only when needed**.

This is the kind of **internal tooling** used by:
- Product teams
- Founders
- Strategy & research orgs

## **üß† What We're Building Today**

A **PM-grade AI Research & PRD system** that can:
- Understand user intent
- Decide which expert agent should respond
- Route queries intelligently
- Generate:
  - Market research
  - User research
  - Full 2-page PRDs
- Ask for confirmation before saving
- Persist outputs only when approved

All built using **n8n + AI agents**.

No frontend. No backend. Just **AI + orchestration + workflows**.

## **ü§ñ Why This Is an AI Agent (Not a Chatbot)**

An AI agent is **not** a single LLM call.

A real agent:
- Accepts unstructured input
- Applies decision logic
- Uses tools (search, memory, files)
- Routes tasks intelligently
- Produces structured outputs
- Takes conditional actions

That's exactly what we're building today.

## **üß© Agent Architecture (High Level)**

This system has **four agents**:
- **Orchestration Agent** (the brain)
- **Market Research Agent**
- **User Research Analyst**
- **PRD Generator Agent**

‚ö†Ô∏è Only **one agent is called at a time**, based on user intent.

This is deliberate. This is how reliable agent systems are built.

## **üß™ Prerequisites (Important)**

Before starting, make sure you have:
- An active **n8n account**
- An **OpenAI API key**
- Set up **Tavily API key (find the instructions below)
- The **n8n workflow JSON file**

üëâ **Download the workflow JSON here** _(Don't forget to star the repo)_

‚ö†Ô∏è You do **NOT** need to build this flow manually.

## **Step 1: Import the Workflow (Mandatory)**

This tutorial uses a **production-ready JSON template**.

### **How to import:**

- Open your **n8n dashboard**
- Click **Create Workflow**
- Open the menu (‚ãÆ)
- Select **Import from clipboard**
- Paste the JSON
- Click **Import**

‚úÖ The full workflow will instantly appear on your canvas.

Do **not** run it yet.

## **üß≠ Step 2: Orchestration Agent (The Brain)**

This is the **most important node** in the entire workflow.

### **What it does:**

- Reads the user's message
- Classifies intent
- Routes to exactly **one agent**:
  - Market Research
  - User Research
  - PRD Generator

It **never answers questions for itself**.

### **üß† Orchestration Agent ‚Äì System Prompt**

You will find the **exact prompt inside the JSON file** for the Orchestration Agent node.

Core idea (excerpt):

```
Act like an advanced Orchestration Agent designed to intelligently route user queries.

Analyze the user's intent and dispatch the request to exactly ONE tool:
- Market Research Analyst
- User Research Analyst
- PRD Generator

Never modify tool outputs.
Never answer directly.
```

üìå **Refer to the JSON for the complete routing logic and examples.**

This turns your system into a **decision-making AI**, not a chatbot.

## **üìä Step 3: Market Research Agent (Uses Tavily)**

This agent behaves like a **senior strategy analyst**.

You will find the **exact prompt inside the JSON file**.

### **What it handles:**

- Competitor analysis
- Market size (TAM / SAM / SOM)
- Pricing intelligence
- Market trends
- Strategic recommendations

### **üîç Tavily Usage (Critical)**

LLMs **do not have real-time market knowledge**.

So for anything involving:
- Competitors
- Pricing pages
- Market reports
- Industry trends

üëâ This agent **must call Tavily**.

In the workflow image, you'll see:
- A **Tavily Search Tool** connected directly to the Market Research Agent.

The flow is:
- User asks a market question
- Agent calls **Tavily**
- Fetches real-world data
- Synthesizes insights
- Returns PM-ready analysis

üìå The **full Market Research prompt** (including Tavily instructions) is inside the JSON.

### **Step A: Create a Tavily Account**

- Go to üëâ https://tavily.com
- Click **Sign up**
- Create an account using:
  - Email, or
  - GitHub / Google login

Once logged in, you'll land on the Tavily dashboard.

### **Step B: Generate Your Tavily API Key**

- Inside the Tavily dashboard, go to **API Keys**
- Click **Create API Key**
- Copy the generated key

‚ö†Ô∏è Treat this like a secret. Do **not** commit it to GitHub.

### **Step C: Add Tavily Credentials in n8n**

#### Now connect Tavily to n8n.

- Open **n8n**
- Go to **Credentials**
- Click **Create new credential**
- Search for **Tavily**
- Paste your **Tavily API Key**
- Save

‚úÖ Tavily is now available as a tool inside your workflows.

## **üßë‚Äçüíª Step 4: User Research Analyst (Also Uses Tavily)**

This agent behaves like a **UX research lead**.

### **What it handles:**

- User pain points
- Behavioral patterns
- Personas & JTBD
- UX issues
- Sentiment analysis

### **üîç Tavily Usage for User Research**

Here, Tavily is used to:
- Scan public reviews
- Analyze forums & Reddit threads
- Look at complaints and feedback
- Understand sentiment at scale

This allows the agent to:
- Go beyond assumptions
- Reference real user signals
- Ground UX insights in reality

üìå You'll see **Tavily connected to the User Research Agent** in the workflow image.

üìå The **complete User Research prompt** lives inside the JSON.

## **üß† Step 4.1: What "Memory" Means in This Workflow**

You'll notice **Simple Memory nodes** connected to every agent.

This is **not chat history**.

This is **agent memory**.

### **üß© What Memory Does**

Memory allows an agent to:
- Retain relevant context
- Avoid repeating work
- Stay consistent across steps
- Support multi-turn reasoning

Each agent has **its own memory**:
- Orchestration memory
- Market Research memory
- User Research memory
- PRD Generator memory

This isolation is intentional.

### **üß† Why Memory Matters**

Without memory:
- Agents repeat research
- PRDs lose context
- Outputs become inconsistent

With memory:
- Research compounds
- PRDs build on insights
- The system feels "aware."

This is **foundational to production AI systems**.

## **üßæ Step 5: PRD Generator Agent**

This agent generates a **full 2-page Product Requirements Document**.

### **Key rules:**

- Triggered **only** when the user explicitly asks:
  - "Generate a PRD"
  - "Create a product requirements document."

- Pulls from:
  - Market Research memory
  - User Research memory

- Uses a structured PRD template
- Outputs PM-ready documentation

üìå The **golden PRD prompt** is fully defined inside the JSON.

This is **agent chaining done right**.

## **üó£ Step 6: Ask Before Saving (Human-in-the-Loop)**

After any agent responds, the system asks:

**"Do you want me to store this in a file?"**

### **Why this exists:**

- Prevents unnecessary persistence
- Respects user intent
- Mirrors enterprise workflows

## **üö¶ Step 7: Conditional Logic (Yes / No)**

- **Yes** ‚Üí Output is converted to a text file
- **No** ‚Üí System responds and exits

This is **production-grade AI behavior**.

## **üéØ Day 6 Takeaway**

You didn't build "another AI demo".

You built:
- A multi-agent system
- Intelligent routing
- Tool-augmented research (Tavily)
- Agent memory
- Human-in-the-loop control
- Conditional persistence

This is **how internal AI platforms are built**.

More coming next üöÄ Happy building!

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 8: Day 4: Building a Full-Stack AI Journal App with Vibe Coding in Bolt

**Published:** December 24, 2025

**Frontend, backend, database, auth, and AI ‚Äî without writing traditional backend code.**

In the last few days, we've been building AI Agents step by step:

üëâ **Day 4 is different.** Today, we're building a **complete full-stack AI application** using **Vibe coding** in Bolt.

No backend setup. No infra diagrams. No DevOps rabbit holes.

Just **clear product intent ‚Üí working software**.

## **What Does "Full-Stack" Mean?**

A **full-stack app** includes everything needed to run a real product:

### **1. Frontend**

What users see and interact with:
- UI
- Design
- Forms
- Buttons
- Editor
- Animations

### **2. Backend**

The logic behind the scenes:
- Saving data
- Fetching data
- Calling APIs
- Running AI models

### **3. Database**

Where data lives:
- Journal entries
- Dates
- Moods
- AI insights
- User preferences

### **4. Authentication**

Who the user is:
- Login
- Signup
- User-specific data isolation

### **5. AI Layer**

Intelligence on top:
- LLMs (Large Language Models)
- Analysis
- Insights
- Personalization

**Today's goal:** Build **all five layers** using Bolt ‚Äî by describing _what we want_, not _how to implement it_.

## **What We're Building Today**

A **personal journaling app** inspired by late-night caf√© vibes:
- Calm
- Intimate
- Reflective
- Private
- AI-assisted (but not intrusive)

This app includes:
- Calendar-based journal entries
- Mood tracking
- Rich-text editor
- Writing streaks
- Persistent storage
- Authentication
- Optional AI reflections

## **Step 1: Start a New Bolt Project**

Create a new project in Bolt and choose the default React template.

https://bolt.new/

You'll see:
- File Explorer on the left
- Live preview panel
- A chat interface where Bolt acts as your builder

At this stage, **don't touch code**. We'll build everything using prompts.

## **Step 2: Give Bolt the Core App Prompt**

This prompt defines:
- Product vision
- UX
- UI
- Features
- Mood

üëâ Paste this **exact prompt** into Bolt:

### **Prompt 1 ‚Äî Core App**

```
Design a personal journaling app inspired by late-night caf√© vibes‚Äîcalm, intimate, and reflective. The interface should feel warm and inviting, with soft amber and golden lighting accents, subtle shadows, and cozy contrast.

Use smooth, rounded UI components, generous spacing, and gentle micro-interactions (fade-ins, slow transitions, soft hover states) to create a relaxing writing experience.

Core features should include:
‚Äì A calendar-based journal view with daily entries
‚Äì Mood tracking with minimal, expressive icons
‚Äì A rich-text editor supporting formatting (bold, italics, lists, highlights) without visual clutter
‚Äì Daily writing streaks presented in a motivating but non-gamified way
- previous entries to be seen in the UI

The color palette should lean toward warm browns, muted oranges, soft creams, and low-saturation neutrals, avoiding harsh contrasts. Overall, the app should feel like sitting alone in a quiet caf√© at night‚Äîsafe, personal, and focused.
```

### **What Bolt Does Automatically**

From the screenshots:
- Builds the UI with warm amber tones
- Adds mood pills (Calm, Happy, Reflective, etc.)
- Creates a calendar view
- Adds a distraction-free editor
- Implements writing streak logic
- Displays previous entries

This is **vibe coding**:

You describe the feeling and intent ‚Äî Bolt figures out the structure.

## **Step 3: Database ‚Äî What Is Supabase and Why Bolt Uses It?**

### **What Is Supabase?**

**Supabase** is an open-source backend platform that provides:
- PostgreSQL database
- Authentication
- Row-level security
- APIs out of the box

Think of it as:

"Firebase, but with SQL and more control."

### **Why Bolt Uses Supabase**

Bolt automatically:
- Provisions a Supabase project
- Creates tables
- Handles migrations
- Connects auth with data

From the screenshots, you can see tables like:
- `journal_entries`
- `user_preferences`
- `ai_insights`

You never write SQL ‚Äî Bolt infers schema from your app.

## **Step 4: Authentication Setup**

In **Project Settings ‚Üí Authentication**, Bolt enables:
- Email + password login
- User-specific data isolation
- Optional anonymous access

This is crucial for a journaling app:
- Private
- Secure
- Personal
- No social pressure

Each user only sees **their own entries**.

## **Step 5: Secrets ‚Äî What They Are and Where to Get Them**

### **What Are Secrets?**

**Secrets** are sensitive values like:
- API keys
- Database URLs
- Private credentials

They should **never** be exposed in frontend code.

Bolt provides a secure secrets manager.

### **Secret 1: OpenAI API Key**

#### **What Is an OpenAI LLM?**

An **LLM (Large Language Model)** is what powers ChatGPT-like intelligence:
- Text understanding
- Pattern detection
- Emotional tone analysis
- Summarization

We use OpenAI **only for reflection**, not advice.

#### **Where to Get the OpenAI API Key**

- Go to üëâ https://platform.openai.com
- Create an account
- Go to **API Keys**
- Create a new secret key
- Copy it

Add it in Bolt as:

```
OPENAI_API_KEY = your_key_here
```

### **Secret 2: Supabase Keys**

#### **How to Get Supabase Keys (Quick)**

##### **Step 1: Open Your Supabase Project**

- In **Bolt ‚Üí Project Settings ‚Üí Database**
- Click **Open in Supabase** (or **View Database**)
- This opens your project in the Supabase dashboard

##### **Step 2: Copy the Required Keys**

#### **In Supabase ‚Üí Project Settings ‚Üí API**, copy:

- **Project URL** ‚Üí `SUPABASE_URL`
- **anon public key** ‚Üí `SUPABASE_ANON_KEY`
- **service_role key** ‚Üí `SUPABASE_SERVICE_ROLE_KEY`

Then go to **Project Settings ‚Üí Database** in Supabase and copy:
- **Connection string** ‚Üí `SUPABASE_DB_URL`

Add all of these in **Bolt ‚Üí Project Settings ‚Üí Secrets**.

## **Step 6: Add the AI Reflection Layer**

Once the core app is working, we **layer on AI gently**.

üëâ Paste this prompt:

### **Prompt 2 ‚Äî AI Layer**

```
Add a subtle AI reflection layer to the journaling app. Using an OpenAI LLM, the AI gently analyzes journal entries (with user consent) to surface emotional patterns, recurring themes, mood trends, and tone shifts.

Insights should feel calm, empathetic, and observational‚Äînever diagnostic or prescriptive. The AI acts like a quiet late-night companion, offering short reflections and optional prompts without interrupting the writing flow.

AI insights should appear in soft, minimal cards that blend into the warm caf√© aesthetic.
```

### **System Prompt (Very Important)**

This controls AI behavior and **prevents unsafe output**.

```
You are a reflective journaling assistant.

Gently analyze user journal entries to surface patterns, emotions, and themes.
Be calm, empathetic, and non-judgmental.
Do not diagnose, prescribe, or give advice.
Prefer reflection over instruction.
Keep responses short and soothing.
Your goal is to help the user feel seen and understood.
```

This is **responsible AI design**.

## **Step 7: How Data Flows (Simple Mental Model)**

- User writes a journal entry
- Entry is saved to Supabase
- Mood + date are stored
- If AI is enabled:
  - Entry sent to OpenAI
  - Reflection generated
  - Saved to `ai_insights`
- UI displays insights softly

Everything is:
- User-scoped
- Persistent
- Secure

## **Step 8: Publish the App**

Click **Publish**.

Bolt:
- Builds the app
- Hosts it
- Gives you a public URL
- Supports custom domains

You've now shipped a **real full-stack AI product**.

## **Why This Matters**

This project proves:
- You don't need backend expertise to build backend systems
- Product thinking > framework knowledge
- AI should _support_, not dominate
- Vibe coding works when the intent is clear

## **What's Next?**

From here, you could add:
- Weekly reflection summaries
- Mood heatmaps
- Export to PDF
- Encryption
- Multi-device sync
- SaaS plans

But most importantly ‚Äî You've learned how to **think full-stack without fear**.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 9: Day 3 of Building AI Projects - Build a Custom GPT

**Published:** December 23, 2025

On **Day 1 and Day 2**, we built hands-on AI projects using **n8n** and **Zapier**‚Äîautomating workflows, connecting tools, and reducing busywork.

**Day 3 is about building an AI product.**

Not an automation. Not a one-off prompt. But a **Custom GPT** that people actually use‚Äîand keep coming back to.

Today, I'll break down:
- What a Custom GPT really is
- How to create one (step by step)
- How documents, instructions, and publishing work
- The **exact prompt** I used
- Why my GPT (**PM Interview Expert**) is now used by **15,000+ Product Managers**
- Practice GPT ideas you can build yourself

## **What Is a Custom GPT (In Simple Terms)?**

A **Custom GPT** is your knowledge + your instructions wrapped into a reusable AI assistant.

It has **three core components**:
- **Instructions** ‚Üí how the GPT behaves
- **Documents (Knowledge)** ‚Üí what it knows
- **Publishing settings** ‚Üí who can use it

You're not training a new model. You're **productizing your expertise**.

Think of it like this:

Prompts = one-time  
Custom GPTs = reusable products

## **Where to Create a Custom GPT**

You create Custom GPTs here üëá

üîó **Create a GPT:** https://chat.openai.com/gpts/editor

(You'll need ChatGPT Plus / Team / Enterprise to create one.)

## **Why I Built a Custom GPT for PM Interview Prep**

PM interviews are uniquely hard.

They test:
- Product thinking
- Metrics & analytics
- Estimation
- Technical fundamentals
- Communication

Most candidates:
- Memorize frameworks
- Read blog posts
- Still struggle to **structure answers live**

I wanted something better.

So I built **PM Interview Expert**‚Äîa Custom GPT trained on:
- My personal PM frameworks
- Real interview questions
- Sample strong answers
- Rubrics for evaluation

Today:
- ‚úÖ **15,000+ PMs have used it**
- ‚úÖ It's one of the **top PM interview GPTs**
- ‚úÖ Used by Associate ‚Üí Senior PMs globally

üîó **Try it here:** https://chat.openai.com/g/g-X9Zal2ygw-pm-interview-expert

## **What Can a PM Interview Expert Help With?**

### **üß† Product Sense**

- How would you improve Spotify as a podcast app?
- What's your favorite product and why?

### **üìê Estimation**

- How much money does Spotify make in a year?
- Estimate the number of songs played per day.
- What will the market size of Alexa be in 2025?

### **üìä Analytical / Metrics**

- How would you measure success for TikTok?
- Facebook messages dropped 10% in 2 days. Why?
- Gmail signups are down 5%. What data do you need?

### **‚öôÔ∏è Technical (PM-level)**

- What happens when you type google.com in a browser?
- Explain APIs to your grandfather.
- How does Google Maps compute ETA?
- Types of load-balancing algorithms?

## **Step-by-Step: How to Create Your Own Custom GPT**

### **Step 1: Open the GPT Builder**

Go to: üëâ https://chat.openai.com/gpts/editor  
Click **Create**

You'll see two tabs:
- **Create** ‚Üí chat-based setup
- **Configure** ‚Üí where the real magic happens

## **Step 2: Paste This Prompt (Starter Prompt)**

In the **Create** tab, paste this üëá

```
I want to create a Custom GPT called "PM Interview Expert".

It should act as an experienced Product Manager and interview coach.

Target audience:
- Product Manager candidates (Associate ‚Üí Senior)

Core use case:
- Help users practice PM interviews across Product Sense, Analytical, Estimation, and Technical rounds.

Behavior:
- Ask clarifying questions when prompts are ambiguous
- Structure answers like real interview responses
- Use clear frameworks and step-by-step reasoning
- Never invent metrics or facts; state assumptions explicitly

Coaching mode:
- Evaluate user answers
- Highlight strengths
- Identify gaps
- Provide a refined model answer

Tone:
- Calm, confident, practical
- Like a senior PM interviewer

I will upload my own PM frameworks and sample answers as documents.
```

This sets the **direction**.

## **Step 3: Instructions (The Brain of Your GPT)**

Now go to **Configure ‚Üí Instructions** and paste this in full:

```
You are "PM Interview Expert," an interview coach for Product Manager candidates.

Your goal:
Help users practice PM interviews across Product Sense, Analytical, Estimation, and Technical rounds.

GLOBAL RULES
- Ask clarifying questions when needed
- Never invent real-world data
- State assumptions clearly
- Keep answers concise and structured

PRODUCT SENSE
1. Clarify goal and user segment
2. Define problem
3. Success metrics
4. Key insights
5. Solution ideas
6. Prioritization
7. Tradeoffs
8. MVP and rollout

ANALYTICAL / RCA
1. Restate metric change
2. Data needed
3. Hypothesis tree
4. Debug plan
5. Likely causes
6. Fixes

ESTIMATION
1. Define target
2. State assumptions
3. Step-by-step math
4. Sanity check

TECHNICAL
1. Simple explanation
2. Technical breakdown
3. Tradeoffs
4. Examples

COACHING MODE
- Grade answers: Strong / Mixed / Weak
- Highlight strengths
- Suggest improvements
- Provide a better model answer
```

This is what makes your GPT **non-generic**.

## **Step 4: Documents (Knowledge Files)**

You can upload **up to 20 documents**.

Best documents to add:
- Frameworks
- Sample answers
- Question banks
- Evaluation rubrics
- Notes from real interviews

üí° Tip: Clean text (Docs / Markdown) works best. Avoid slides with multiple columns.

## **Step 5: Conversation Starters (UX Matters)**

Add examples like:
- "Give me a Product Sense question and interview me."
- "Evaluate my answer and suggest improvements."
- "Run a 15-minute mock PM interview."
- "Ask me an estimation question."

This dramatically improves usage.

## **Step 6: Publishing Your GPT**

Under **Publish settings**, you can choose:
- Only me
- Anyone with a link
- Public (listed)

Once published, your GPT gets a **shareable link** like:

```
https://chat.openai.com/g/g-xxxxxxxx
```

That's how **PM Interview Expert** reached **15,000+ users**.

## **Practice: Custom GPT Ideas (Beyond Product Management)**

Once you understand how Custom GPTs work, you'll realize they're **role-based AI tools**, not just "chatbots".

Below are **high-impact Custom GPT ideas for different personas**, along with _how to build each one_.

Each of these can be built in **20‚Äì40 minutes**.

## **1Ô∏è‚É£ Resume & Career Coach GPT (Non-Tech / General)**

### **Who it's for**

- Students
- Career switchers
- Early professionals

### **What it does**

- Reviews resumes
- Suggests role-specific improvements
- Helps write bullet points
- Prepares interview answers

### **How to build it**

**Instructions**
- Act as a career coach
- Ask role, experience level, and target company
- Give actionable, concise feedback

**Documents to upload**
- Resume templates
- Strong bullet examples
- STAR method examples
- Common resume mistakes

**Conversation starters**
- "Review my resume for a marketing role."
- "Rewrite this bullet to sound more impactful."
- "Prepare me for an HR interview."

## **2Ô∏è‚É£ Personal Finance Explainer GPT**

### **Who it's for**

- Beginners to investing
- Young professionals
- Non-finance backgrounds

### **What it does**

- Explains finance concepts simply
- Helps with budgeting
- Explains tax, SIPs, stocks, and mutual funds
- Avoids financial jargon

### **How to build it**

**Instructions**
- Explain concepts using analogies
- Avoid giving legal or investment advice
- Ask about the country and risk appetite

**Documents to upload**
- Finance explainers
- Budgeting frameworks
- Common financial terms glossary

**Conversation starters**
- "Explain SIPs like I'm 10"
- "How should I budget my salary?"
- "Difference between stocks and mutual funds?"

## **3Ô∏è‚É£ Health & Fitness Habit Coach GPT (Non-Medical)**

### **Who it's for**

- Busy professionals
- Beginners to fitness
- People building habits

### **What it does**

- Builds workout routines
- Creates habit plans
- Tracks consistency
- Motivates without shaming

### **How to build it**

**Instructions**
- Never give medical advice
- Focus on habits, routines, and motivation
- Ask about lifestyle and constraints

**Documents to upload**
- Workout templates
- Habit-building frameworks
- Fitness myths vs facts

**Conversation starters**
- "Create a 15-minute daily workout."
- "Help me build a walking habit."
- "How do I stay consistent?"

## **4Ô∏è‚É£ Writing & Blogging Coach GPT**

### **Who it's for**

- Content creators
- Newsletter writers
- Bloggers

### **What it does**

- Improves writing clarity
- Suggests hooks
- Edits tone and structure
- Helps overcome writer's block

### **How to build it**

**Instructions**
- Ask audience and platform (Substack, LinkedIn, blog)
- Suggest multiple hooks
- Edit without changing voice

**Documents to upload**
- Writing frameworks
- Sample great posts
- Headline swipe files

**Conversation starters**
- "Improve this intro."
- "Give me 5 hooks for this idea."
- "Rewrite this for LinkedIn."

## **5Ô∏è‚É£ Study Companion GPT (Students / Exams)**

### **Who it's for**

- College students
- Exam prep candidates
- Self-learners

### **What it does**

- Explains concepts step-by-step
- Creates quizzes
- Summarizes notes
- Tests understanding

### **How to build it**

**Instructions**
- Teach concept ‚Üí ask a question ‚Üí correct mistakes
- Adjust depth based on user responses

**Documents to upload**
- Study notes
- Syllabi
- Practice questions

**Conversation starters**
- "Explain this topic simply."
- "Quiz me on this chapter."
- "Summarize my notes."

## **6Ô∏è‚É£ Startup Idea Validator GPT**

### **Who it's for**

- Founders
- Indie hackers
- First-time builders

### **What it does**

- Evaluates startup ideas
- Identifies target users
- Finds risks and assumptions
- Suggests MVPs

### **How to build it**

**Instructions**
- Think like an early-stage investor
- Challenge assumptions politely
- Focus on clarity, not hype

**Documents to upload**
- Startup frameworks
- MVP examples
- Market sizing guides

**Conversation starters**
- "Validate this startup idea."
- "Who is the real customer?"
- "What assumptions am I making?"

## **7Ô∏è‚É£ Language Practice GPT (Conversational)**

### **Who it's for**

- Language learners
- Non-native speakers

### **What it does**

- Simulates conversations
- Corrects grammar gently
- Improves fluency

### **How to build it**

**Instructions**
- Act as a friendly conversation partner
- Correct mistakes after the response
- Encourage speaking, not perfection

**Documents to upload**
- Common phrases
- Grammar rules
- Example conversations

**Conversation starters**
- "Talk to me in simple English."
- "Correct my sentences."
- "Practice an interview conversation"

## **Key Pattern to Notice**

Every good Custom GPT has:
- **One clear user persona**
- **One primary job**
- **Strong instructions**
- **Relevant documents**
- **Good conversation starters**

That's it.

## **Final Reminder**

Custom GPTs are not about prompts. They are about **designing behavior**.

If you can clearly answer:
- Who is this for?
- What problem does it solve?
- How should it respond?

You can build a valuable GPT.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 10: Day 2 ‚Äì Building AI Agents: Automating Your Daily AI Briefs with Zapier

**Published:** December 22, 2025

Welcome to **Day 2 of building AI agents**.

On **Day 1**, we focused on understanding _what AI agents are_ and how tools like **n8n** help you orchestrate them end-to-end.

In this tutorial, you'll learn how to build a **real AI agent workflow** using **Zapier (conceptually similar to n8n)** that:
- Collects AI newsletters automatically
- Uses an LLM to reason over unstructured data
- Produces a structured daily brief
- Delivers it where you actually work (Slack)

Even if you're building in **n8n**, this tutorial maps **1:1 conceptually**:
- Schedule Trigger ‚Üí Cron node
- Gmail Search ‚Üí Gmail / IMAP node
- AI Analysis ‚Üí OpenAI / LLM node
- Slack Message ‚Üí Slack node

## **What We're Building Today**

A **Daily AI Newsletter Summary Agent** that runs every morning and answers:

"What happened in AI yesterday that I should care about?"

### **What the automation does:**

- ‚è∞ Runs daily at 9 AM
- üì© Finds all AI newsletters from yesterday
- ü§ñ Summarizes them using AI
- üí¨ Sends a clean, structured brief to Slack

## **Prerequisites**

Before beginning this lab, ensure you have completed the following:
- A Zapier account (or n8n if you're mapping this later)
- Gmail account with an **"AI Newsletters"** label
- Slack workspace with admin access
- OpenAI API key (or Zapier's built-in OpenAI)

## **Step 1: Set Up the Daily Schedule Trigger**

### **What This Step Does**

This trigger fires every morning at your specified time (9 AM) to kick off the entire workflow.

### **Configuration**

- Create a new Zap and select **Schedule by Zapier**
- Choose **Every Day**
- Set **Time of Day** to **9:00 AM**
- Set **Trigger on weekends** (Yes / No)
- Click **Continue**

### **Why This Matters**

Using a scheduled trigger instead of a "New Email" trigger ensures you receive **one consolidated daily brief**, not multiple notifications throughout the day.

In n8n terms: this is your **Cron / Time-based orchestration layer**.

## **Step 2: Search for Yesterday's AI Newsletter Emails**

### **What This Step Does**

This step searches your Gmail inbox for all emails labeled **"AI Newsletters"** from the last 24 hours.

### **Configuration**

- Add Action ‚Üí **Gmail**
- Choose **Find Email**
- Search string:

```
label:"AI Newsletters" newer_than:1d
```

### **Breaking Down the Search Query**

| Component | Purpose |
|----------|---------|
| `label:"AI Newsletters"` | Filters relevant newsletters |
| `newer_than:1d` | Only yesterday's emails |

### **Gmail Search Operator Tips**

- `from:newsletter@example.com`
- `subject:AI`
- `has:attachment`

## **Step 3: Summarize Emails with AI**

### **What This Step Does**

This step uses OpenAI's GPT-4o mini model to **reason over multiple emails** and return a structured summary.

### **Configuration**

- Add Action ‚Üí **AI by Zapier**
- Choose **Analyze and Return Data**
- Provider: OpenAI
- Model: GPT-4o mini
- Prompt:

```
You are an AI newsletter summarizer. Analyze all the emails provided and create a comprehensive daily summary.

For each email, extract and structure the following:
1. Subject/Title
2. Key Points (3‚Äì5 bullets)
3. Sender/Source
4. Action Items & Links

Format as a structured brief.
```

### **Input Mapping**

- Subject ‚Üí `{{step_2__subject}}`
- Sender ‚Üí `{{step_2__from__name}}`
- Body (plain + HTML)

### **Output Schema**

- subject
- key_points
- sender
- action_items
- links

This is the **"reasoning core"** of your AI agent.

## **Step 4: Send the Formatted Brief to Slack**

### **What This Step Does**

Post the AI-generated brief into Slack in a readable format.

### **Configuration**

- Add Action ‚Üí **Slack**
- Choose **Send Channel Message**
- Select channel
- Message template:
  - Send as bot: Yes
  - Bot name: AI Newsletter Bot

```
üì∞ AI Newsletter Daily Brief

SUBJECT:
{{step_3__subject}}

FROM:
{{step_3__sender}}

KEY POINTS:
{{step_3__key_points}}

ACTION ITEMS:
{{step_3__action_items}}

LINKS:
{{step_3__links}}
```

## **Testing Your Zap**

Test each step sequentially:
- Schedule trigger fires
- Gmail returns emails
- AI produces structured output
- Slack receives a message

Verify formatting and content accuracy.

This is my Zap response

## **Troubleshooting Guide**

### **Gmail returns no results**

- Confirm label exists
- Test without `newer_than:1d`

### **AI output incomplete**

- Ensure the email body is passed correctly
- Simplify the prompt if needed

### **Slack message fails**

- Confirm bot permissions
- Confirm channel access

## **Advanced Customizations**

- Filter only Substack emails:

```
from:@substack.com
```

- Multiple labels
- Multiple Slack channels
- Add Formatter for cleanup
- Change the schedule timing

## **Best Practices**

**Do**
- Test before enabling
- Review summaries initially
- Start simple

**Don't**
- Over-optimize early
- Post directly to #general
- Expect perfect AI output on day one

## **Conclusion**

By Day 2, you've built a **real AI agent workflow** that:
- Runs on a schedule
- Consumes unstructured data
- Uses an LLM for reasoning
- Produces structured output
- Delivers value automatically

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 11: üöÄ Day 1: Building AI Agents ‚Äî Create an AI-Powered ATS Resume Reviewer & Writer Using n8n

**Published:** December 19, 2025

Welcome to **Day 1 of building AI Agents**.

Over the next **30 days**, we'll build **real, production-grade AI agents** or **platforms**‚Äî not chat demos, not toy examples ‚Äî but agents that **reason, validate, decide, and take actions**.

My goal is that by the end of 30 days, you'll be able to build AI agents or full AI products and become well-versed in using tools like n8n, Make, Lovable, Cursor, CrewAI, Langchain, Autogen, and more.

Today's agent: üëâ An **AI-powered ATS Resume Reviewer & Writer**, built using **n8n**.

No backend. No frontend. Just **AI + workflows + automation**.

## **ü§ñ What Is an AI Agent?**

An **AI agent** is more than an LLM response.

An agent:
- Accepts structured inputs
- Applies rules and constraints
- Uses tools (APIs, documents, databases)
- Makes decisions
- Produces structured outputs
- Can trigger actions automatically

This tutorial teaches you **agent architecture**, not just prompting.

## **üß† AI Agent Categories (What We'll Build in 30 Days)**

### **Category 1: Consumer Agents (Built-In)**

**Examples**
- ChatGPT Agent
- Claude 4
- Grok
- Gemini 4

Best for:
- Quick research
- Writing docs
- One-off tasks

Limitations:
- No automation
- No system control
- No workflows

### **Category 2: No-Code / Low-Code Agent Builders** ‚úÖ _(Today)_

**Examples**
- Zapier Agents
- Lindy
- Relay.app
- Make.com
- **n8n**

These agents:
- Combine workflows + AI reasoning
- Allow structured, repeatable automation
- Power most real-world AI use cases today

### **Category 3: Developer-First Platforms**

**Examples**
- LangChain
- CrewAI
- AutoGen
- Swarm

Used when:
- Building customer-facing AI products
- Engineering teams need full control

We'll reach this later.

## **üß∞ What is n8n?**

## **n8n** is a workflow automation platform.

Think of it as:

Zapier + logic + code + AI ‚Äî all in one

With n8n, you can:
- Call APIs
- Run JavaScript
- Use LLMs safely
- Add decision logic
- Build full AI agents visually

Most importantly: üëâ n8n lets you **control AI behavior** (prompts, validation, parsing, errors)

That's why it's ideal for learning agents.

## **üß™ Prerequisites**

Before beginning this lab, ensure you have:
- **Set up your n8n account**
- **Generate an OpenAI API key**
- **Downloaded the n8n workflow JSON file** üëâ Click Here. Don't forget to star the GitHub repo.

## **üü¢ Step 1: Set Up Your n8n Account**

If you're new to n8n:
- Create an n8n account (cloud or self-hosted)
- Log in to your **n8n dashboard**

Once logged in, continue below.

## **üü¢ Step 2: Import the Workflow**

- Click **Create Workflow**
- Open the menu (three dots/hamburger icon)
- Select **Import from File**
- Upload the downloaded JSON workflow

‚úÖ The workflow will appear on your canvas.

Do **not** run it yet.

## **üîê Step 3: Configure Google Docs Access (Google Cloud Console)**

This workflow creates and writes to **Google Docs**, so we must configure **Google OAuth correctly**.

This step is **mandatory**.

### **üß© Why This Step Exists**

Google APIs:
- Do NOT work with just an email login
- Require OAuth credentials
- Must be explicitly authorized

This setup allows your AI agent to:
- Create Google Docs
- Insert content programmatically
- Return a shareable document link

## **üü¢ Step 3.1: Create a Google Cloud Project**

- Go to **Google Cloud Console**
- Click **Select Project ‚Üí New Project**
- Give it a name (e.g. `n8n-ai-agents`)
- Create the project

## **üü¢ Step 3.2: Enable Google Docs API**

Inside your new project:
- Go to **APIs & Services ‚Üí Library**
- Search for **Google Docs API**
- Click **Enable**

(Optional but recommended)
- Also, enable the **Google Drive API**

## **üü¢ Step 3.3: Configure OAuth Consent Screen**

- Go to **APIs & Services ‚Üí OAuth Consent Screen**
- Choose **External**
- Fill required fields:
  - App name (e.g. `n8n AI Agent`)
  - User support email
  - Developer email
- Save and continue
- Add scopes:
  - `https://www.googleapis.com/auth/documents`
  - `https://www.googleapis.com/auth/drive.file`
- Save

üìå You do NOT need verification for personal use.

## **üü¢ Step 3.4: Create OAuth Credentials**

- Go to **APIs & Services ‚Üí Credentials**
- Click **Create Credentials ‚Üí OAuth Client ID**
- Application type: **Web application**
- Add redirect URI:

```
https://<your-n8n-domain>/rest/oauth2-credential/callback
```

(If using n8n cloud, this URL is shown inside n8n)
- Create credentials
- Copy:
  - Client ID
  - Client Secret

## **üü¢ Step 3.5: Configure Google Credential in n8n**

- Open **Credentials** in n8n
- Create new credential ‚Üí **Google OAuth2 API**
- Paste:
  - Client ID
  - Client Secret
- Click **Connect / Authenticate**
- Log in to Google and approve access

‚úÖ Google Docs access is now configured.

## **üü¢ Step 4: Input Fields (Why This Step Exists)**

### **Node: Edit Fields (Set Node)**

Defines:
- `resume_text`
- `job_description`
- `candidate_name`
- `target_role`

This node exists to:
- Centralize inputs
- Make the agent reusable
- Support future forms / APIs

## **‚ö†Ô∏è IMPORTANT: Replace Sample Resume & JD**

The workflow includes **sample data**.

You MUST replace:

```
resume_text ‚Üí Your resume (plain text)
job_description ‚Üí Target job description
candidate_name ‚Üí Your name
target_role ‚Üí Role title
```

If you skip this:
- ‚ùå The AI optimizes the sample resume
- ‚ùå Results are meaningless

## **üßπ Step 5: Clean & Normalize Text**

### **Node: Code in JavaScript**

Why this exists:
- Removes invisible characters
- Normalizes bullets
- Fixes spacing
- Prevents AI confusion

Clean inputs ‚Üí predictable AI outputs.

## **üö¶ Step 6: Input Validation**

### **Node: If**

Rules:
- Resume ‚â• 500 chars
- JD ‚â• 300 chars

Why:
- Prevent hallucinations
- Avoid wasted tokens
- Enforce quality

This is **production-grade agent design**.

## **ü§ñ Step 7: ATS Evaluation (AI Brain #1)**

### **Node: Message a model**

Purpose:
- Structured ATS-style scoring
- Identify strengths & gaps
- Output strict JSON

Evaluation is separated from writing to improve reliability.

## **üß© Step 8: Parse AI Output**

### **Node: Parse ATS JSON**

Why:
- LLMs sometimes break JSON
- Parsing protects downstream steps
- Agents must fail safely

## **‚úçÔ∏è Step 9: Resume Rewriting (AI Brain #2)**

### **Node: Tailor Resume**

Purpose:
- Rewrite the resume using gaps
- Maintain truth
- Preserve ATS formatting

This is **agent chaining**:

One AI analyzes ‚Üí another AI acts

## **üìÑ Step 10: Export to Google Docs**

Why Google Docs:
- Shareable
- Editable
- Recruiter-friendly

The agent:
- Creates a doc
- Inserts a tailored resume
- Returns a live URL

## **‚úÖ Step 11: Final Output**

Returns:
- ATS score
- Dimension scores
- Strengths & gaps
- Google Doc link

Ready for:
- Frontends
- APIs
- Notifications
- Scaling into a product

## **üéØ Day 1 Takeaway**

You didn't just build a resume tool.

You built a **real AI agent** with:
- Validation
- Decision logic
- Tool usage
- Multiple AI roles
- Safe automation

More on the way!!! Happy building:)

---

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 12: Why Midjourney Chose Discord? A Creative Haven for AI Art

**Published:** January 4, 2024

Midjourney, the popular AI art generator, has picked an unusual home: Discord. This choice might seem odd against the sleek, dedicated apps of today. Yet, it's a strategic move that's as creative as the art produced.

**Building a Creative Community:**

Midjourney isn't just about churning out AI-powered masterpieces; it's about fostering a collaborative space where creativity thrives. With its built-in communities and real-time interaction, Discord becomes more than just a platform - it's a vibrant, ever-evolving art studio. Imagine tossing prompt ideas with artists from across the globe, witnessing AI art, and receiving immediate feedback on your creations.

**Discord nurtures a sense of community and continuous creative exchange, unlike isolated apps.**

**Utilizing Ready Resources:**

Building and maintaining a separate platform is a resource-intensive task. Discord, on the other hand, offered a ready-made solution with robust image hosting, organized channels, and built-in chat functionalities. This allowed Midjourney to focus on refining the core AI engine while leveraging Discord's strengths to create a unique user experience.

**Learning and Improving Together:**

The partnership with Discord encourages a playful, experimental approach. Users learn by doing‚Äîtrying different prompts, sharing results, and collaborating. This not only makes AI art more accessible but also fun! Additionally, by continuously learning from user interactions and feedback, Midjourney improves, adapting to what users enjoy and find effective.

**Added Benefits of Discord:**
- **Continuous Learning from Feedback:** Midjourney's use of Discord allows it to evolve from user input constantly. This means the AI learns what's working and what's not, thanks to the vast amount of feedback provided by the community.
- **Better Prompts Lead to Better Art:** Users see which prompts yield the best art, leading them to craft better prompts over time. This collective learning helps everyone generate more stunning results.

**Challenges and the Future:**

While Discord's lively nature can be daunting for some, and dependency on a third-party platform raises sustainability questions, the benefits are clear. Midjourney's adoption of Discord has transformed it into a dynamic, collaborative space that fosters the growth of AI art.

**Subscribe to the AI & Product Newsletter on Substack to get access to subscriber-only content.**

---

AI & Product Newsletter

Explore the future of AI, product management, tech, and startups with weekly deep dives delivered straight to your inbox. Stay one step ahead of the curve by subscribing now.

By Sri Laxmi

**A subscription gets you:**
- Weekly deep dives on AI product
- Weekly product management content
- Full archives

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 13: From Note-Taking App to AI Savior: Clueso Founder Neil Bala on Building with User Focus

**Published:** December 31, 2023

Welcome, AI enthusiasts, to another exciting episode of AI Product Builders! This week, we delve into the fascinating world of **Clueso**, an AI-powered platform that's revolutionizing how companies create documentation and video tutorials. We had the pleasure of chatting with Clueso's founder, Neil Bala, and gleaned invaluable insights on building and scaling an AI product with user needs at the heart.

**Clueso: Bridging the Knowledge Gap with AI**

Imagine generating professional product guides and tutorials in a fraction of the time, without needing a dedicated tech writer or video editor. That's Clueso's magic! By simply recording a screencast, their AI automatically crafts a step-by-step article and a polished video tutorial. This empowers companies, especially startups and small businesses, to deliver top-notch user education and reduce customer churn, all while saving precious time and resources.

**From Desk Lamp to Clueso: Pivoting for Impact**

Neil's journey with Clueso is as inspiring as it is insightful. Originally, he and his co-founders built Desk Lamp, a note-taking app for students. However, they encountered challenges with monetization due to their target audience's price sensitivity. This valuable experience led them to pivot towards a bigger problem: the lack of efficient user education tools for companies. Clueso was born from this realization, driven by a passion for bridging the knowledge gap between products and their users.

**Key Takeaways from Neil's Founder Wisdom:**

Neil's insightful words resonated deeply throughout our conversation. Here are some key nuggets for aspiring AI product builders:
- **Embrace public building:** Share your journey, engage with potential users and investors, and build excitement together.
- **Customer validation reigns supreme:** Ensure you're truly solving a real problem by regularly seeking and acting upon user feedback.
- **Monetization fuels growth:** Don't wait too long to find a sustainable revenue model. Demonstrate your product's value and secure resources for continuous development.
- **Co-founder synergy is vital:** Surround yourself with complementary skills and a shared vision to navigate the startup rollercoaster.

**Beyond Documentation: Clueso's Impact**

Clueso's impact extends far beyond efficient documentation. Companies using their platform have reported a significant drop in support tickets related to product usage, and faster onboarding times thanks to readily available clear guides. They've even empowered users to choose their preferred learning format, further enhancing the user experience.

**A Glimpse into the Future: What's Next for Clueso?**

Neil shared their exciting vision for Clueso's future. They're actively exploring integrations with various platforms, expanding their language support, and delving into advanced AI features like personalized knowledge delivery. The goal is to continuously refine Clueso into the ultimate user education assistant, ensuring seamless product adoption and empowering every user to unlock their full potential.

**Wrapping Up: AI for User Empowerment**

Neil Bala and Clueso are pioneers in leveraging AI to democratize user education. Their story is a testament to the power of focusing on user needs, adapting to market demands, and embracing innovation. Clueso is not just a platform; it's a beacon of hope for businesses striving to bridge the knowledge gap and cultivate a seamless user experience.

We at AI Product Builders are thrilled to have shared this insightful conversation with you. Join us next week as we explore another corner of the ever-evolving AI landscape!

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 14: Navigating the AI Revolution: Essential Skills for Product Managers in the AI Era

**Published:** November 14, 2023

In the dynamic landscape of technology, artificial intelligence (AI) stands as the driving force reshaping industries and revolutionizing the business landscape. As the relentless march of AI continues, product managers find themselves at the forefront of this technological wave, compelled to acquire new skills that will not only keep them afloat but propel their careers to new heights.

## **AI Fundamentals Understanding:**

To effectively communicate with data scientists and engineers, product managers need to grasp the core concepts of AI, including machine learning (ML) and generative AI. While coding proficiency is not essential, understanding AI fundamentals empowers PMs to build AI products successfully. They must comprehend the strengths and limitations of different AI models, stay up-to-date with the latest advancements, and bridge the gap between technical teams and non-technical stakeholders.

**Where to start?**
- Understanding the basics of machine learning algorithms (e.g., linear regression, decision trees).
- Familiarity with generative AI concepts, such as GANs (Generative Adversarial Networks).
- Familiarity with different AI models that are being used right now

**Steps to Acquire:**
- Take online courses: Platforms like Coursera, edX, and Stanford offer introductory courses on machine learning and AI.
- Attend workshops and conferences: Participate in events where AI experts share insights and practical knowledge.
- Collaborate with AI teams: Engage in cross-functional collaborations to gain hands-on experience and insights from AI professionals.

## **Finding use-cases around AI:**

Identifying innovative AI applications relies on a deep understanding of the target audience and their pain points. Product managers must actively explore diverse industries and domains to draw inspiration for novel AI use cases. They foster a culture of innovation within their product teams, encouraging open discussions about AI possibilities. Additionally, they develop the ability to discern when AI may not be the optimal solution, saving resources and preventing over-engineering.

**Where to start?**
- Identifying AI applications in healthcare for predictive diagnostics.
- Exploring AI-driven personalization in e-commerce for enhanced customer experiences.
- Explore recommendation models

Check out my post AI use cases - https://www.linkedin.com/posts/sri-laxmi-b5875bba_ai-innovation-technologyleaders-activity-7122080809703899136-iYzS?utm_source=share&utm_medium=member_desktop

**Steps to Acquire:**
- Industry research: Stay updated on industry trends and emerging technologies in various sectors.
- Foster a culture of innovation: Encourage team members to brainstorm and explore unconventional AI applications.
- Networking: Connect with professionals from diverse industries to gain insights into their challenges and potential AI solutions

## **Data Literacy:**

Data literacy is a fundamental requirement for AI product managers. They need to develop a deep understanding of customer data to ensure its relevance, availability, and quality for AI applications. Asking the right questions and considering prior examples (supervised learning) or the need for learning without precedents (unsupervised learning) are crucial aspects of leveraging data effectively for AI solutions.

**Where to start?**

- Analyzing customer data to identify patterns for targeted marketing strategies.
- Understanding the difference between structured and unstructured data.
- Understand how to acquire data to train your models
- Understand how data can impact model quality

**Steps to Acquire:**
- Hands-on projects: Work on real-world projects that involve cleaning, analyzing, and interpreting data.
- Collaborate with data teams: Engage with data scientists and analysts to understand the practical aspects of working with data.
- Start playing with your customer data

## **AI Model Evaluation Expertise:**

As AI products flood the market, product managers must possess the expertise to evaluate AI models comprehensively. They establish metrics such as accuracy, precision, and recall, and also analyze model bias and fairness. By implementing automated testing and monitoring systems, they ensure consistent model performance over time. The user experience is a priority, with a focus on minimizing errors and continuously assessing and improving the models.

**Where to start?**
- Understand the different metrics used to measure model accuracy, quality, performance, etc
- Addressing bias in an AI algorithm used for resume screening.

**Steps to Acquire:**
- Learn model evaluation metrics: Understand metrics like F1 score, ROC-AUC, and confusion matrices.
- Hands-on experimentation: Experiment with AI models using platforms like TensorFlow or PyTorch.
- Continuous learning: Stay updated on advancements in AI model evaluation techniques through research papers and conferences.

## **Responsible AI Awareness:**

With growing concerns about data privacy, product managers are responsible for designing AI solutions with robust data encryption, access controls, and auditing features to protect user information. Keeping up-to-date with evolving data privacy laws and regulations is crucial to ensure compliance. Collaborating with legal and compliance teams, they develop privacy policies and consent mechanisms, while also educating stakeholders about data protection best practices.

**Steps to Acquire:**
- Collaborate with legal teams: Work closely with legal and compliance teams to understand regulatory requirements.
- Stay informed: Regularly review updates on data privacy laws and industry best practices.

## **Proficiency in using AI tools:**

Product managers need to familiarize themselves with a range of AI tools and platforms available for various tasks, from data analysis to content generation. Embracing AI as an enabler of productivity rather than a threat to job roles, they train team members on the effective use of AI tools. Staying updated on the latest AI applications and tools is crucial, allowing PMs to continuously enhance their engineering skills.

**Steps to Acquire:**
- Start using AI tools in your work
- Understand how other AI tools work and the technology behind it

By combining theoretical knowledge with practical experience, product managers can effectively acquire and hone these essential AI skills, positioning themselves as adept leaders in the AI-driven landscape.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 15: Figma X Generative AI

**Published:** November 8, 2023

Figma, renowned for its innovative product design applications, has recently unveiled a game-changing addition to its arsenal. FigJam AI, a suite of generative AI tools, promises to revolutionize the way teams collaborate on whiteboard projects, rendering them more efficient and accessible. This breakthrough technology, introduced in open beta, provides ready-to-use templates for various design and planning endeavors. FigJam AI's introduction marks a significant stride towards automating the creation of collaborative whiteboard projects, freeing up valuable time for creative tasks.

### **The Evolving Landscape**

FigJam is Figma's collaborative whiteboard platform, a versatile tool designed for teams to work on a multitude of projects, from design tasks to meeting organization and brainstorming sessions. It has garnered popularity since its launch in 2021, boasting a user base that extends beyond traditional designers. The application leverages a digital sticky note concept to facilitate idea sharing and organization, making it a versatile workspace for diverse teams. However, as the platform's adoption grew, so did the challenges of navigating and managing the growing number of digital sticky notes.

### **Empowering Creativity with AI**

Recognizing these challenges, Figma introduced three generative AI features to FigJam, designed to facilitate project initiation and organization. These features aim to empower users to initiate collaborative projects more effectively, organize their ideas in a structured manner, and effortlessly distill key insights from a sea of sticky notes.

**1. Generate**: The Generate feature simplifies the creation of FigJam boards by providing suggested prompts for various templates, such as flowcharts, icebreakers, brainstorming sessions, and meeting planners. Users can also describe their desired board content in their own words, with the AI providing default descriptions for added convenience. This feature streamlines the board creation process and ensures that users have a solid starting point for their projects.

**2. Sort:** FigJam AI's Sort function automatically categorizes sticky notes based on common themes. This intelligent organization tool brings structure to an otherwise chaotic whiteboard, making it easier to find and work with related ideas. For example, after a brainstorming session, designers can effortlessly sort sticky notes into thematic groups, enhancing the overall organization of the project.

**3. Summarize:** The Summarize feature is a powerful addition that automatically generates a concise summary of information derived from groups of sticky notes. This simplifies the task of extracting key themes and insights from extensive brainstorming sessions, saving valuable time and effort in the process.

### **Unleashing the Power of OpenAI**

FigJam AI relies on the robust capabilities of OpenAI's GPT-4, a large language model that has been fine-tuned to understand Figma and FigJam-specific concepts, such as diagrams and calendar objects. OpenAI's technology is a pivotal component in realizing the potential of AI-driven whiteboard collaboration. The use of AI enables FigJam to provide intelligent suggestions, simplifying project creation and management.

### **Figma's Holistic Approach**

Unlike many competitors who superficially integrate AI features, Figma adopts a holistic approach to enhancing its products. Rather than simply adding AI as a veneer to existing tools, Figma's AI features are the result of thoughtful internal exploration and hackathons. These features are carefully crafted to serve the specific needs of users who rely on Figma for productive cross-team collaboration, extending its utility beyond traditional design tasks.

### **Conclusion**

Figma's FigJam AI represents a significant leap in collaborative whiteboard technology, driven by the innovative use of generative AI. By automating the creation, organization, and summarization of whiteboard projects, Figma empowers teams to collaborate more efficiently and creatively. With a strong foundation in OpenAI technology, Figma's holistic approach to AI integration ensures that the tools are tailored to the diverse needs of its user base, setting it apart in the competitive landscape of collaborative design software. The introduction of FigJam AI ushers in a new era of streamlined and effective team collaboration, offering a promising glimpse into the future possibilities in the realm of creative workspaces.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 16: From Prompt to Perfection: How Copy.ai Enhances Your Writing Workflow

**Published:** October 31, 2023

## **1) What is Copy.ai?**

Copy.ai is an innovative writing tool powered by advanced AI algorithms. Using generative AI, Copy.ai assists users in generating compelling and engaging written content across various platforms. From creating ad copy to drafting blog posts, landing page content, or social media captions, the capabilities of Copy.ai seamlessly blend human creativity with AI's computational power.

## **2) Use Cases of Copy.ai**

Copy.ai offers a wide range of use cases, making it a valuable tool for individuals and businesses alike.

- **Advertising Copy**: Copy.ai helps in crafting persuasive and attention-grabbing advertising copy for various platforms such as Google Ads, Facebook Ads, Instagram posts, and more.
- **Content Writing**: From blog posts to articles, Copy.ai assists in generating engaging and informative content on any topic, saving significant time and effort.
- **Email Marketing**: Writing compelling email subject lines and body text is crucial. Copy.ai streamlines the process by suggesting captivating content and boosting open and click-through rates.
- **Product Descriptions**: Copy.ai enables the creation of compelling product descriptions that highlight features, benefits, and key selling points, maximizing conversion rates.
- **Social Media Captions**: Engage your audience on platforms like Instagram, Twitter, or LinkedIn with captivating copy and catchy captions tailored to your brand's voice.

## **3) Prompts for Copy.ai with Examples**

Copy.ai provides a multitude of prompts and templates to kickstart your writing process. Here are a few examples:

- **Blog Introduction**: "In this article, we will explore the top 5 strategies to enhance productivity."
- **Marketing Headline**: "Revolutionize your life with our cutting-edge technology."
- **Product Descriptions**: "Introducing the all-new smartphone that combines style and performance like never before."
- **Creative Writing Ideas**: "Write a short story about a mysterious island that grants wishes."

## **4) Copy.ai stands out among other writing tools due to its unique features that elevate the content creation experience.**

**1. Versatile Writing Prompts**: Copy.ai provides a wide range of writing prompts and templates tailored to various industries and formats. Whether you need ad copy, blog introductions, email subject lines or social media captions, Copy.ai has you covered with dynamic suggestions that spark creativity.

**2. Language Translation:** Copy.ai offers a built-in language translation feature, allowing you to seamlessly translate your content into multiple languages. This functionality is particularly useful for global businesses or content creators looking to reach a broader audience.

**3. Tone and Style Adjustments:** Copy.ai lets you customize the tone and style of your generated content to match your brand's voice or the desired writing style. Whether you want your content to be professional, conversational, or humorous, Copy.ai adapts to your preferences.

**4. Word and Sentence-Level Editing:** Copy.ai allows you to edit generated content at the word and sentence level, giving you full control over the final output. You can make adjustments, add or remove information, or rephrase sentences to ensure that the content aligns perfectly with your intentions.

**8. Workflow integration**: This has to be my favorite so far. Copy.ai has found a wonderful use case around AI for content writers by introducing workflow integration. You can customize your workflows and run your content work on autopilot.

## **5) Risks of Tools like Copy.ai**

While Copy.ai is an incredibly powerful tool, there are a few risks associated with AI-powered content generation:

- **Loss of Human Touch:** The automated nature of AI writing tools may result in content that lacks the nuance and authenticity that human writers bring.
- **Plagiarism Concerns:** Users must exercise caution to ensure that the generated content is original and doesn't infringe upon copyright or ethical boundaries.
- **Algorithmic Bias:** As AI models are trained on existing data, biases present in the training data may inadvertently be reflected in the generated content. Care must be taken to address potential bias issues.

In conclusion, Copy.ai offers tremendous opportunities for individuals and organizations looking to streamline their writing process. With its broad range of use cases, versatility, and user-friendly interface, Copy.ai empowers content creators to generate persuasive, engaging, and high-quality content. However, it's essential to remember limitations and risks associated with AI writing tools to ensure quality and ethical standards of the generated content. With its ability to transform the content creation landscape, Copy.ai emerges as an indispensable tool for professionals across industries. By combining the strengths of human creativity and AI-driven efficiency, Copy.ai empowers users to generate persuasive, engaging, and high-quality content. However, it's essential to navigate the potential limitations and risks associated with AI writing tools, ensuring the ethical and authentic production of content. With Copy.ai, the future of writing assistance has arrived.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 17: Getting to Know Your Virtual Friends with Character.ai

**Published:** October 24, 2023

## **What is Character.ai?**

Character.ai is an AI chatbot platform that has been designed to simulate conversations with fictional characters. Using advanced natural language processing and generative AI models, Character.ai can understand questions and hold nuanced discussions on a wide range of topics. Some of the virtual characters you can chat with include famous literary characters, celebrities, historical figures, and more.

The conversations with Character.ai feel very natural and life-like. The AI is able to recall details from the character's backstory and demonstrate their unique personality. It's almost like you are actually talking to character directly! The AI also has broad general knowledge that allows it to discuss almost any subject at a very high level.

### **My Experience Using Character.ai**

When I first started chatting with some of the characters on Character.ai, I was really impressed by how life-like and knowledgeable AI seemed. I was able to recall small details about the characters and incorporate them naturally into our discussion. The AI also demonstrated unique personality traits that were consistent with how character is portrayed.

One fun conversation I had was chatting with Spiderman about his superpowers and adventures fighting crime in New York City. The level of depth and realism in the AI's responses made it feel like I was getting insights directly from Spiderman! Overall, Character.AI provides a really engaging and immersive experience for interacting with virtual characters. It will be exciting to see how conversational AI advances in future.

### **Technology behind Character.ai**

Character.ai relies on advanced natural language processing (NLP) techniques and Generative AI models to power its conversational capabilities. Specifically, it utilizes deep learning models, such as transformer-based architectures, that have been trained on large-scale datasets. These models enable the AI to understand and generate human-like responses in real time.

The underlying technology involves training these models on vast amounts of text data, which helps them acquire language patterns and contextual understanding. The training process involves running the data through multiple iterations to optimize the models' ability to generate coherent and contextually appropriate responses. This allows the AI to converse with users and simulate interactions as if user is talking to a virtual character.

**To train each character within Character.ai, the AI models are trained on a diverse range of data sources. These sources typically include:**

- **Books and literature:** Character.ai incorporates a variety of literary works, from classic novels to contemporary fiction, to capture essence and nuances of different characters.
- **Movies and TV shows:** Transcripts and scripts from popular movies and TV shows are utilized to grasp the personality traits, dialogue patterns, and unique characteristics associated with the chosen characters.
- **Interviews and biographies:** Data from interviews with actors, authors, and experts, as well as biographical information, provide insights into a character's background, experiences, and thought processes.
- **Online content and articles:** Online content, articles, and other relevant sources are leveraged to further enhance the knowledge base and ensure updated information for each character.

### **Most used characters on Character.ai?**

Character.ai offers a wide range of virtual characters to chat with, and the popularity of characters can vary depending on individual interests and preferences. However, some of the most commonly used characters on Character.AI include:

- Classic literary characters like Sherlock Holmes, Jane Austen heroines, and characters from Shakespeare's plays.
- Famous historical figures such as Abraham Lincoln, Cleopatra, and Albert Einstein.
- Popular fictional characters from movies and TV shows, like Harry Potter, Darth Vader, and Captain Jack Sparrow.
- Iconic personalities from different fields, such as Albert Einstein, Marie Curie, and Leonardo da Vinci.

### **How is each character different from one another?**

Character.ai creates unique personalities for each virtual character, making them distinct from one another. These differences are based on the character's traits, background, and experiences. Here's how each character is different:

- **Personalities:** Each character has a distinct personality, which is developed based on their characteristics as portrayed in books, movies, or historical records. For example, Sherlock Holmes is known for his logical thinking and attention to detail, while Captain Jack Sparrow is known for his unpredictable and witty behavior.
- **Knowledge and expertise:** Characters vary in terms of their domain expertise. For instance, Marie Curie would have in-depth knowledge of scientific concepts and discoveries, while Darth Vader would have insights into the Star Wars universe.
- **Background and experiences:** The AI models used in Character.AI are trained on extensive datasets that include information about each character's background and experiences. This enables the AI to generate responses that align with the character's unique story, adding depth and authenticity to the conversations.

However, while exploring the wonders of Character.ai, it is important to be mindful of potential challenges. Privacy concerns may arise, as conversations may involve sharing personal information. It is crucial for developers and users to prioritize data privacy and security measures to ensure a safe and trustworthy experience.

Additionally, although the AI models are trained on extensive datasets, including books and interviews, there is always a possibility of misinformation or biased information being conveyed in the AI's responses. Critical thinking and verification of information are essential when interacting with virtual characters on Character. AI.

In conclusion, Character.AI demonstrates how advanced AI is transforming digital conversations. Being able to chat with fictional characters in such a life-like way opens up new possibilities for storytelling and interactive experiences.

### **A few of my favorite characters**

---

Thanks for reading the AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 18: Spotify X Generative AI

**Published:** October 13, 2023

Remember when creating a playlist was an art form? Hours spent pouring over albums, debating song orders, crafting mixed tapes and CDs for your crush or road trip. Well, gone are the days of meticulously curating playlists by hand. Spotify is leveraging Generative AI to deliver personalized playlists and podcasts tailored precisely to each listener. Let's explore the three latest developments showcasing Spotify's dedication to an AI-powered future.

### **1. AI-Generated Playlists with Prompts**

Spotify users currently have access to a variety of personalized playlists, such as Discover Weekly, Daily Mix, and Release Radar. These playlists are generated using algorithms that take into account the user's listening history and preferences. However, users do not have the ability to directly control the content of these playlists.

Tired of Spotify's recommended playlists that seem to miss the mark? Soon you may be able to conjure up the perfect playlist simply by describing what you want. Recent discoveries hint that Spotify is developing "AI playlists" based entirely on your prompts. Fancy a upbeat mix for your workout? An indie folk compilation for winding down? Or a genre-spanning party playlist? Spotify's AI could deliver playlists tailored to your exact specifications.

While Spotify hasn't officially confirmed these plans, the groundwork for such AI playlists may have been laid with the introduction of Niche mixes. These mixes allow users to build unique playlists based on textual descriptions alone, such as genre, vibe, or aesthetic. Although these mixes are not currently AI-powered, Spotify has hinted at a future where AI-generated playlists might be built using prompts.

This development highlights Spotify's dedication to leveraging AI to enhance music personalization, a journey that goes beyond just the AI DJ feature that garnered much attention.

#### **How the improvement helped users:**

AI-generated playlists with prompts would give users more control over their personalized listening experience. Users could create playlists based on their own specific criteria, such as genre, mood, or activity. This would make it easier for users to find the perfect music for any occasion.

#### **Potential threats to users:**

One potential threat to users is that AI-generated playlists could be biased. For example, if the user only creates playlists based on their existing preferences, they may not be exposed to new music or genres.

Another potential threat is that AI-generated playlists could be used to manipulate users. For example, if a company wanted to promote a new song or album, they could create playlists that are biased towards that artist's music.

### **2. The AI DJ**

Spotify's AI DJ feature represents a significant step towards the streamer's AI-powered future. Launched ahead of Spotify's Stream On event in early 2023, the AI DJ curates a personalized music selection combined with spoken commentary in a life like AI-generated voice. This innovative feature is underpinned by cutting-edge AI technologies, including large language models and generative voice, all integrated into Spotify's existing personalization and machine learning framework.

The AI DJ is designed to understand users so well that it can effortlessly play the music they desire with a simple tap. This marks a shift in how users engage with music on platform, especially with its prominent placement in the revamped app.

Spotify's ability to make the AI DJ sound realistic is a game-changer. The voice was created using technology acquired from Sonantic, with a level of authenticity that sets it apart from earlier AI attempts like Google's Duplex. This technology not only captures different emotions but also imitates natural human pauses for breathing, intonations, and excitement for specific genres. This realistic AI voice is a testament to Spotify's dedication to creating a more immersive listening experience.

### **3. Podcast Voice Translation with AI**

Moving beyond music, Spotify is venturing into the realm of podcasts with its AI-powered Voice Translation feature. This groundbreaking tool uses AI, including OpenAI's voice generation technology, to translate podcasts into multiple languages while maintaining the original speaker's style and characteristics. This approach ensures a more authentic and natural listening experience compared to traditional dubbing.

As part of the pilot for Voice Translation, Spotify collaborated with renowned podcasters to generate AI-powered voice translations in languages like Spanish, French, and German. This initiative will enable podcasters' voices to be heard worldwide, breaking down language barriers and expanding the reach of podcast content.

The feedback from early adopters has been promising, reinforcing Spotify's belief that AI can forge deeper connections between creators and listeners. This project is just the beginning, with plans to extend access to more creators and languages in the future.

### **In Conclusion**

Spotify's journey into AI-driven personalization is far from over. From AI-generated playlists with prompts to lifelike AI DJ voices and innovative podcast translations, Spotify is committed to offering its users a more immersive and tailored experience. While these developments are exciting, they are only a glimpse of what the future holds for AI in the world of music and podcast streaming. As Spotify continues to innovate and explore the possibilities of AI, users can look forward to more personalized and engaging content in the coming years.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 19: Revolutionizing Photoshop: Adobe's Leap into Generative AI

**Published:** October 5, 2023

In the ever-evolving world of technology and creative innovation, Adobe has once again raised the bar for digital content creation. With the integration of generative AI powered by Firefly, Adobe Photoshop has undergone a groundbreaking transformation, offering a slew of new features that will forever change the way creators approach image editing. In this blog, we delve into the exciting enhancements that Adobe has introduced and explore how these features are poised to make Photoshop an even more indispensable tool for artists and designers.

## **Generative AI Takes Center Stage:**

On May 23, 2023, Adobe ushered in a new era for Photoshop by infusing it with the power of generative AI. This update introduces a host of Firefly-based features that promise to redefine image manipulation. Here's a glimpse of what's in store:

**1. Extend Beyond Borders**: Photoshop users can now effortlessly extend images beyond their original boundaries with Firefly-generated backgrounds. This feature opens up endless possibilities for creating stunning compositions and immersive visuals.

**2. Object Addition with AI:** Generative AI now allows users to seamlessly integrate objects into their images. Whether you want to add a playful twist to a photo or blend elements seamlessly, this tool empowers you to do so with unprecedented ease and precision.

**3. Precision in Object Removal:** The new generative fill feature provides an unparalleled level of precision when removing objects from images. Bid farewell to the limitations of content-aware fill as this advanced tool takes your object removal capabilities to the next level.

## **The Magic of Natural Language Prompts:**

One of the most exciting aspects of this integration is the ability to use natural language text prompts to guide Firefly in generating images or objects. Imagine describing your vision in words, and with a few keystrokes, witnessing it come to life on your screen. While generative AI can yield unpredictable results, Adobe offers users three variations for each prompt to choose from, ensuring creative flexibility.

### **A Sneak Peek at the Creative Potential:**

While generative AI results can be a mixed bag, some outcomes were nothing short of impressive. For instance, Firefly was able to generate a realistic puddle beneath a running corgi, considering the lighting conditions and even adding a convincing reflection. It's evident that Firefly excels at enhancing landscapes, though it may stumble with text-based requests. Check out the image I generated using my vision and memories from Munich.

**Prompt** - "Create a surreal and dreamy nighttime cityscape with neon-lit skyscrapers reflecting in a calm, glassy river. The city is Munich"

_Photo credits - Adobe_

## **How did Adobe train their models?**

Firefly draws its creative prowess from a vast repository of over 100 million images, including Adobe's stock images, licensed visuals, and public domain pictures. This extensive dataset forms the foundation of Firefly's ability to produce high-quality, visually captivating AI-generated content.

Adobe Stock, a treasure trove of creative assets, provides the backbone for Firefly's training. Contributors to Adobe Stock, who typically receive 33% of royalties when their images are sold or used, play a pivotal role in shaping Firefly's capabilities.

## **How is it helping creators/artists/designers?**

#### **Design recommendations:**

For creators, this means you don't have to rely only on your own instincts and skills. Firefly can be like your digital design assistant, guiding you toward creating designs that not only look good but also function optimally for users.

#### **Collaboration:**

In today's fast-paced design world, teamwork is crucial. Adobe Firefly recognizes this and offers features that make it a breeze for teams to collaborate.

With Firefly, creators and team members can work together in real-time. They can easily share ideas, mark areas for improvement, and suggest changes. This eliminates the need for long, confusing email chains or chats, ensuring that everyone stays on the same page throughout the design process.

#### **Seamless Integration with Adobe Creative Cloud**

Adobe Firefly seamlessly fits into the Adobe Creative Cloud suite, enhancing its capabilities and opening up endless possibilities for designers. Whether you're already familiar with tools like Photoshop, Illustrator, or XD or if you're new to Adobe's world, Firefly provides a familiar and user-friendly interface that lets you use your existing skills and workflows without any hassle.

## **Safety and Responsibility:**

Adobe has prioritized safety in the use of generative AI. By drawing from a curated training set of images, including Adobe Stock and other commercially safe sources, the results are intended to be reliable and free from objectionable content. Additional safeguards, such as excluding certain terms and words, ensure that the generated content remains within appropriate boundaries.

## **The Future Beyond Photoshop:**

While these features mark a significant leap for Photoshop, Adobe has even bigger plans. The company is actively exploring the extension of Firefly's capabilities to Lightroom, its popular photo management tool. This expansion promises to unlock new creative avenues for photographers and digital artists.

## **Conclusion:**

With the integration of Firefly's generative AI, Adobe Photoshop has redefined the boundaries of image editing. Natural language prompts, precision object removal, and object addition with AI are just the beginning of this transformative journey. Adobe's commitment to safety and responsible AI usage ensures that creators can push the limits of their creativity without crossing any ethical lines. As we await further developments and the eventual integration of Firefly into Lightroom, it's clear that Adobe remains at the forefront of empowering digital artists and photographers with cutting-edge technology. The future of creativity has arrived, and it's more exciting than ever.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

# Post 20: YouTube x Generative AI: AI-Powered Tools for Content Creators

**Published:** September 26, 2023

## **AI Insights for Creative Spark**

Introduction of "AI Insights for Creators," a tool designed to streamline the brainstorming process. By leveraging generative AI, this tool suggests video topics based on data derived from viewer preferences and trending content. This breakthrough innovation is poised to be a game-changer for content creators who often grapple with the challenge of ideation.

**Advantage for Content Creators:** This tool not only jumpstarts the creative process but also saves valuable time and resources. Creators can confidently generate ideas that align with audience interests, reducing the uncertainty and guesswork associated with content planning.

## **Dream Screen: Fueling Creativity with AI**

Another exciting addition is "Dream Screen," which is set to empower users in the Shorts platform. This tool harnesses the power of AI to generate video or image backgrounds based on text input. Imagine typing in whimsical requests like "a panda drinking coffee" or fantastical scenarios like "underwater castles," and witnessing them come to life on screen. Dream Screen opens up new creative horizons, making it easier for individuals to produce engaging content without needing extensive production expertise.

**Advantage for Content Creators:** Dream Screen eliminates the need for elaborate sets or backgrounds, allowing creators to focus on their content's essence. It offers a cost-effective solution for producing visually captivating videos, broadening the possibilities for creative expression.

## **Revolutionizing Music Selection and Dubbing**

YouTube is also expanding its Creator Music feature with AI-enhancements. Creators will soon be able to employ AI tools to simplify the process of finding suitable music for their videos. With a description-based search, they can quickly discover the perfect soundtrack that fits their vision. This feature promises to expedite music selection and licensing, making it a breeze for creators to enhance their content.

**Advantage for Content Creators:** This AI-driven music selection tool not only saves time but also helps creators avoid copyright issues by suggesting suitable, licensed tracks. It enhances the overall quality of videos while simplifying the often complex task of music selection.

Additionally, YouTube is introducing an **AI-dubbing tool called "Aloud."** This intuitive tool simplifies the process of dubbing content into different languages, offering creators the ability to reach a global audience effortlessly. By providing a one-click solution, Aloud is set to become an invaluable asset for content localization and expansion.

**Advantage for Content Creators:** Aloud expands the reach of creators by making content accessible to diverse language-speaking audiences. It saves the time and resources that would otherwise be spent on manual dubbing, enabling creators to scale their content effectively.

## **A Bright Future for Content Creation**

These AI-driven innovations, poised to launch next year, mark a significant step forward in YouTube's mission to empower content creators and make content creation more accessible. With tools that inspire, simplify, and amplify creativity, YouTube is set to nurture a vibrant and diverse ecosystem of content that resonates with audiences worldwide. The future of content creation has arrived, and it's fueled by the power of AI, offering a multitude of advantages for content creators.

---

Thanks for reading AI & Product Newsletter! Subscribe for free to receive new posts and support my work.

---

**End of all posts**

I've extracted and formatted all 16 posts from the AI & Product Newsletter into a copyable markdown format. Each post includes the full title, publication date, and complete content as they appeared in the RSS feed.

